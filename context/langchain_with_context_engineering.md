# åŸºäºä¸Šä¸‹æ–‡å·¥ç¨‹çš„ LangChain æ™ºèƒ½ä½“åº”ç”¨

ä¸Šä¸‹æ–‡å·¥ç¨‹æŒ‡åœ¨æ‰§è¡Œä»»åŠ¡å‰ä¸ºäººå·¥æ™ºèƒ½åˆ›å»ºåˆç†é…ç½®æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŒ…å«ï¼š

* **è¡Œä¸ºå‡†åˆ™**ï¼šæ˜ç¡®AIçš„èŒèƒ½å®šä½ï¼ˆä¾‹å¦‚æ‹…ä»»ç»æµå‹æ—…è¡Œè§„åˆ’åŠ©æ‰‹ï¼‰
* **ä¿¡æ¯æ¥å…¥**ï¼šå¯è®¿é—®æ•°æ®åº“ã€æ–‡æ¡£æˆ–å®æ—¶æ•°æ®æºçš„å…³é”®ä¿¡æ¯
* **ä¼šè¯è®°å¿†**ï¼šä¿ç•™å†å²å¯¹è¯è®°å½•ä»¥é¿å…é‡å¤æˆ–ä¿¡æ¯é—æ¼
* **å·¥å…·é›†æˆ**ï¼šæ”¯æŒè°ƒç”¨è®¡ç®—å™¨æˆ–æœç´¢å¼•æ“ç­‰è¾…åŠ©åŠŸèƒ½
* **ç”¨æˆ·ç”»åƒ**ï¼šæŒæ¡ä¸ªäººåå¥½åŠåœ°ç†ä½ç½®ç­‰æ ¸å¿ƒä¿¡æ¯

![ä¸Šä¸‹æ–‡å·¥ç¨‹](https://cdn-images-1.medium.com/max/1500/1*sCTOzjG6KP7slQuxLZUtNg.png)
*ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼ˆæ¦‚å¿µæºè‡ª[LangChain](https://blog.langchain.com/context-engineering-for-agents/) ä¸[12Factor](https://github.com/humanlayer/12-factor-agents/tree/main) ï¼‰*

[å½“å‰AIå·¥ç¨‹å¸ˆæ­£é€æ­¥è½¬å‹](https://diamantai.substack.com/p/why-ai-experts-are-moving-from-prompt) ï¼Œä»æç¤ºè¯å·¥ç¨‹è½¬å‘ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼ŒåŸå› åœ¨äº...

> ä¸Šä¸‹æ–‡å·¥ç¨‹ä¸“æ³¨äºä¸ºäººå·¥æ™ºèƒ½æä¾›åˆé€‚çš„èƒŒæ™¯å’Œå·¥å…·ï¼Œä½¿å…¶å›ç­”æ›´åŠ æ™ºèƒ½å®ç”¨ã€‚

æœ¬æ–‡å°†æ¢è®¨å¦‚ä½•è¿ç”¨**LangChain**ä¸**LangGraph**è¿™ä¸¤å¤§æ„å»ºäººå·¥æ™ºèƒ½æ™ºèƒ½ä½“ã€RAGåº”ç”¨å’ŒLLMåº”ç”¨çš„åˆ©å™¨ï¼Œæœ‰æ•ˆå®æ–½**ä¸Šä¸‹æ–‡å·¥ç¨‹**ä»¥ä¼˜åŒ–äººå·¥æ™ºèƒ½æ™ºèƒ½ä½“ã€‚

æœ¬æŒ‡å—åŸºäº[langgchain ai](https://github.com/FareedKhan-dev/contextual-engineering-guide) æŒ‡å—åˆ›å»ºã€‚

---

## 1. ä»€ä¹ˆæ˜¯ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼Ÿ

å¤§è¯­è¨€æ¨¡å‹è¿ä½œåŸç†ç±»ä¼¼æ–°å‹æ“ä½œç³»ç»Ÿã€‚å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¦‚åŒCPUï¼Œå…¶ä¸Šä¸‹æ–‡çª—å£åˆ™ç±»ä¼¼RAMï¼Œå……å½“çŸ­æœŸè®°å¿†åŠŸèƒ½ã€‚ä½†å¦‚åŒRAMçš„ç‰©ç†é™åˆ¶ï¼Œä¸Šä¸‹æ–‡çª—å£å­˜å‚¨ä¸åŒä¿¡æ¯çš„ç©ºé—´ä¹Ÿæœ‰é™ã€‚

> æ­£å¦‚æ“ä½œç³»ç»Ÿå†³å®šRAMçš„å­˜å‚¨å†…å®¹ï¼Œâ€œä¸Šä¸‹æ–‡å·¥ç¨‹â€çš„æ ¸å¿ƒåœ¨äºå†³ç­–LLMåº”åœ¨ä¸Šä¸‹æ–‡ä¸­ä¿ç•™å“ªäº›ä¿¡æ¯ã€‚

![ä¸åŒä¸Šä¸‹æ–‡ç±»å‹](https://cdn-images-1.medium.com/max/1000/1*kMEQSslFkhLiuJS8-WEMIg.png)

æ„å»ºLLMåº”ç”¨æ—¶éœ€ç®¡ç†å¤šç§ä¸Šä¸‹æ–‡ç±»å‹ã€‚ä¸Šä¸‹æ–‡å·¥ç¨‹ä¸»è¦æ¶µç›–ä»¥ä¸‹ç±»å‹ï¼š

* æŒ‡ä»¤ç±»ï¼šæç¤ºè¯ã€ç¤ºä¾‹ã€è®°å¿†ç‰‡æ®µã€å·¥å…·æè¿°
* çŸ¥è¯†ç±»ï¼šäº‹å®æ•°æ®ã€å­˜å‚¨ä¿¡æ¯ã€è®°å¿†åº“
* å·¥å…·ç±»ï¼šå·¥å…·è°ƒç”¨çš„åé¦ˆä¸æ‰§è¡Œç»“æœ

ä»Šå¹´å› å¤§è¯­è¨€æ¨¡å‹åœ¨æ€ç»´é“¾ä¸å·¥å…·è°ƒç”¨èƒ½åŠ›ä¸Šçš„æå‡ï¼Œæ™ºèƒ½ä½“æŠ€æœ¯æ­£è·å¾—æ›´å¤šå…³æ³¨ã€‚æ™ºèƒ½ä½“ç¾¤ç»„é€šè¿‡ååŒLLMä¸å·¥å…·å¤„ç†é•¿å‘¨æœŸä»»åŠ¡ï¼Œå¹¶ä¾æ®å·¥å…·åé¦ˆåŠ¨æ€å†³ç­–åç»­æ“ä½œã€‚

![æ™ºèƒ½ä½“å·¥ä½œæµ](https://cdn-images-1.medium.com/max/1500/1*Do44CZkpPYyIJefuNQ69GA.png)

ä½†å†—é•¿ä»»åŠ¡å’Œä»å·¥å…·æ”¶é›†è¿‡å¤šåé¦ˆä¼šæ¶ˆè€—å¤§é‡ä»¤ç‰Œã€‚è¿™å°†å¯¼è‡´å¤šé‡é—®é¢˜ï¼šä¸Šä¸‹æ–‡çª—å£å¯èƒ½æº¢å‡ºï¼Œæˆæœ¬ä¸å»¶è¿Ÿå¢åŠ ï¼Œä¸”æ™ºèƒ½ä½“æ€§èƒ½å¯èƒ½ä¸‹é™ã€‚

Drew Breunig é˜è¿°äº†è¿‡å¤šä¸Šä¸‹æ–‡æŸå®³æ€§èƒ½çš„æœºåˆ¶ï¼ŒåŒ…æ‹¬ï¼š

* ä¸Šä¸‹æ–‡æ±¡æŸ“ï¼š[å½“é”™è¯¯æˆ–å¹»è§‰å†…å®¹è¿›å…¥ä¸Šä¸‹æ–‡æ—¶](https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html?ref=blog.langchain.com#context-poisoning)
* ä¸Šä¸‹æ–‡å¹²æ‰°ï¼š[è¿‡é‡ä¸Šä¸‹æ–‡æ··æ·†æ¨¡å‹åˆ¤æ–­æ—¶](https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html?ref=blog.langchain.com#context-distraction)
* ä¸Šä¸‹æ–‡æ··æ·†ï¼š[å½“é¢å¤–æ— å…³ç»†èŠ‚å½±å“ç­”æ¡ˆæ—¶](https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html?ref=blog.langchain.com#context-confusion)
* ä¸Šä¸‹æ–‡å†²çªï¼š[å½“éƒ¨åˆ†ä¸Šä¸‹æ–‡æä¾›ç›¸äº’çŸ›ç›¾çš„ä¿¡æ¯æ—¶](https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html?ref=blog.langchain.com#context-clash)

![æ™ºèƒ½ä½“çš„å¤šè½®å¯¹è¯](https://cdn-images-1.medium.com/max/1500/1*ZJeZJPKI5jC_1BMCoghZxA.png)

Anthropic[åœ¨å…¶ç ”ç©¶ä¸­](https://www.anthropic.com/engineering/built-multi-agent-research-system?ref=blog.langchain.com) å¼ºè°ƒäº†å…¶å¿…è¦æ€§ï¼š

> æ™ºèƒ½ä½“ç¾¤ç»„é€šå¸¸éœ€è¦è¿›è¡Œæ•°ç™¾è½®å¯¹è¯ï¼Œå› æ­¤è°¨æ…ç®¡ç†ä¸Šä¸‹æ–‡è‡³å…³é‡è¦ã€‚

é‚£ä¹ˆç›®å‰äººä»¬å¦‚ä½•è§£å†³è¿™ä¸€é—®é¢˜ï¼Ÿäººå·¥æ™ºèƒ½æ™ºèƒ½ä½“çš„ä¸Šä¸‹æ–‡å·¥ç¨‹å¸¸ç”¨ç­–ç•¥å¯å½’çº³ä¸ºå››å¤§ä¸»è¦ç±»å‹ï¼š

* ç¼–å†™ï¼šåˆ›å»ºæ¸…æ™°æœ‰æ•ˆçš„ä¸Šä¸‹æ–‡
* ç­›é€‰ï¼šä»…é€‰å–æœ€ç›¸å…³ä¿¡æ¯
* å‹ç¼©ï¼šç¼©çŸ­ä¸Šä¸‹æ–‡ä»¥èŠ‚çœç©ºé—´
* éš”ç¦»ï¼šä¿æŒä¸åŒç±»å‹ä¸Šä¸‹æ–‡ç‹¬ç«‹

![ä¸Šä¸‹æ–‡å·¥ç¨‹åˆ†ç±»](https://cdn-images-1.medium.com/max/2600/1*CacnXVAI6wR4eSIWgnZ9sg.png)
*ä¸Šä¸‹æ–‡å·¥ç¨‹åˆ†ç±»ï¼ˆæºè‡ª[LangChainæ–‡æ¡£](https://blog.langchain.com/context-engineering-for-agents/) ï¼‰*

[LangGraph](https://www.langchain.com/langgraph) çš„è®¾è®¡å…¨é¢æ”¯æŒæ‰€æœ‰è¿™äº›ç­–ç•¥ã€‚æˆ‘ä»¬å°†é€šè¿‡`LangGrap`é€ä¸€è§£æè¿™äº›ç»„ä»¶ï¼Œæ¢ç©¶å…¶å¦‚ä½•ä¼˜åŒ–äººå·¥æ™ºèƒ½æ™ºèƒ½ä½“çš„è¿ä½œæ•ˆèƒ½ã€‚

## 2. LangGraphæš‚å­˜åŒºåº”ç”¨

å¦‚åŒäººç±»é€šè¿‡ç¬”è®°è®°å½•ä»»åŠ¡è¦ç‚¹ï¼Œæ™ºèƒ½ä½“å¯åˆ©ç”¨[æš‚å­˜åŒº](https://www.anthropic.com/engineering/claude-think-tool) å®ç°ç›¸åŒåŠŸèƒ½â€”â€”è¯¥æœºåˆ¶å°†ä¿¡æ¯å­˜å‚¨åœ¨ä¸Šä¸‹æ–‡çª—å£ä¹‹å¤–ï¼Œç¡®ä¿æ™ºèƒ½ä½“éšæ—¶è°ƒç”¨å…³é”®æ•°æ®ã€‚

![ä¸Šä¸‹æ–‡å·¥ç¨‹(CE)çš„ç¬¬ä¸€ç»„ä»¶](https://cdn-images-1.medium.com/max/1000/1*aXpKxYt03iZPcrGkxsFvrQ.png)
*ä¸Šä¸‹æ–‡å·¥ç¨‹çš„ç¬¬ä¸€ç»„ä»¶ï¼ˆæ‘˜è‡ª[LangChainæ–‡æ¡£](https://blog.langchain.com/context-engineering-for-agents/) ï¼‰*

å…¸å‹æ¡ˆä¾‹å‚è€ƒ[Anthropicå¤šæ™ºèƒ½ä½“ç ”ç©¶ç³»ç»Ÿ](https://www.anthropic.com/engineering/built-multi-agent-research-system) ï¼š

> *é¦–å¸­ç ”ç©¶å‘˜åˆ¶å®šè®¡åˆ’åå°†å…¶å­˜å…¥è®°å¿†ï¼Œå› ä¸ºå½“ä¸Šä¸‹æ–‡çª—å£è¶…è¿‡200,000ä»¤ç‰Œå®¹é‡æ—¶ä¼šè¢«æˆªæ–­ï¼Œä¿å­˜è®¡åˆ’å¯ç¡®ä¿å…¶å®Œæ•´æ€§ã€‚*

æš‚å­˜åŒºé›†å¯é€šè¿‡ä¸åŒæ–¹å¼å®ç°ï¼š

* é€šè¿‡[å·¥å…·è°ƒç”¨](https://www.anthropic.com/engineering/claude-think-tool) å®ç°[æ–‡ä»¶å†™å…¥åŠŸèƒ½](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem) ã€‚
* ä½œä¸ºä¼šè¯æœŸé—´æŒç»­å­˜åœ¨çš„è¿è¡Œæ—¶[çŠ¶æ€å¯¹è±¡](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) ä¸­çš„å­—æ®µå®ç°ã€‚

ç®€è€Œè¨€ä¹‹ï¼Œæš‚å­˜åŒºå¸®åŠ©æ™ºèƒ½ä½“åœ¨ä¼šè¯è¿‡ç¨‹ä¸­ä¿å­˜é‡è¦ç¬”è®°ï¼Œä»è€Œé«˜æ•ˆå®Œæˆä»»åŠ¡ã€‚

åœ¨LangGraphæ¡†æ¶ä¸­ï¼Œç³»ç»ŸåŒæ—¶æ”¯æŒ[çŸ­æœŸè®°å¿†](https://langchain-ai.github.io/langgraph/concepts/memory/#short-term-memory) ï¼ˆçº¿ç¨‹èŒƒå›´ï¼‰å’Œ[é•¿æœŸè®°å¿†](https://langchain-ai.github.io/langgraph/concepts/memory/#long-term-memory) æœºåˆ¶ã€‚

* çŸ­æœŸè®°å¿†é€šè¿‡[æ£€æŸ¥ç‚¹æœºåˆ¶](https://langchain-ai.github.io/langgraph/concepts/persistence/) åœ¨ä¼šè¯æœŸé—´ä¿å­˜[æ™ºèƒ½ä½“çŠ¶æ€](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) ã€‚ å…¶è¿ä½œåŸç†ç±»ä¼¼æš‚å­˜åŒºï¼Œå…è®¸åœ¨æ™ºèƒ½ä½“è¿è¡Œæ—¶å­˜å‚¨ä¿¡æ¯å¹¶åœ¨åç»­é˜¶æ®µè°ƒç”¨ã€‚

çŠ¶æ€å¯¹è±¡æ˜¯åœ¨å›¾èŠ‚ç‚¹é—´ä¼ é€’çš„æ ¸å¿ƒæ•°æ®ç»“æ„ã€‚å¯è‡ªå®šä¹‰å…¶æ ¼å¼ï¼ˆé€šå¸¸é‡‡ç”¨Pythonå­—å…¸å½¢å¼ï¼‰ã€‚ å®ƒå……å½“å…±äº«æš‚å­˜åŒºï¼Œæ¯ä¸ªèŠ‚ç‚¹å‡å¯è¯»å–å¹¶æ›´æ–°ç‰¹å®šå­—æ®µã€‚

> æˆ‘ä»¬å°†æŒ‰éœ€å¯¼å…¥æ¨¡å—ï¼Œä»¥ä¾¿ä»¥æ¸…æ™°çš„é€»è¾‘é€æ­¥å­¦ä¹ å®ç°è¿‡ç¨‹ã€‚

ä¸ºè·å¾—æ›´æ¸…æ™°ç¾è§‚çš„è¾“å‡ºæ•ˆæœï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Pythonçš„`pprint`æ¨¡å—è¿›è¡Œç¾åŒ–è¾“å‡ºï¼Œå¹¶é‡‡ç”¨`rich`åº“ä¸­çš„`Console`æ¨¡å—ã€‚é¦–å…ˆå¯¼å…¥å¹¶åˆå§‹åŒ–è¿™äº›æ¨¡å—ï¼š

```python
# å¯¼å…¥å¿…è¦åº“
from typing import TypedDict  # ç”¨äºé€šè¿‡ç±»å‹æç¤ºå®šä¹‰çŠ¶æ€æ¨¡å¼

from rich.console import Console  # ç”¨äºç¾åŒ–è¾“å‡º
from rich.pretty import pprint  # ç”¨äºç¾åŒ–Pythonå¯¹è±¡æ˜¾ç¤º

# åˆå§‹åŒ–æ§åˆ¶å°å¯¹è±¡ï¼Œå®ç°notebookä¸­çš„å¯Œæ–‡æœ¬æ ¼å¼åŒ–è¾“å‡º
console = Console()
```

æ¥ä¸‹æ¥åˆ›å»ºçŠ¶æ€å¯¹è±¡çš„`TypedDict`ï¼š

```python
# ä½¿ç”¨TypedDictå®šä¹‰å›¾çŠ¶æ€æ¨¡å¼
# è¯¥ç±»ä½œä¸ºæ•°æ®ç»“æ„å°†åœ¨å›¾çš„èŠ‚ç‚¹é—´ä¼ é€’
# ç¡®ä¿çŠ¶æ€å…·æœ‰ä¸€è‡´ç»“æ„å¹¶æä¾›ç±»å‹æç¤º
class State(TypedDict):
    """
    Defines the structure of the state for our joke generator workflow.

    Attributes:
        topic: The input topic for which a joke will be generated.
        joke: The output field where the generated joke will be stored.
    """

    topic: str
    joke: str
```

è¯¥çŠ¶æ€å¯¹è±¡å°†å­˜å‚¨ä¸»é¢˜ï¼Œä»¥åŠè¦æ±‚æ™ºèƒ½ä½“æ ¹æ®ç»™å®šä¸»é¢˜ç”Ÿæˆçš„ç¬‘è¯å†…å®¹

## 3. åˆ›å»ºçŠ¶æ€å›¾

å®šä¹‰çŠ¶æ€å¯¹è±¡åï¼Œå¯é€šè¿‡[StateGraph](https://langchain-ai.github.io/langgraph/concepts/low_level/#stategraph) å‘å…¶å†™å…¥ä¸Šä¸‹æ–‡

StateGraph æ˜¯ LangGraph æ„å»ºæœ‰çŠ¶æ€[æ™ºèƒ½ä½“æˆ–å·¥ä½œæµ](https://langchain-ai.github.io/langgraph/concepts/workflows/) çš„æ ¸å¿ƒå·¥å…·ï¼Œå¯å°†å…¶ç†è§£ä¸ºæœ‰å‘å›¾ï¼š

* èŠ‚ç‚¹ï¼ˆnodesï¼‰ä»£è¡¨å·¥ä½œæµä¸­çš„å¤„ç†æ­¥éª¤ã€‚æ¯ä¸ªèŠ‚ç‚¹æ¥æ”¶å½“å‰çŠ¶æ€ä½œä¸ºè¾“å…¥ï¼Œæ›´æ–°åè¿”å›å˜æ›´ç»“æœã€‚
* è¾¹ï¼ˆedgesï¼‰è¿æ¥èŠ‚ç‚¹å¹¶å®šä¹‰æ‰§è¡Œæµå‘ï¼Œæ”¯æŒçº¿æ€§ã€æ¡ä»¶åˆ¤æ–­ç”šè‡³å¾ªç¯è·¯å¾„ã€‚

æ¥ä¸‹æ¥æˆ‘ä»¬å°†æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

1. ä»[Anthropicæ¨¡å‹](https://docs.anthropic.com/en/docs/about-claude/models/overview) ä¸­é€‰æ‹©å¹¶åˆ›å»º[èŠå¤©æ¨¡å‹](https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html) ã€‚
2. å°†å…¶åº”ç”¨äºLangGraphå·¥ä½œæµä¸­ã€‚

```python
# å¯¼å…¥ç¯å¢ƒç®¡ç†ã€æ˜¾ç¤ºåŠŸèƒ½å’ŒLangGraphæ‰€éœ€çš„åº“
import getpass
import os

from IPython.display import Image, display
from langchain.chat_models import init_chat_model
from langgraph.graph import END, START, StateGraph

# --- ç¯å¢ƒä¸æ¨¡å‹é…ç½® ---
# è®¾ç½®Anthropic APIå¯†é’¥ä»¥éªŒè¯è¯·æ±‚
from dotenv import load_dotenv
api_key = os.getenv("ANTHROPIC_API_KEY")
if not api_key:
    raise ValueError("Missing ANTHROPIC_API_KEY in environment")

# åˆå§‹åŒ–å·¥ä½œæµä¸­å°†ä½¿ç”¨çš„èŠå¤©æ¨¡å‹
# é€‰ç”¨ç‰¹å®šClaudeæ¨¡å‹å¹¶è®¾å®štemperature=0ä»¥ç¡®ä¿è¾“å‡ºç¡®å®šæ€§
llm = init_chat_model("anthropic:claude-sonnet-4-20250514", temperature=0)
```

æˆ‘ä»¬å·²åˆå§‹åŒ–Sonnetæ¨¡å‹ã€‚LangChainé€šè¿‡APIæ”¯æŒå¤šç§å¼€æºå’Œé—­æºæ¨¡å‹ï¼Œå› æ­¤æ‚¨å¯ä»¥ä½¿ç”¨å…¶ä¸­ä»»æ„æ¨¡å‹ã€‚

ç°åœ¨éœ€è¦åˆ›å»ºä½¿ç”¨è¯¥Sonnetæ¨¡å‹ç”Ÿæˆå“åº”çš„å‡½æ•°ã€‚

```python
# --- å®šä¹‰å·¥ä½œæµèŠ‚ç‚¹ ---
def generate_joke(state: State) -> dict[str, str]:
    """
    A node function that generates a joke based on the topic in the current state.

    This function reads the 'topic' from the state, uses the LLM to generate a joke,
    and returns a dictionary to update the 'joke' field in the state.

    Args:
        state: The current state of the graph, which must contain a 'topic'.

    Returns:
        A dictionary with the 'joke' key to update the state.
    """
    # ä»çŠ¶æ€ä¸­è¯»å–ä¸»é¢˜
    topic = state["topic"]
    print(f"Generating a joke about: {topic}")

    # è°ƒç”¨è¯­è¨€æ¨¡å‹ç”Ÿæˆç¬‘è¯
    msg = llm.invoke(f"Write a short joke about {topic}")

    # å°†ç”Ÿæˆçš„ç¬‘è¯è¿”å›è‡³çŠ¶æ€
    return {"joke": msg.content}
```

æ­¤å‡½æ•°ä»…è¿”å›åŒ…å«ç”Ÿæˆå“åº”ï¼ˆç¬‘è¯ï¼‰çš„å­—å…¸ã€‚

æ¥ä¸‹æ¥æˆ‘ä»¬å°†ä½¿ç”¨çŠ¶æ€å›¾è½»æ¾æ„å»ºå¹¶ç¼–è¯‘è¯¥å›¾ã€‚

```python
# --- æ„å»ºå¹¶ç¼–è¯‘å›¾ç»“æ„ ---
# ä½¿ç”¨é¢„å®šä¹‰çš„çŠ¶æ€æ¨¡å¼åˆå§‹åŒ–æ–°çŠ¶æ€å›¾
workflow = StateGraph(State)

# å°†'ç”Ÿæˆç¬‘è¯'å‡½æ•°æ·»åŠ ä¸ºå›¾èŠ‚ç‚¹
workflow.add_node("generate_joke", generate_joke)

# å®šä¹‰å·¥ä½œæµçš„æ‰§è¡Œè·¯å¾„ï¼š
# å›¾ä»STARTå…¥å£ç‚¹å¼€å§‹æµå‘'ç”Ÿæˆç¬‘è¯'èŠ‚ç‚¹
workflow.add_edge(START, "generate_joke")
# 'ç”Ÿæˆç¬‘è¯'èŠ‚ç‚¹æ‰§è¡Œå®Œæ¯•åç»“æŸå›¾æµç¨‹
workflow.add_edge("generate_joke", END)

# å°†å·¥ä½œæµç¼–è¯‘ä¸ºå¯æ‰§è¡Œé“¾
chain = workflow.compile()

# --- å¯è§†åŒ–å›¾è°± ---
# å±•ç¤ºç¼–è¯‘åå·¥ä½œæµå›¾è°±çš„å¯è§†åŒ–å‘ˆç°
display(Image(chain.get_graph().draw_mermaid_png()))
```

![ç”Ÿæˆå›¾è°±](https://cdn-images-1.medium.com/max/1000/1*SxWwYN-oO_rG9xUFgeuB-A.png)

ç°åœ¨å¯ä»¥æ‰§è¡Œæ­¤å·¥ä½œæµ

```python
# --- æ‰§è¡Œå·¥ä½œæµ ---
# ä½¿ç”¨åŒ…å«ä¸»é¢˜çš„åˆå§‹çŠ¶æ€è°ƒç”¨ç¼–è¯‘å›¾è°±
# `invoke`æ–¹æ³•å°†è¿è¡Œä»STARTèŠ‚ç‚¹åˆ°ENDèŠ‚ç‚¹çš„å›¾è°±
joke_generator_state = chain.invoke({"topic": "cats"})

# --- æ˜¾ç¤ºæœ€ç»ˆçŠ¶æ€ ---
# æ‰“å°æ‰§è¡Œåçš„å›¾è°±æœ€ç»ˆçŠ¶æ€
# è¿™å°†åŒæ—¶æ˜¾ç¤ºå†™å…¥çŠ¶æ€çš„è¾“å…¥é¡¹'topic'å’Œè¾“å‡ºé¡¹'joke'
console.print("\n[bold blue]Joke Generator State:[/bold blue]")
pprint(joke_generator_state)

#### è¾“å‡ºç»“æœ ####
{
  'topic': 'cats', 
  'joke': 'Why did the cat join a band?\n\nBecause it wanted to be the purr-cussionist!'
}
```

è¿”å›çš„å­—å…¸æœ¬è´¨ä¸Šæ˜¯æ™ºèƒ½ä½“çš„ç¬‘è¯ç”ŸæˆçŠ¶æ€è¿™ä¸ªç®€å•ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•å°†ä¸Šä¸‹æ–‡å†™å…¥çŠ¶æ€

> æ‚¨å¯æ·±å…¥äº†è§£[æ£€æŸ¥ç‚¹æœºåˆ¶](https://langchain-ai.github.io/langgraph/concepts/persistence/) ï¼ˆç”¨äºä¿å­˜å’Œæ¢å¤å›¾è°±çŠ¶æ€ï¼‰åŠ[äººæœºååŒ](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/) ï¼ˆæš‚åœå·¥ä½œæµä»¥è·å–äººå·¥è¾“å…¥åç»§ç»­æ‰§è¡Œï¼‰

## 4. LangGraphä¸­çš„è®°å¿†å†™å…¥

æš‚å­˜åŒºé›†æ”¯æŒæ™ºèƒ½ä½“åœ¨å•æ¬¡ä¼šè¯ä¸­å·¥ä½œï¼Œä½†æœ‰æ—¶æ™ºèƒ½ä½“éœ€è¦è·¨å¤šä¸ªä¼šè¯ä¿ç•™è®°å¿†ä¿¡æ¯ã€‚

* [Reflexion](https://arxiv.org/abs/2303.11366) å¼•å…¥äº†æ™ºèƒ½ä½“åœ¨æ¯è½®äº¤äº’åè¿›è¡Œåæ€å¹¶å¤ç”¨è‡ªæˆ‘ç”Ÿæˆæç¤ºçš„æ¦‚å¿µã€‚
* [ç”Ÿæˆå¼æ™ºèƒ½ä½“](https://ar5iv.labs.arxiv.org/html/2304.03442) é€šè¿‡æ€»ç»“å†å²æ™ºèƒ½ä½“åé¦ˆæ„å»ºé•¿æœŸè®°å¿†ç³»ç»Ÿã€‚

![è®°å¿†å†™å…¥](https://cdn-images-1.medium.com/max/1000/1*VaMVevdSVxDITLK1j0LfRQ.png)
*è®°å¿†å†™å…¥ï¼ˆæºè‡ª [LangChainæ–‡æ¡£](https://blog.langchain.com/context-engineering-for-agents/) ï¼‰*

è¿™äº›ç†å¿µå·²åº”ç”¨äº [ChatGPT](https://help.openai.com/en/articles/8590148-memory-faq) ã€[Cursor](https://forum.cursor.com/t/0-51-memories-feature/98509) å’Œ [Windsurf](https://docs.windsurf.com/windsurf/cascade/memories) ç­‰äº§å“ï¼Œå®ƒä»¬èƒ½è‡ªåŠ¨ä»ç”¨æˆ·äº¤äº’ä¸­ç”Ÿæˆé•¿æœŸè®°å¿†ã€‚

* æ£€æŸ¥ç‚¹æœºåˆ¶ä¼šåœ¨æ¯ä¸ªæ­¥éª¤å°†å›¾çš„[çŠ¶æ€](https://langchain-ai.github.io/langgraph/concepts/persistence/) ä¿å­˜åˆ°[çº¿ç¨‹](https://langchain-ai.github.io/langgraph/concepts/persistence/) ä¸­ã€‚æ¯ä¸ªçº¿ç¨‹æ‹¥æœ‰å”¯ä¸€IDï¼Œé€šå¸¸ä»£è¡¨ä¸€æ¬¡äº¤äº’â€”â€”ä¾‹å¦‚ChatGPTä¸­çš„å•æ¬¡å¯¹è¯ã€‚
* é•¿æœŸè®°å¿†åŠŸèƒ½æ”¯æŒæ‚¨åœ¨ä¸åŒçº¿ç¨‹é—´ä¿æŒç‰¹å®šä¸Šä¸‹æ–‡ã€‚æ‚¨å¯ä»¥ä¿å­˜[ç‹¬ç«‹æ–‡ä»¶](https://langchain-ai.github.io/langgraph/concepts/memory/#profile) ï¼ˆä¾‹å¦‚ç”¨æˆ·æ¡£æ¡ˆï¼‰æˆ–è®°å¿†[é›†åˆ](https://langchain-ai.github.io/langgraph/concepts/memory/#collection) ã€‚
* è¯¥åŠŸèƒ½é‡‡ç”¨é”®å€¼å­˜å‚¨çš„[BaseStore](https://langchain-ai.github.io/langgraph/reference/store/) æ¥å£å®ç°ã€‚æ—¢å¯å¦‚ç¤ºä¾‹æ‰€ç¤ºåœ¨å†…å­˜ä¸­ä½¿ç”¨ï¼Œä¹Ÿå¯ç”¨äº[LangGraphå¹³å°éƒ¨ç½²](https://langchain-ai.github.io/langgraph/concepts/persistence/#langgraph-platform) ã€‚

ç°åœ¨è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª`å†…å­˜å­˜å‚¨`ï¼Œä¾›æœ¬ç¬”è®°æœ¬ä¸­å¤šä¸ªä¼šè¯å…±åŒä½¿ç”¨ã€‚

```python
from langgraph.store.memory import InMemoryStore

# --- åˆå§‹åŒ–é•¿æœŸè®°å¿†å­˜å‚¨ ---
# åˆ›å»ºInMemoryStoreå®ä¾‹ï¼Œå®ƒæä¾›ç®€å•ã€éæŒä¹…åŒ–çš„
# é”®å€¼å­˜å‚¨ç³»ç»Ÿï¼Œä»…é™å½“å‰ä¼šè¯ä½¿ç”¨
store = InMemoryStore()

# --- å®šä¹‰ç»„ç»‡ç”¨å‘½åç©ºé—´ ---
# å‘½åç©ºé—´ç”¨äºåœ¨å­˜å‚¨ä¸­å¯¹ç›¸å…³æ•°æ®è¿›è¡Œé€»è¾‘åˆ†ç»„
# æ­¤å¤„ä½¿ç”¨å…ƒç»„è¡¨ç¤ºåˆ†å±‚å‘½åç©ºé—´ï¼Œ
# å¯å…³è”ç”¨æˆ·IDå’Œåº”ç”¨ä¸Šä¸‹æ–‡
namespace = ("rlm", "joke_generator")

# --- å†™å…¥æ•°æ®åˆ°è®°å¿†å­˜å‚¨ ---
# ä½¿ç”¨`put`æ–¹æ³•å°†é”®å€¼å¯¹ä¿å­˜åˆ°æŒ‡å®šå‘½åç©ºé—´
# æ­¤æ“ä½œå°†ä¸Šä¸€æ­¥ç”Ÿæˆçš„ç¬‘è¯è¿›è¡ŒæŒä¹…åŒ–å­˜å‚¨ï¼Œ
# ä½¿å…¶å¯åœ¨ä¸åŒä¼šè¯æˆ–çº¿ç¨‹ä¸­æ£€ç´¢
store.put(
    namespace,  # ç›®æ ‡å†™å…¥å‘½åç©ºé—´
    "last_joke",  # æ•°æ®æ¡ç›®é”®å
    {"joke": joke_generator_state["joke"]},  # å¾…å­˜å‚¨çš„å€¼
)
```

æˆ‘ä»¬å°†åœ¨åç»­ç« èŠ‚è®¨è®ºå¦‚ä½•ä»å‘½åç©ºé—´ä¸­é€‰æ‹©ä¸Šä¸‹æ–‡å½“å‰å¯ä½¿ç”¨[search](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search) æ–¹æ³•æŸ¥çœ‹å‘½åç©ºé—´å†…çš„æ¡ç›®ï¼Œç¡®è®¤å†™å…¥æˆåŠŸ

```python
# æœç´¢å‘½åç©ºé—´ä»¥æŸ¥çœ‹æ‰€æœ‰å­˜å‚¨é¡¹
stored_items = list(store.search(namespace))

# ä»¥å¯Œæ–‡æœ¬æ ¼å¼æ˜¾ç¤ºå­˜å‚¨é¡¹
console.print("\n[bold green]Stored Items in Memory:[/bold green]")
pprint(stored_items)

#### è¾“å‡ºç»“æœ ####
[
  Item(namespace=['rlm', 'joke_generator'], key='last_joke', 
  value={'joke': 'Why did the cat join a band?\n\nBecause it wanted to be the purr-cussionist!'},
  created_at='2025-07-24T02:12:25.936238+00:00',
  updated_at='2025-07-24T02:12:25.936238+00:00', score=None)
]
```

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°†ä¹‹å‰çš„æ‰€æœ‰æ“ä½œæ•´åˆåˆ°LangGraphå·¥ä½œæµä¸­

æˆ‘ä»¬å°†ä½¿ç”¨ä¸¤ä¸ªå‚æ•°ç¼–è¯‘å·¥ä½œæµï¼š

* `checkpointer` åœ¨çº¿ç¨‹çš„æ¯ä¸ªæ­¥éª¤ä¿å­˜å›¾çŠ¶æ€
* `store` å®ç°è·¨çº¿ç¨‹çš„ä¸Šä¸‹æ–‡ä¿æŒ

```python
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.store.base import BaseStore
from langgraph.store.memory import InMemoryStore

# åˆå§‹åŒ–å­˜å‚¨ç»„ä»¶
checkpointer = InMemorySaver()  # ç”¨äºçº¿ç¨‹çº§çŠ¶æ€æŒä¹…åŒ–
memory_store = InMemoryStore()  # ç”¨äºè·¨çº¿ç¨‹è®°å¿†å­˜å‚¨


def generate_joke(state: State, store: BaseStore) -> dict[str, str]:
    """Generate a joke with memory awareness.
    
    This enhanced version checks for existing jokes in memory
    before generating new ones.
    
    Args:
        state: Current state containing the topic
        store: Memory store for persistent context
        
    Returns:
        Dictionary with the generated joke
    """
    # æ£€æŸ¥é•¿æœŸè®°å¿†ä¸­æ˜¯å¦å­˜åœ¨ç°æœ‰ç¬‘è¯
    existing_jokes = list(store.search(namespace))
    if existing_jokes:
        existing_joke = existing_jokes[0].value
        print(f"Existing joke: {existing_joke}")
    else:
        print("Existing joke: No existing joke")

    # æ ¹æ®ä¸»é¢˜ç”Ÿæˆæ–°ç¬‘è¯
    msg = llm.invoke(f"Write a short joke about {state['topic']}")
    
    # å°†æ–°ç¬‘è¯å­˜å…¥é•¿æœŸè®°å¿†
    store.put(namespace, "last_joke", {"joke": msg.content})

    # è¿”å›å¾…æ·»åŠ åˆ°çŠ¶æ€çš„ç¬‘è¯
    return {"joke": msg.content}


# æ„å»ºå…·å¤‡è®°å¿†èƒ½åŠ›çš„å·¥ä½œæµ
workflow = StateGraph(State)

# æ·»åŠ æ”¯æŒè®°å¿†çš„ç¬‘è¯ç”ŸæˆèŠ‚ç‚¹
workflow.add_node("generate_joke", generate_joke)

# è¿æ¥å·¥ä½œæµç»„ä»¶
workflow.add_edge(START, "generate_joke")
workflow.add_edge("generate_joke", END)

# åŒæ—¶å¯ç”¨æ£€æŸ¥ç‚¹æœºåˆ¶å’Œè®°å¿†å­˜å‚¨è¿›è¡Œç¼–è¯‘
chain = workflow.compile(checkpointer=checkpointer, store=memory_store)
```

å¾ˆå¥½ï¼ç°åœ¨åªéœ€æ‰§è¡Œæ›´æ–°åçš„å·¥ä½œæµï¼Œå³å¯æµ‹è¯•å¯ç”¨è®°å¿†åŠŸèƒ½çš„æ•ˆæœ

```python
# åŸºäºçº¿ç¨‹é…ç½®æ‰§è¡Œå·¥ä½œæµ
config = {"configurable": {"thread_id": "1"}}
joke_generator_state = chain.invoke({"topic": "cats"}, config)

# ä»¥ä¸°å¯Œæ ¼å¼å±•ç¤ºå·¥ä½œæµç»“æœ
console.print("\n[bold cyan]Workflow Result (Thread 1):[/bold cyan]")
pprint(joke_generator_state)

#### è¾“å‡ºç»“æœ ####
Existing joke: No existing joke

Workflow Result (Thread 1):
{  'topic': 'cats', 
   'joke': 'Why did the cat join a band?\n\nBecause it wanted to be the purr-cussionist!'}
```

ç”±äºè¿™æ˜¯çº¿ç¨‹1ï¼Œæˆ‘ä»¬çš„AIæ™ºèƒ½ä½“å†…å­˜ä¸­æ²¡æœ‰å­˜å‚¨ç°æœ‰ç¬‘è¯â€”â€”è¿™æ­£æ˜¯æ–°çº¿ç¨‹çš„é¢„æœŸçŠ¶æ€ã€‚

ç”±äºæˆ‘ä»¬é€šè¿‡æ£€æŸ¥ç‚¹æœºåˆ¶ç¼–è¯‘äº†å·¥ä½œæµï¼Œç°åœ¨å¯ä»¥æŸ¥çœ‹å›¾çš„[æœ€æ–°çŠ¶æ€](https://langchain-ai.github.io/langgraph/concepts/persistence/#get-state) ã€‚

```python
# --- æ£€ç´¢å¹¶æ£€æŸ¥å›¾çŠ¶æ€ ---
# ä½¿ç”¨`get_state`æ–¹æ³•æ£€ç´¢æŒ‡å®šçº¿ç¨‹ï¼ˆæœ¬ä¾‹ä¸­ä¸ºçº¿ç¨‹"1"ï¼‰çš„æœ€æ–°çŠ¶æ€å¿«ç…§ï¼Œ
# è¯¥æ“ä½œä¹‹æ‰€ä»¥å¯è¡Œï¼Œæ˜¯å› ä¸ºæˆ‘ä»¬åœ¨ç¼–è¯‘å›¾ç»“æ„æ—¶å¯ç”¨äº†æ£€æŸ¥ç‚¹æœºåˆ¶
#
latest_state = chain.get_state(config)

# --- æ˜¾ç¤ºçŠ¶æ€å¿«ç…§ ---
# å°†æ£€ç´¢åˆ°çš„çŠ¶æ€æ‰“å°è‡³æ§åˆ¶å°StateSnapshotä¸ä»…åŒ…å«
# æ•°æ®ï¼ˆ'topic', 'joke'ï¼‰ï¼Œè¿˜åŒ…å«æ‰§è¡Œå…ƒæ•°æ®
console.print("\n[bold magenta]Latest Graph State (Thread 1):[/bold magenta]")
pprint(latest_state)
```

æŸ¥çœ‹è¾“å‡ºç»“æœï¼š

```text
### æœ€æ–°çŠ¶æ€è¾“å‡º ###
Latest Graph State:

StateSnapshot(
    values={
        'topic': 'cats',
        'joke': 'Why did the cat join a band?\n\nBecause it wanted to be the purr-cussionist!'
    },
    next=(),
    config={
        'configurable': {
            'thread_id': '1',
            'checkpoint_ns': '',
            'checkpoint_id': '1f06833a-53a7-65a8-8001-548e412001c4'
        }
    },
    metadata={'source': 'loop', 'step': 1, 'parents': {}},
    created_at='2025-07-24T02:12:27.317802+00:00',
    parent_config={
        'configurable': {
            'thread_id': '1',
            'checkpoint_ns': '',
            'checkpoint_id': '1f06833a-4a50-6108-8000-245cde0c2411'
        }
    },
    tasks=(),
    interrupts=()
)
```

å¯è§å½“å‰çŠ¶æ€å·²è®°å½•æˆ‘ä»¬ä¸æ™ºèƒ½ä½“çš„æœ€è¿‘å¯¹è¯â€”â€”æœ¬ä¾‹ä¸­æˆ‘ä»¬è¦æ±‚å…¶è®²è¿°å…³äºçŒ«çš„ç¬‘è¯ã€‚è®©æˆ‘ä»¬ä½¿ç”¨ä¸åŒçš„IDé‡æ–°è¿è¡Œå·¥ä½œæµã€‚

```python
# ä½¿ç”¨ä¸åŒçº¿ç¨‹IDæ‰§è¡Œå·¥ä½œæµ
config = {"configurable": {"thread_id": "2"}}
joke_generator_state = chain.invoke({"topic": "cats"}, config)

# å±•ç¤ºè·¨çº¿ç¨‹å†…å­˜æŒä¹…åŒ–çš„ç»“æœ
console.print("\n[bold yellow]Workflow Result (Thread 2):[/bold yellow]")
pprint(joke_generator_state)

#### è¾“å‡ºç»“æœ ####
Existing joke: {'joke': 'Why did the cat join a band?\n\nBecause it wanted to be the purr-cussionist!'}
Workflow Result (Thread 2):
{'topic': 'cats', 'joke': 'Why did the cat join a band?\n\nBecause it wanted to be the purr-cussionist!'}
```

å¯è§é¦–ä¸ªçº¿ç¨‹çš„ç¬‘è¯å·²æˆåŠŸä¿å­˜è‡³å†…å­˜ã€‚

> æ‚¨å¯é€šè¿‡[LangMem](https://langchain-ai.github.io/langmem/) äº†è§£å†…å­˜æŠ½è±¡æœºåˆ¶ï¼Œé€šè¿‡[Ambientæ™ºèƒ½ä½“è¯¾ç¨‹](https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/memory.ipynb) æŒæ¡LangGraphæ™ºèƒ½ä½“ä¸­çš„å†…å­˜ç®¡ç†æ¦‚è§ˆã€‚

## 5. æš‚å­˜åŒºé€‰æ‹©ç­–ç•¥

ä»æš‚å­˜åŒºé€‰æ‹©ä¸Šä¸‹æ–‡çš„æ–¹å¼å–å†³äºå…¶å®ç°æœºåˆ¶ï¼š

* è‹¥å±äº[å·¥å…·](https://www.anthropic.com/engineering/claude-think-tool) ï¼Œæ™ºèƒ½ä½“å¯ç›´æ¥é€šè¿‡å·¥å…·è°ƒç”¨è¯»å–
* è‹¥å±äºæ™ºèƒ½ä½“è¿è¡Œæ—¶çŠ¶æ€ï¼Œå¼€å‘è€…éœ€è‡ªè¡Œå†³å®šæ¯ä¸ªæ­¥éª¤å‘æ™ºèƒ½ä½“æš´éœ²çš„çŠ¶æ€éƒ¨åˆ†è¿™ä½¿æ‚¨èƒ½å¤Ÿå¯¹æš´éœ²çš„ä¸Šä¸‹æ–‡å®æ–½ç»†ç²’åº¦æ§åˆ¶

![ä¸Šä¸‹æ–‡å·¥ç¨‹çš„ç¬¬äºŒç»„ä»¶](https://cdn-images-1.medium.com/max/1000/1*VZiHtQ_8AlNdV3HIMrbBZA.png)
*ä¸Šä¸‹æ–‡å·¥ç¨‹ç¬¬äºŒç»„ä»¶ï¼ˆæºè‡ª[LangChainæ–‡æ¡£](https://blog.langchain.com/context-engineering-for-agents/) ï¼‰*

åœ¨å…ˆå‰æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†å¦‚ä½•å‘LangGraphçŠ¶æ€å¯¹è±¡å†™å…¥æ•°æ®ã€‚ç°åœ¨æˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•ä»çŠ¶æ€ä¸­é€‰æ‹©ä¸Šä¸‹æ–‡ï¼Œå¹¶å°†å…¶ä¼ é€’è‡³ä¸‹æ¸¸èŠ‚ç‚¹çš„å¤§è¯­è¨€æ¨¡å‹è°ƒç”¨ä¸­ã€‚

è¿™ç§é€‰æ‹©æ€§æ–¹æ³•å…è®¸æ‚¨ç²¾ç¡®æ§åˆ¶å¤§è¯­è¨€æ¨¡å‹åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­å¯è§çš„ä¸Šä¸‹æ–‡å†…å®¹ã€‚

```python
def generate_joke(state: State) -> dict[str, str]:
    """Generate an initial joke about the topic.
    
    Args:
        state: Current state containing the topic
        
    Returns:
        Dictionary with the generated joke
    """
    msg = llm.invoke(f"Write a short joke about {state['topic']}")
    return {"joke": msg.content}


def improve_joke(state: State) -> dict[str, str]:
    """Improve an existing joke by adding wordplay.
    
    This demonstrates selecting context from state - we read the existing
    joke from state and use it to generate an improved version.
    
    Args:
        state: Current state containing the original joke
        
    Returns:
        Dictionary with the improved joke
    """
    print(f"Initial joke: {state['joke']}")
    
    # ä»çŠ¶æ€ä¸­é€‰å–ç¬‘è¯å‘ˆç°ç»™å¤§è¯­è¨€æ¨¡å‹
    msg = llm.invoke(f"Make this joke funnier by adding wordplay: {state['joke']}")
    return {"improved_joke": msg.content}
```

ä¸ºå¢åŠ å¤æ‚åº¦ï¼Œæˆ‘ä»¬å°†åœ¨æ™ºèƒ½ä½“ä¸­æ–°å¢ä¸¤ä¸ªå·¥ä½œæµï¼š

1. ç”Ÿæˆç¬‘è¯ï¼ˆä¸ä¹‹å‰æµç¨‹ç›¸åŒï¼‰
2. ä¼˜åŒ–ç¬‘è¯ï¼ˆæ¥æ”¶ç”Ÿæˆçš„ç¬‘è¯å¹¶è¿›è¡Œæ”¹è¿›ï¼‰

æ­¤è®¾ç½®å°†å¸®åŠ©æˆ‘ä»¬ç†è§£LangGraphä¸­æš‚å­˜åŒºé€‰æ‹©çš„è¿ä½œæœºåˆ¶ã€‚ç°åœ¨æŒ‰ç…§å…ˆå‰æ–¹å¼ç¼–è¯‘è¯¥å·¥ä½œæµï¼Œå¹¶æŸ¥çœ‹æˆ‘ä»¬çš„å›¾è°±ç»“æ„ã€‚

```python
# æ„å»ºåŒ…å«ä¸¤ä¸ªé¡ºåºèŠ‚ç‚¹çš„å·¥ä½œæµ
workflow = StateGraph(State)

# æ·»åŠ ä¸¤ä¸ªç¬‘è¯ç”ŸæˆèŠ‚ç‚¹
workflow.add_node("generate_joke", generate_joke)
workflow.add_node("improve_joke", improve_joke)

# æŒ‰é¡ºåºè¿æ¥èŠ‚ç‚¹
workflow.add_edge(START, "generate_joke")
workflow.add_edge("generate_joke", "improve_joke")
workflow.add_edge("improve_joke", END)

# ç¼–è¯‘å·¥ä½œæµ
chain = workflow.compile()

# æ˜¾ç¤ºå·¥ä½œæµå¯è§†åŒ–è§†å›¾
display(Image(chain.get_graph().draw_mermaid_png()))
```

![æˆ‘ä»¬ç”Ÿæˆçš„å›¾è°±](https://cdn-images-1.medium.com/max/1000/1*XU_CMOwwboMYcK6lw3HjrA.png)

æ‰§è¡Œæ­¤å·¥ä½œæµæ—¶ï¼Œæˆ‘ä»¬å°†è·å¾—å¦‚ä¸‹è¾“å‡ºã€‚

```python
# æ‰§è¡Œå·¥ä½œæµä»¥è§‚å¯Ÿä¸Šä¸‹æ–‡é€‰æ‹©æœºåˆ¶çš„å®é™…è¿ä½œ
joke_generator_state = chain.invoke({"topic": "cats"})

# ä»¥å¯Œæ–‡æœ¬æ ¼å¼å±•ç¤ºæœ€ç»ˆçŠ¶æ€
console.print("\n[bold blue]Final Workflow State:[/bold blue]")
pprint(joke_generator_state)

#### è¾“å‡ºç»“æœ ####
Initial joke: Why did the cat join a band?

Because it wanted to be the purr-cussionist!
Final Workflow State:
{
  'topic': 'cats',
  'joke': 'Why did the cat join a band?\n\nBecause it wanted to be the purr-cussionist!'}
```

å·¥ä½œæµæ‰§è¡Œå®Œæˆåï¼Œæˆ‘ä»¬å¯ç»§ç»­å°†å…¶åº”ç”¨äºè®°å¿†é€‰æ‹©é˜¶æ®µã€‚

## 6. è®°å¿†é€‰æ‹©èƒ½åŠ›

è‹¥æ™ºèƒ½ä½“å…·å¤‡è®°å¿†å­˜å‚¨èƒ½åŠ›ï¼Œåˆ™éœ€ä¸ºå½“å‰ä»»åŠ¡ç­›é€‰ç›¸å…³è®°å¿†ã€‚è¯¥æœºåˆ¶é€‚ç”¨äºï¼š

* [æƒ…æ™¯è®°å¿†](https://langchain-ai.github.io/langgraph/concepts/memory/#memory-types) â€”â€”å±•ç¤ºé¢„æœŸè¡Œä¸ºçš„å°‘æ ·æœ¬ç¤ºä¾‹
* [ç¨‹åºæ€§è®°å¿†](https://langchain-ai.github.io/langgraph/concepts/memory/#memory-types) â€”â€”æŒ‡å¯¼è¡Œä¸ºæ“ä½œçš„æŒ‡ä»¤é›†
* [è¯­ä¹‰è®°å¿†](https://langchain-ai.github.io/langgraph/concepts/memory/#memory-types) â€”â€”æä¾›ä»»åŠ¡ç›¸å…³èƒŒæ™¯çš„äº‹å®ä¸å…³ç³»ç½‘ç»œ

éƒ¨åˆ†æ™ºèƒ½ä½“ä½¿ç”¨ç‹­çª„çš„é¢„å®šä¹‰æ–‡ä»¶å­˜å‚¨è®°å¿†ï¼š

* Claudeä»£ç é‡‡ç”¨[`CLAUDE.md`](http://claude.md/) æ–‡ä»¶ã€‚
* [Cursor](https://docs.cursor.com/context/rules) ä¸[Windsurf](https://windsurf.com/editor/directory) é€šè¿‡ã€Œè§„åˆ™ã€æ–‡ä»¶å­˜å‚¨æŒ‡ä»¤æˆ–ç¤ºä¾‹ã€‚

ä½†å½“å­˜å‚¨å¤§é‡äº‹å®é›†åˆï¼ˆè¯­ä¹‰è®°å¿†ï¼‰æ—¶ï¼Œè®°å¿†ç­›é€‰ä¼šå˜å¾—å›°éš¾ã€‚

* [ChatGPT](https://help.openai.com/en/articles/8590148-memory-faq) å¶å°”ä¼šæ£€ç´¢æ— å…³è®°å¿†ï¼Œ[Simon Willison](https://simonwillison.net/2025/Jun/6/six-months-in-llms/) æ›¾æŒ‡å‡ºï¼šå½“ChatGPTé”™è¯¯è·å–å…¶åœ°ç†ä½ç½®å¹¶æ³¨å…¥å›¾åƒç”Ÿæˆè¿‡ç¨‹æ—¶ï¼Œä¼šè®©äººæ„Ÿè§‰ä¸Šä¸‹æ–‡ã€Œä¸å†å±äºè‡ªå·±ã€ã€‚
* ä¸ºä¼˜åŒ–ç­›é€‰æ•ˆæœï¼Œé€šå¸¸é‡‡ç”¨åµŒå…¥å‘é‡æˆ–[çŸ¥è¯†å›¾è°±](https://neo4j.com/blog/developer/graphiti-knowledge-graph-memory/#:~:text=changes%20since%20updates%20can%20trigger,and%20holistic%20memory%20for%20agentic) å»ºç«‹ç´¢å¼•æœºåˆ¶ã€‚

åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å‘å›¾ä¸­çš„`InMemoryStore`å†…å­˜å­˜å‚¨æ‰§è¡Œäº†å†™å…¥æ“ä½œã€‚ç°åœ¨å¯ä»¥é€šè¿‡[get](https://langchain-ai.github.io/langgraph/concepts/memory/#memory-storage) æ–¹æ³•ä»ä¸­é€‰æ‹©ä¸Šä¸‹æ–‡ï¼Œå°†ç›¸å…³çŠ¶æ€å¼•å…¥å·¥ä½œæµã€‚

```python
from langgraph.store.memory import InMemoryStore

# åˆå§‹åŒ–å†…å­˜å­˜å‚¨
store = InMemoryStore()

# å®šä¹‰å‘½åç©ºé—´ä»¥ç»„ç»‡è®°å¿†
namespace = ("rlm", "joke_generator")

# å°†ç”Ÿæˆçš„ç¬‘è¯å­˜å…¥å†…å­˜
store.put(
    namespace,                             # ç”¨äºç»„ç»‡çš„å‘½åç©ºé—´
    "last_joke",                          # é”®æ ‡è¯†ç¬¦
    {"joke": joke_generator_state["joke"]} # å¾…å­˜å‚¨çš„å€¼
)

# ä»å†…å­˜ä¸­é€‰æ‹©ï¼ˆæ£€ç´¢ï¼‰ç¬‘è¯
retrieved_joke = store.get(namespace, "last_joke").value

# æ˜¾ç¤ºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
console.print("\n[bold green]Retrieved Context from Memory:[/bold green]")
pprint(retrieved_joke)

#### è¾“å‡ºç»“æœ ####
Retrieved Context from Memory:
{'joke': 'Why did the cat join a band?\n\nBecause it wanted to be the purr-cussionist!'}
```

ç³»ç»ŸæˆåŠŸä»å†…å­˜ä¸­æ£€ç´¢åˆ°æ­£ç¡®çš„ç¬‘è¯ã€‚

ç°åœ¨éœ€è¦ç¼–å†™è§„èŒƒçš„`generate_joke`å‡½æ•°ï¼Œä½¿å…¶èƒ½å¤Ÿï¼š

1. è·å–å½“å‰çŠ¶æ€ï¼ˆç”¨äºæš‚å­˜åŒºä¸Šä¸‹æ–‡ï¼‰
2. åˆ©ç”¨è®°å¿†ï¼ˆè‹¥æ‰§è¡Œç¬‘è¯æ”¹è¿›ä»»åŠ¡æ—¶è·å–è¿‡å¾€ç¬‘è¯ï¼‰

æ¥ä¸‹æ¥æˆ‘ä»¬å°†å®ç°è¯¥å‡½æ•°ã€‚

```python
# åˆå§‹åŒ–å­˜å‚¨ç»„ä»¶
checkpointer = InMemorySaver()
memory_store = InMemoryStore()

def generate_joke(state: State, store: BaseStore) -> dict[str, str]:
    """Generate a joke with memory-aware context selection.
    
    This function demonstrates selecting context from memory before
    generating new content, ensuring consistency and avoiding duplication.
    
    Args:
        state: Current state containing the topic
        store: Memory store for persistent context
        
    Returns:
        Dictionary with the generated joke
    """
    # è‹¥å­˜åœ¨è¿‡å¾€ç¬‘è¯åˆ™ä»å†…å­˜ä¸­é€‰å–
    prior_joke = store.get(namespace, "last_joke")
    if prior_joke:
        prior_joke_text = prior_joke.value["joke"]
        print(f"Prior joke: {prior_joke_text}")
    else:
        print("Prior joke: None!")

    # ç”Ÿæˆä¸å…ˆå‰ä¸åŒçš„æ–°ç¬‘è¯
    prompt = (
        f"Write a short joke about {state['topic']}, "
        f"but make it different from any prior joke you've written: {prior_joke_text if prior_joke else 'None'}"
    )
    msg = llm.invoke(prompt)

    # å°†æ–°ç¬‘è¯å­˜å…¥å†…å­˜ä¾›åç»­ä¸Šä¸‹æ–‡é€‰æ‹©
    store.put(namespace, "last_joke", {"joke": msg.content})

    return {"joke": msg.content}
```

ç°åœ¨æˆ‘ä»¬å¯ä»¥åƒä¹‹å‰é‚£æ ·ç›´æ¥æ‰§è¡Œè¿™ä¸ªå…·å¤‡è®°å¿†åŠŸèƒ½çš„å·¥ä½œæµã€‚

```python
# æ„å»ºå…·å¤‡è®°å¿†åŠŸèƒ½çš„å·¥ä½œæµ
workflow = StateGraph(State)
workflow.add_node("generate_joke", generate_joke)

# è¿æ¥å·¥ä½œæµ
workflow.add_edge(START, "generate_joke")
workflow.add_edge("generate_joke", END)

# åŒæ—¶å¯ç”¨æ£€æŸ¥ç‚¹æœºåˆ¶å’Œè®°å¿†å­˜å‚¨è¿›è¡Œç¼–è¯‘
chain = workflow.compile(checkpointer=checkpointer, store=memory_store)

# ä½¿ç”¨é¦–ä¸ªçº¿ç¨‹æ‰§è¡Œå·¥ä½œæµ
config = {"configurable": {"thread_id": "1"}}
joke_generator_state = chain.invoke({"topic": "cats"}, config)

#### è¾“å‡ºç»“æœ ####
Prior joke: None!
```

æœªæ£€æµ‹åˆ°å…ˆå‰çš„ç¬‘è¯ï¼Œç°åœ¨å¯ä»¥æ‰“å°æœ€æ–°çŠ¶æ€ç»“æ„ã€‚

```python
# è·å–å›¾ç»“æ„çš„æœ€æ–°çŠ¶æ€
latest_state = chain.get_state(config)

console.print("\n[bold magenta]Latest Graph State:[/bold magenta]")
pprint(latest_state)
```

è¾“å‡ºç»“æœï¼š

```text
#### æœ€æ–°çŠ¶æ€è¾“å‡º ####
StateSnapshot(
    values={
        'topic': 'cats',
        'joke': "Here's a new one:\n\nWhy did the cat join a band?\n\nBecause it wanted to be the purr-cussionist!"
    },
    next=(),
    config={
        'configurable': {
            'thread_id': '1',
            'checkpoint_ns': '',
            'checkpoint_id': '1f068357-cc8d-68cb-8001-31f64daf7bb6'
        }
    },
    metadata={'source': 'loop', 'step': 1, 'parents': {}},
    created_at='2025-07-24T02:25:38.457825+00:00',
    parent_config={
        'configurable': {
            'thread_id': '1',
            'checkpoint_ns': '',
            'checkpoint_id': '1f068357-c459-6deb-8000-16ce383a5b6b'
        }
    },
    tasks=(),
    interrupts=()
)
```

æˆ‘ä»¬ä»è®°å¿†ä¸­è·å–å…ˆå‰çš„ç¬‘è¯ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ”¹è¿›ã€‚

```python
# ä½¿ç”¨ç¬¬äºŒä¸ªçº¿ç¨‹æ‰§è¡Œå·¥ä½œæµä»¥éªŒè¯è®°å¿†æŒä¹…æ€§
config = {"configurable": {"thread_id": "2"}}
joke_generator_state = chain.invoke({"topic": "cats"}, config)


#### è¾“å‡ºç»“æœ ####
Prior joke: Here is a new one:
Why did the cat join a band?
Because it wanted to be the purr-cussionist!
```

ç³»ç»Ÿå·²æˆåŠŸ**ä»è®°å¿†ä¸­è·å–æ­£ç¡®çš„ç¬‘è¯**å¹¶æŒ‰è¦æ±‚**å¯¹å…¶è¿›è¡Œäº†æ”¹è¿›**ã€‚

## 7. LangGraphå¤§å·¥å…·è°ƒç”¨ä¼˜åŠ¿

æ™ºèƒ½ä½“ç¾¤ç»„ä¼šä½¿ç”¨å·¥å…·ï¼Œä½†æä¾›è¿‡å¤šå·¥å…·å¯èƒ½å¯¼è‡´æ··æ·†ï¼Œå°¤å…¶åœ¨å·¥å…·æè¿°å­˜åœ¨é‡å æ—¶ã€‚è¿™ä¼šå¢åŠ æ¨¡å‹é€‰æ‹©æ­£ç¡®å·¥å…·çš„éš¾åº¦ã€‚

è§£å†³æ–¹æ¡ˆæ˜¯é‡‡ç”¨RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æŠ€æœ¯ï¼Œé€šè¿‡å·¥å…·æè¿°çš„è¯­ä¹‰ç›¸ä¼¼åº¦ç­›é€‰æœ€ç›¸å…³å·¥å…·â€”â€”è¿™ç§æ–¹æ³•è¢«Drew Breunigç§°ä¸º[å·¥å…·è´Ÿè½½æ–¹æ¡ˆ](https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html) ã€‚

> æ ¹æ®[æœ€æ–°ç ”ç©¶](https://arxiv.org/abs/2505.03275) ï¼Œè¯¥æ–¹æ³•å°†å·¥å…·é€‰æ‹©å‡†ç¡®ç‡æœ€é«˜æå‡è‡³3å€ã€‚

åœ¨å·¥å…·é€‰æ‹©æ–¹é¢ï¼Œ[LangGraph Bigtool](https://github.com/langchain-ai/langgraph-bigtool) åº“æ˜¯æœ€ä½³æ–¹æ¡ˆã€‚å®ƒé€šè¿‡å¯¹å·¥å…·æè¿°è¿›è¡Œè¯­ä¹‰ç›¸ä¼¼æ€§æœç´¢ï¼Œä¸ºä»»åŠ¡ç­›é€‰æœ€ç›¸å…³çš„å·¥å…·ã€‚è¯¥åº“åˆ©ç”¨LangGraphçš„é•¿æœŸè®°å¿†å­˜å‚¨æœºåˆ¶ï¼Œä½¿æ™ºèƒ½ä½“ç¾¤ç»„èƒ½å¤Ÿæœç´¢å¹¶æ£€ç´¢é€‚ç”¨äºç‰¹å®šé—®é¢˜çš„å·¥å…·ã€‚

è®©æˆ‘ä»¬é€šè¿‡è°ƒç”¨Pythonå†…ç½®æ•°å­¦åº“çš„å…¨éƒ¨å‡½æ•°æ¥ç†è§£`langgraph-bigtool`çš„å·¥ä½œæœºåˆ¶ã€‚

```python
import math

# æ”¶é›†`math`å†…ç½®åº“çš„å‡½æ•°
all_tools = []
for function_name in dir(math):
    function = getattr(math, function_name)
    if not isinstance(
        function, types.BuiltinFunctionType
    ):
        continue
    # è¿™æ˜¯`math`åº“çš„ç‰¹æ®Šè®¾è®¡
    if tool := convert_positional_only_function_to_tool(
        function
    ):
        all_tools.append(tool)
```

é¦–å…ˆå°†Pythonæ•°å­¦æ¨¡å—çš„æ‰€æœ‰å‡½æ•°æ·»åŠ è‡³åˆ—è¡¨ã€‚æ¥ä¸‹æ¥éœ€å°†è¿™äº›å·¥å…·æè¿°è½¬åŒ–ä¸ºå‘é‡åµŒå…¥ï¼Œä»¥ä¾¿æ™ºèƒ½ä½“æ‰§è¡Œè¯­ä¹‰ç›¸ä¼¼æ€§æœç´¢ã€‚

æˆ‘ä»¬å°†é‡‡ç”¨åµŒå…¥æ¨¡å‹å®ç°æ­¤åŠŸèƒ½â€”â€”æœ¬æ¡ˆä¾‹ä½¿ç”¨OpenAIæ–‡æœ¬åµŒå…¥æ¨¡å‹ã€‚

```python
# åˆ›å»ºå·¥å…·æ³¨å†Œè¡¨ï¼ˆå­—å…¸ç»“æ„
# ç”¨äºå°†æ ‡è¯†ç¬¦æ˜ å°„åˆ°å·¥å…·å®ä¾‹ï¼‰
tool_registry = {
    str(uuid.uuid4()): tool
    for tool in all_tools
}

# åœ¨LangGraphå­˜å‚¨ä¸­å»ºç«‹å·¥å…·åç§°ä¸æè¿°çš„ç´¢å¼•
# æ­¤å¤„ä½¿ç”¨ç®€æ˜“å†…å­˜å­˜å‚¨
embeddings = init_embeddings("openai:text-embedding-3-small")

store = InMemoryStore(
    index={
        "embed": embeddings,
        "dims": 1536,
        "fields": ["description"],
    }
)
for tool_id, tool in tool_registry.items():
    store.put(
        ("tools",),
        tool_id,
        {
            "description": f"{tool.name}: {tool.description}",
        },
    )
```

æ¯ä¸ªå‡½æ•°è¢«åˆ†é…å”¯ä¸€IDï¼Œå¹¶æŒ‰æ ‡å‡†åŒ–æ ¼å¼è¿›è¡Œç»“æ„åŒ–å¤„ç†è¿™ç§ç»“æ„åŒ–æ ¼å¼ç¡®ä¿å‡½æ•°å¯è½»æ¾è½¬æ¢ä¸ºåµŒå…¥å‘é‡ï¼Œä»¥æ”¯æŒè¯­ä¹‰æœç´¢

ç°åœ¨å¯è§†åŒ–æ™ºèƒ½ä½“ï¼Œè§‚å¯Ÿæ‰€æœ‰æ•°å­¦å‡½æ•°åµŒå…¥åå‡†å¤‡å°±ç»ªçš„è¯­ä¹‰æœç´¢å½¢æ€ï¼

```python
# åˆå§‹åŒ–æ™ºèƒ½ä½“
builder = create_agent(llm, tool_registry)
agent = builder.compile(store=store)
agent
```

![æˆ‘ä»¬çš„å·¥å…·æ™ºèƒ½ä½“](https://cdn-images-1.medium.com/max/1000/1*7uXCS9bgbNCwxB-6t6ZXOw.png)

ç°åœ¨å¯é€šè¿‡ç®€å•æŸ¥è¯¢è°ƒç”¨æ™ºèƒ½ä½“ï¼Œè§‚å¯Ÿå·¥å…·è°ƒç”¨æ™ºèƒ½ä½“å¦‚ä½•é€‰æ‹©å¹¶è¿ç”¨æœ€ç›¸å…³çš„æ•°å­¦å‡½æ•°è§£ç­”é—®é¢˜

```python
# å¯¼å…¥ç”¨äºæ ¼å¼åŒ–ä¸æ˜¾ç¤ºæ¶ˆæ¯çš„å®ç”¨å‡½æ•°
from utils import format_messages

# å®šä¹‰æ™ºèƒ½ä½“æŸ¥è¯¢æŒ‡ä»¤
# è¯¥æŒ‡ä»¤è¦æ±‚æ™ºèƒ½ä½“ä½¿ç”¨æ•°å­¦å·¥å…·æ±‚è§£åä½™å¼¦å€¼
query = "Use available tools to calculate arc cosine of 0.5."

# ä½¿ç”¨æŸ¥è¯¢è°ƒç”¨æ™ºèƒ½ä½“æ™ºèƒ½ä½“å°†æœç´¢å…¶å·¥å…·åº“ï¼Œ
# æ ¹æ®æŸ¥è¯¢è¯­ä¹‰é€‰æ‹©'acos'å·¥å…·å¹¶æ‰§è¡Œ
result = agent.invoke({"messages": query})

# æ ¼å¼åŒ–å¹¶å±•ç¤ºæ™ºèƒ½ä½“æ‰§è¡Œåçš„æœ€ç»ˆæ¶ˆæ¯
format_messages(result['messages'])
```

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Human   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Use available tools to calculate     â”‚
â”‚ arc cosine of 0.5.                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“ AI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ I will search for a tool to calculateâ”‚
â”‚ the arc cosine of 0.5.               â”‚
â”‚                                      â”‚
â”‚ ğŸ”§ Tool Call: retrieve_tools         â”‚
â”‚ Args: {                              â”‚
â”‚   "query": "arc cosine arccos        â”‚
â”‚            inverse cosine trig"      â”‚
â”‚ }                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”§ Tool Output â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Available tools: ['acos', 'acosh']   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“ AI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Perfect! I found the `acos` function â”‚
â”‚ which calculates the arc cosine.     â”‚
â”‚ Now I will use it to calculate the   â”‚
â”‚ arc                                  â”‚
â”‚ cosine of 0.5.                       â”‚
â”‚                                      â”‚
â”‚ ğŸ”§ Tool Call: acos                   â”‚
â”‚ Args: { "x": 0.5 }                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”§ Tool Output â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1.0471975511965976                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“ AI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ The arc cosine of 0.5 is â‰ˆ**1.047**  â”‚
â”‚ radians.                             â”‚
â”‚                                      â”‚
â”‚ âœ” Check: cos(Ï€/3)=0.5, Ï€/3â‰ˆ1.047 rad â”‚
â”‚ (60Â°).                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

å¯è§æˆ‘ä»¬çš„äººå·¥æ™ºèƒ½æ™ºèƒ½ä½“èƒ½é«˜æ•ˆè°ƒç”¨æ­£ç¡®å·¥å…·æ‰©å±•é˜…è¯»èµ„æºï¼š

* [**Toolshed**](https://arxiv.org/abs/2410.14594) æå‡ºToolshedçŸ¥è¯†åº“ä¸é«˜çº§RAG-å·¥å…·èåˆæŠ€æœ¯ï¼Œä¼˜åŒ–AIæ™ºèƒ½ä½“çš„å·¥å…·é€‰æ‹©èƒ½åŠ›
* [**å›¾RAG-å·¥å…·èåˆ**](https://arxiv.org/abs/2502.07223) ç»“åˆå‘é‡æ£€ç´¢ä¸å›¾éå†æŠ€æœ¯ï¼Œæ•æ‰å·¥å…·é—´ä¾èµ–å…³ç³»
* [**LLMå·¥å…·ç»¼è¿°**](https://github.com/quchangle1/LLM-Tool-Survey) å¤§è¯­è¨€æ¨¡å‹å·¥å…·å­¦ä¹ ç»¼åˆç ”ç©¶
* [**ToolRet**](https://arxiv.org/abs/2503.01763) å¤§è¯­è¨€æ¨¡å‹å·¥å…·æ£€ç´¢èƒ½åŠ›è¯„ä¼°ä¸æ”¹è¿›åŸºå‡†

## 8. åŸºäºä¸Šä¸‹æ–‡å·¥ç¨‹çš„RAGç³»ç»Ÿ

[RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰](https://github.com/langchain-ai/rag-from-scratch) æ˜¯ä¸€ä¸ªå¹¿æ³›çš„ç ”ç©¶é¢†åŸŸï¼Œè€Œä»£ç æ™ºèƒ½ä½“æ­£æ˜¯ç”Ÿäº§ç¯å¢ƒä¸­æ™ºèƒ½ä½“å¼RAGçš„æœ€ä½³å®è·µèŒƒä¾‹ã€‚

åœ¨å®é™…åº”ç”¨ä¸­ï¼ŒRAGå¾€å¾€æ˜¯ä¸Šä¸‹æ–‡å·¥ç¨‹çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚æ­£å¦‚[é£å¸†å†²æµªå…¬å¸çš„Varun](https://x.com/_mohansolo/status/1899630246862966837) æ‰€æŒ‡å‡ºçš„ï¼š
> ç´¢å¼• â‰  ä¸Šä¸‹æ–‡æ£€ç´¢ã€‚åŸºäºASTåˆ†å—çš„åµŒå…¥æœç´¢è™½ç„¶æœ‰æ•ˆï¼Œä½†éšç€ä»£ç åº“è§„æ¨¡æ‰©å¤§ä¼šé€æ¸å¤±æ•ˆã€‚æˆ‘ä»¬éœ€è¦æ··åˆæ£€ç´¢æ–¹æ¡ˆï¼šgrep/æ–‡ä»¶æœç´¢ã€çŸ¥è¯†å›¾è°±é“¾æ¥ä»¥åŠåŸºäºç›¸å…³æ€§çš„é‡æ’åºã€‚

LangGraphæä¾›[æ•™ç¨‹ä¸è§†é¢‘](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/) æŒ‡å¯¼å¦‚ä½•å°†RAGé›†æˆè‡³æ™ºèƒ½ä½“ç³»ç»Ÿã€‚é€šå¸¸éœ€è¦æ„å»ºä¸€ä¸ªèƒ½ç»¼åˆè¿ç”¨ä¸Šè¿°RAGæŠ€æœ¯çš„æ£€ç´¢å·¥å…·ã€‚

ä¸ºä½œæ¼”ç¤ºï¼Œæˆ‘ä»¬å°†ä»Lilian Wengçš„ä¼˜ç§€åšå®¢ä¸­é€‰å–æœ€è¿‘ä¸‰ç¯‡æ–‡ç« ä½œä¸ºRAGç³»ç»Ÿçš„æ–‡æ¡£æ¥æºã€‚

æˆ‘ä»¬å°†é¦–å…ˆä½¿ç”¨`WebBaseLoader`å·¥å…·æå–é¡µé¢å†…å®¹ã€‚

```python
# å¯¼å…¥WebBaseLoaderï¼Œç”¨äºä»URLè·å–æ–‡æ¡£
from langchain_community.document_loaders import WebBaseLoader

# å®šä¹‰Lilian Wengåšå®¢æ–‡ç« çš„URLåˆ—è¡¨
urls = [
    "https://lilianweng.github.io/posts/2025-05-01-thinking/",
    "https://lilianweng.github.io/posts/2024-11-28-reward-hacking/",
    "https://lilianweng.github.io/posts/2024-07-07-hallucination/",
    "https://lilianweng.github.io/posts/2024-04-12-diffusion-video/",
]

# é€šè¿‡åˆ—è¡¨æ¨å¯¼å¼ä»æŒ‡å®šURLåŠ è½½æ–‡æ¡£
# æ­¤æ“ä½œä¸ºæ¯ä¸ªURLåˆ›å»ºWebBaseLoaderå®ä¾‹å¹¶è°ƒç”¨å…¶load()æ–¹æ³•
docs = [WebBaseLoader(url).load() for url in urls]
```

RAGå­˜åœ¨å¤šç§æ•°æ®åˆ†å—æ–¹å¼ï¼Œæ­£ç¡®çš„åˆ†å—å¤„ç†å¯¹é«˜æ•ˆæ£€ç´¢è‡³å…³é‡è¦ã€‚

åœ¨å°†è·å–çš„æ–‡æ¡£ç´¢å¼•åˆ°å‘é‡åº“ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶åˆ†å‰²ä¸ºæ›´å°çš„æ–‡æœ¬å—ã€‚æˆ‘ä»¬å°†é‡‡ç”¨ç®€å•ç›´æ¥çš„æ–¹æ³•ï¼ˆå¦‚å¸¦é‡å ç‰‡æ®µçš„é€’å½’åˆ†å—ï¼‰ï¼Œåœ¨ä¿æŒåˆ†å—é€‚ç”¨äºåµŒå…¥å’Œæ£€ç´¢çš„åŒæ—¶ï¼Œç¡®ä¿è·¨æ–‡æœ¬å—çš„ä¸Šä¸‹æ–‡è¿è´¯æ€§ã€‚

```python
# å¯¼å…¥ç”¨äºæ–‡æ¡£åˆ†å—çš„æ–‡æœ¬åˆ†å‰²å™¨
from langchain_text_splitters import RecursiveCharacterTextSplitter

# å°†æ–‡æ¡£åˆ—è¡¨æ‰å¹³åŒ–å¤„ç†WebBaseLoaderä¸ºæ¯ä¸ªURLè¿”å›æ–‡æ¡£åˆ—è¡¨ï¼Œ
# å› æ­¤æˆ‘ä»¬å¾—åˆ°çš„æ˜¯åµŒå¥—åˆ—è¡¨ç»“æ„è¯¥æ¨å¯¼å¼å°†æ‰€æœ‰æ–‡æ¡£åˆå¹¶ä¸ºå•ä¸€åˆ—è¡¨
docs_list = [item for sublist in docs for item in sublist]

# åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨æ­¤æ“ä½œå°†æ–‡æ¡£åˆ†å‰²æˆæ›´å°çš„æ–‡æœ¬å—
# æŒ‰æŒ‡å®šå¤§å°åˆ†å‰²æ–‡æœ¬å—ï¼Œåˆ†å—é—´ä¿ç•™éƒ¨åˆ†é‡å ä»¥ç»´æŒä¸Šä¸‹æ–‡è¿è´¯æ€§ã€‚
text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
    chunk_size=2000, chunk_overlap=50
)

# å°†æ–‡æ¡£åˆ†å‰²æˆæ–‡æœ¬å—
doc_splits = text_splitter.split_documents(docs_list)
```

å®Œæˆæ–‡æ¡£åˆ†å‰²åï¼Œæˆ‘ä»¬å¯å°†å…¶ç´¢å¼•åˆ°å‘é‡å­˜å‚¨ä¸­ï¼Œç”¨äºåç»­è¯­ä¹‰æœç´¢ã€‚

```python
# å¯¼å…¥åˆ›å»ºå†…å­˜å‘é‡å­˜å‚¨æ‰€éœ€çš„ç±»
from langchain_core.vectorstores import InMemoryVectorStore

# åŸºäºæ–‡æ¡£åˆ†å‰²å—åˆ›å»ºå†…å­˜å‘é‡å­˜å‚¨
# ä½¿ç”¨å‰æ–‡ç”Ÿæˆçš„'doc_splits'å’Œå·²åˆå§‹åŒ–çš„'embeddings'æ¨¡å‹ï¼Œä¸ºæ–‡æœ¬å—åˆ›å»ºå‘é‡è¡¨ç¤º
# é€šè¿‡æ–‡æœ¬å—ç”Ÿæˆå‘é‡åŒ–è¡¨å¾
vectorstore = InMemoryVectorStore.from_documents(
    documents=doc_splits, embedding=embeddings
)

# ä»å‘é‡å­˜å‚¨åˆ›å»ºæ£€ç´¢å™¨
# è¯¥æ£€ç´¢å™¨æä¾›åŸºäºæŸ¥è¯¢æœç´¢ç›¸å…³æ–‡æ¡£çš„æ¥å£
# ç”¨äºæ‰§è¡Œæ–‡æ¡£æ£€ç´¢æ“ä½œ
retriever = vectorstore.as_retriever()
```

éœ€åˆ›å»ºå¯åœ¨æ™ºèƒ½ä½“ä¸­ä½¿ç”¨çš„æ£€ç´¢å™¨å·¥å…·

```python
# å¯¼å…¥åˆ›å»ºæ£€ç´¢å™¨å·¥å…·çš„å‡½æ•°
from langchain.tools.retriever import create_retriever_tool

# åŸºäºå‘é‡å­˜å‚¨æ£€ç´¢å™¨åˆ›å»ºå·¥å…·
# æ­¤å·¥å…·å…è®¸æ™ºèƒ½ä½“æ ¹æ®æŸ¥è¯¢
# ä»åšå®¢æ–‡æ¡£ä¸­æœç´¢å¹¶æ£€ç´¢ç›¸å…³å†…å®¹
retriever_tool = create_retriever_tool(
    retriever,
    "retrieve_blog_posts",
    "Search and return information about Lilian Weng blog posts.",
)

# ä»¥ä¸‹ä»£ç è¡Œå±•ç¤ºç›´æ¥è°ƒç”¨è¯¥å·¥å…·çš„ç¤ºä¾‹
# æ­¤è¡Œè¢«æ³¨é‡Šæ‰ï¼Œå› å…¶éæ™ºèƒ½ä½“æ‰§è¡Œæµç¨‹å¿…éœ€ï¼Œä½†å¯ç”¨äºæµ‹è¯•éªŒè¯ã€‚
# retriever_tool.invoke({"query": "types of reward hacking"})
```

ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥å®ç°ä¸€ä¸ªèƒ½å¤Ÿä»å·¥å…·ä¸­é€‰æ‹©ä¸Šä¸‹æ–‡çš„æ™ºèƒ½ä½“ã€‚

```python
# é€šè¿‡å·¥å…·å¢å¼ºå¤§è¯­è¨€æ¨¡å‹èƒ½åŠ›
tools = [retriever_tool]
tools_by_name = {tool.name: tool for tool in tools}
llm_with_tools = llm.bind_tools(tools)
```

å¯¹äºåŸºäºRAGçš„è§£å†³æ–¹æ¡ˆï¼Œéœ€åˆ›å»ºæ¸…æ™°çš„ç³»ç»Ÿæç¤ºä»¥æŒ‡å¯¼æ™ºèƒ½ä½“è¡Œä¸ºã€‚è¯¥æç¤ºæ„æˆå…¶æ ¸å¿ƒæŒ‡ä»¤é›†ã€‚

```python
from langgraph.graph import MessagesState
from langchain_core.messages import SystemMessage, ToolMessage
from typing_extensions import Literal

rag_prompt = """You are a helpful assistant tasked with retrieving information from a series of technical blog posts by Lilian Weng. 
Clarify the scope of research with the user before using your retrieval tool to gather context. Reflect on any context you fetch, and
proceed until you have sufficient context to answer the user's research request."""
```

æ¥ä¸‹æ¥å®šä¹‰å›¾ç»“æ„çš„èŠ‚ç‚¹ã€‚æˆ‘ä»¬éœ€è¦ä¸¤ä¸ªä¸»èŠ‚ç‚¹ï¼š

1. `llm_call`ï¼šæ™ºèƒ½ä½“çš„æ ¸å¿ƒå†³ç­–ä¸­æ¢æ¥æ”¶å½“å‰å¯¹è¯å†å²ï¼ˆç”¨æˆ·æŸ¥è¯¢+å…ˆå‰å·¥å…·è¾“å‡ºï¼‰æ®æ­¤å†³ç­–ä¸‹ä¸€æ­¥åŠ¨ä½œï¼šè°ƒç”¨å·¥å…·æˆ–ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
2. `tool_node`ï¼šæ™ºèƒ½ä½“çš„æ‰§è¡Œç»„ä»¶æ‰§è¡Œç”±`llm_call`å‘èµ·çš„å·¥å…·è°ƒç”¨æŒ‡ä»¤å°†å·¥å…·æ‰§è¡Œç»“æœè¿”å›ç»™æ™ºèƒ½ä½“

```python
# --- å®šä¹‰æ™ºèƒ½ä½“èŠ‚ç‚¹ ---

def llm_call(state: MessagesState):
    """LLM decides whether to call a tool or generate a final answer."""
    # å°†ç³»ç»Ÿæç¤ºåŠ å…¥å½“å‰æ¶ˆæ¯çŠ¶æ€
    messages_with_prompt = [SystemMessage(content=rag_prompt)] + state["messages"]
    
    # ä½¿ç”¨å¢å¼ºåçš„æ¶ˆæ¯åˆ—è¡¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹
    response = llm_with_tools.invoke(messages_with_prompt)
    
    # è¿”å›å¤§è¯­è¨€æ¨¡å‹çš„å“åº”ï¼Œè¯¥å“åº”å°†è¢«æ·»åŠ åˆ°çŠ¶æ€ä¸­
    return {"messages": [response]}
    
def tool_node(state: dict):
    """Performs the tool call and returns the observation."""
    # è·å–æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆåº”åŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼‰
    last_message = state["messages"][-1]
    
    # æ‰§è¡Œæ¯ä¸ªå·¥å…·è°ƒç”¨å¹¶æ”¶é›†ç»“æœ
    result = []
    for tool_call in last_message.tool_calls:
        tool = tools_by_name[tool_call["name"]]
        observation = tool.invoke(tool_call["args"])
        result.append(ToolMessage(content=str(observation), tool_call_id=tool_call["id"]))
        
    # å°†å·¥å…·è¾“å‡ºä½œä¸ºæ¶ˆæ¯è¿”å›
    return {"messages": result}
```

éœ€è¦ä¸€ç§æœºåˆ¶æ¥æ§åˆ¶æ™ºèƒ½ä½“æµç¨‹ï¼Œå†³å®šå…¶åº”è°ƒç”¨å·¥å…·è¿˜æ˜¯ç»“æŸè¿è¡Œã€‚

ä¸ºæ­¤æˆ‘ä»¬å°†åˆ›å»ºåä¸º `should_continue` çš„æ¡ä»¶è¾¹å‡½æ•°ã€‚

* è¯¥å‡½æ•°æ£€æŸ¥å¤§è¯­è¨€æ¨¡å‹æœ€åè¿”å›çš„æ¶ˆæ¯æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨ã€‚
* è‹¥å­˜åœ¨å·¥å…·è°ƒç”¨ï¼Œæµç¨‹å›¾å°†è·¯ç”±è‡³ `tool_node` èŠ‚ç‚¹
* å¦åˆ™ç»ˆæ­¢æ‰§è¡Œæµç¨‹

```python
# --- å®šä¹‰æ¡ä»¶è¾¹ ---

def should_continue(state: MessagesState) -> Literal["Action", END]:
    """Decides the next step based on whether the LLM made a tool call."""
    last_message = state["messages"][-1]
    
    # è‹¥å¤§è¯­è¨€æ¨¡å‹å‘èµ·å·¥å…·è°ƒç”¨ï¼Œåˆ™è·¯ç”±è‡³å·¥å…·èŠ‚ç‚¹
    if last_message.tool_calls:
        return "Action"
    # å¦åˆ™ç»“æŸå·¥ä½œæµ
    return END
```

ç°åœ¨å³å¯æ„å»ºå·¥ä½œæµå¹¶ç¼–è¯‘æµç¨‹å›¾

```python
# æ„å»ºå·¥ä½œæµ
agent_builder = StateGraph(MessagesState)

# æ·»åŠ èŠ‚ç‚¹
agent_builder.add_node("llm_call", llm_call)
agent_builder.add_node("environment", tool_node)

# æ·»åŠ è¿æ¥èŠ‚ç‚¹çš„è¾¹
agent_builder.add_edge(START, "llm_call")
agent_builder.add_conditional_edges(
    "llm_call",
    should_continue,
    {
        # should_continueè¿”å›çš„åç§° : è¦è®¿é—®çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°
        "Action": "environment",
        END: END,
    },
)
agent_builder.add_edge("environment", "llm_call")

# ç¼–è¯‘æ™ºèƒ½ä½“
agent = agent_builder.compile()

# æ˜¾ç¤ºæ™ºèƒ½ä½“
display(Image(agent.get_graph(xray=True).draw_mermaid_png()))
```

![åŸºäºRAGçš„æ™ºèƒ½ä½“](https://cdn-images-1.medium.com/max/1000/1*0QxVbzakDabkoMfgURIx2w.png)

è¯¥æµç¨‹å›¾å‘ˆç°æ¸…æ™°å¾ªç¯ï¼š

1. æ™ºèƒ½ä½“å¯åŠ¨åè°ƒç”¨LLM
2. æ ¹æ®LLMå†³ç­–ï¼Œæ‰§è¡Œæ“ä½œï¼ˆè°ƒç”¨æ£€ç´¢å™¨å·¥å…·ï¼‰å¹¶å¾ªç¯å›é€€ï¼Œæˆ–å®Œæˆå¤„ç†è¿”å›ç­”æ¡ˆ

ç°åœ¨æµ‹è¯•RAGæ™ºèƒ½ä½“æˆ‘ä»¬å°†æå‡ºå…³äº**å¥–åŠ±é»‘å®¢æ”»å‡»**çš„å…·ä½“é—®é¢˜ï¼Œè¯¥é—®é¢˜åªèƒ½é€šè¿‡æ£€ç´¢å·²ç´¢å¼•åšå®¢å†…å®¹è·å–ç­”æ¡ˆ

```python
# å®šä¹‰ç”¨æˆ·æŸ¥è¯¢
query = "What are the types of reward hacking discussed in the blogs?"

# é€šè¿‡æŸ¥è¯¢è°ƒç”¨æ™ºèƒ½ä½“
result = agent.invoke({"messages": [("user", query)]})

# --- æ˜¾ç¤ºæœ€ç»ˆæ¶ˆæ¯ ---
# æ ¼å¼åŒ–è¾“å‡ºå¯¹è¯æµç¨‹
format_messages(result['messages'])
```

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Human  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Clarify scope: I want types of       â”‚
â”‚ reward hacking from Lilian Wengâ€™s    â”‚
â”‚ blog on RL.                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“ AI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Fetching context from her posts...   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”§ Tool Output â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ She lists 3 main types of reward     â”‚
â”‚ hacking in RL:                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“ AI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. **Spec gaming** â€“ Exploit reward  â”‚
â”‚    loopholes, not real goal.         â”‚
â”‚                                      â”‚
â”‚ 2. **Reward tampering** â€“ Change or  â”‚
â”‚    hack reward signals.              â”‚
â”‚                                      â”‚
â”‚ 3. **Wireheading** â€“ Self-stimulate  â”‚
â”‚    reward instead of task.           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“ AI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ These can cause harmful, unintended  â”‚
â”‚ behaviors in RL agents.              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

å¯è§æ™ºèƒ½ä½“æ­£ç¡®è¯†åˆ«äº†éœ€ä½¿ç”¨æ£€ç´¢å·¥å…·çš„éœ€æ±‚éšåæˆåŠŸä»åšå®¢ä¸­æ£€ç´¢åˆ°ç›¸å…³ä¸Šä¸‹æ–‡ï¼Œå¹¶åˆ©ç”¨è¯¥ä¿¡æ¯æä¾›äº†è¯¦å°½å‡†ç¡®çš„ç­”æ¡ˆ

> è¿™å®Œç¾å±•ç¤ºäº†å¦‚ä½•é€šè¿‡RAGå®æ–½ä¸Šä¸‹æ–‡å·¥ç¨‹æ¥æ„å»ºåŠŸèƒ½å¼ºå¤§ã€çŸ¥è¯†æ¸Šåšçš„æ™ºèƒ½ä½“ç¾¤ç»„ã€‚

## 9. çŸ¥è¯†å‹æ™ºèƒ½ä½“çš„å‹ç¼©ç­–ç•¥

æ™ºèƒ½ä½“äº¤äº’å¯è·¨è¶Š[æ•°ç™¾è½®æ¬¡](https://www.anthropic.com/engineering/built-multi-agent-research-system) ï¼Œå¹¶æ¶‰åŠé«˜tokenæ¶ˆè€—çš„å·¥å…·è°ƒç”¨ã€‚æ‘˜è¦ç”Ÿæˆæ˜¯ç®¡ç†æ­¤ç±»é—®é¢˜çš„å¸¸ç”¨æ–¹æ³•ã€‚

![ä¸Šä¸‹æ–‡å·¥ç¨‹çš„ç¬¬ä¸‰ç»„ä»¶](https://cdn-images-1.medium.com/max/1000/1*Xu76qgF1u2G3JipeIgHo5Q.png)
*ä¸Šä¸‹æ–‡å·¥ç¨‹çš„ç¬¬ä¸‰ç»„ä»¶ï¼ˆæ‘˜è‡ª[LangChainæ–‡æ¡£](https://blog.langchain.com/context-engineering-for-agents/) ï¼‰*

ä¾‹å¦‚ï¼š

* å½“ä¸Šä¸‹æ–‡çª—å£ä½¿ç”¨ç‡è¶…è¿‡95%æ—¶ï¼ŒClaudeä»£ç é‡‡ç”¨"[è‡ªåŠ¨å‹ç¼©](https://docs.anthropic.com/en/docs/claude-code/costs) "æœºåˆ¶ï¼Œå¯¹å®Œæ•´çš„ç”¨æˆ·-æ™ºèƒ½ä½“äº¤äº’å†å²è¿›è¡Œæ‘˜è¦ç”Ÿæˆã€‚
* é€šè¿‡[é€’å½’æ‘˜è¦](https://arxiv.org/pdf/2308.15022#:~:text=the%20retrieved%20utterances%20capture%20the,based%203) æˆ–[åˆ†å±‚æ‘˜è¦](https://alignment.anthropic.com/2025/summarization-for-monitoring/#:~:text=We%20addressed%20these%20issues%20by,of%20our%20computer%20use%20capability) ç­‰ç­–ç•¥ï¼Œå¯å‹ç¼©[æ™ºèƒ½ä½“è½¨è¿¹](https://langchain-ai.github.io/langgraph/concepts/memory/#manage-short-term-memory) æ•°æ®ã€‚

æ‚¨ä¹Ÿå¯ä»¥åœ¨ç‰¹å®šèŠ‚ç‚¹æ·»åŠ æ‘˜è¦ç”ŸæˆåŠŸèƒ½ï¼š

* åœ¨ä»¤ç‰Œå¯†é›†å‹å·¥å…·è°ƒç”¨åï¼ˆä¾‹å¦‚æœç´¢å·¥å…·ï¼‰[ç¤ºä¾‹è§æ­¤](https://github.com/langchain-ai/open_deep_research/blob/e5a5160a398a3699857d00d8569cb7fd0ac48a4f/src/open_deep_research/utils.py#L1407) ã€‚
* åœ¨æ™ºèƒ½ä½“é—´è¾¹ç•Œè¿›è¡ŒçŸ¥è¯†ä¼ é€’æ—¶ï¼Œ[Cognition](https://cognition.ai/blog/dont-build-multi-agents#a-theory-of-building-long-running-agents) åœ¨Devinä¸­é€šè¿‡å¾®è°ƒæ¨¡å‹å®ç°äº†è¯¥åŠŸèƒ½ã€‚

![LangGraphæ‘˜è¦ç”Ÿæˆæ–¹æ³•ç¤ºæ„å›¾](https://cdn-images-1.medium.com/max/1500/1*y5AhaYoM_XDDrvlAnnFhcQ.png)
*LangGraphæ‘˜è¦ç”Ÿæˆæ–¹æ³•ï¼ˆæ‘˜è‡ª[LangChainæ–‡æ¡£](https://blog.langchain.com/context-engineering-for-agents/) ï¼‰*

LangGraphæ˜¯ä¸€ä¸ª[åº•å±‚ç¼–æ’æ¡†æ¶](https://blog.langchain.com/how-to-think-about-agent-frameworks/) ï¼Œä¸ºæ‚¨æä¾›ä»¥ä¸‹æ–¹é¢çš„å®Œå…¨æ§åˆ¶æƒï¼š

* å°†æ™ºèƒ½ä½“è®¾è®¡ä¸ºä¸€ç»„[èŠ‚ç‚¹](https://www.youtube.com/watch?v=aHCDrAbH_go) ã€‚
* åœ¨æ¯ä¸ªèŠ‚ç‚¹å†…æ˜ç¡®å®šä¹‰é€»è¾‘ã€‚
* åœ¨èŠ‚ç‚¹é—´ä¼ é€’å…±äº«çŠ¶æ€å¯¹è±¡ã€‚

è¿™ä½¿å¾—é€šè¿‡ä¸åŒæ–¹å¼å‹ç¼©ä¸Šä¸‹æ–‡å˜å¾—ç®€å•ã€‚ä¾‹å¦‚æ‚¨å¯ä»¥ï¼š

* ä½¿ç”¨æ¶ˆæ¯åˆ—è¡¨ä½œä¸ºæ™ºèƒ½ä½“çŠ¶æ€ã€‚
* é€šè¿‡[å†…ç½®å®ç”¨å·¥å…·](https://langchain-ai.github.io/langgraph/how-tos/memory/add-memory/#manage-short-term-memory) è¿›è¡Œæ‘˜è¦ç”Ÿæˆã€‚

æˆ‘ä»¬å°†æ²¿ç”¨å…ˆå‰ç¼–å†™çš„åŸºäºRAGçš„å·¥å…·è°ƒç”¨æ™ºèƒ½ä½“ï¼Œå¹¶å¢åŠ å¯¹è¯å†å²çš„æ‘˜è¦åŠŸèƒ½ã€‚

é¦–å…ˆéœ€è¦æ‰©å±•å›¾çš„çŠ¶æ€ï¼Œæ·»åŠ ç”¨äºå­˜å‚¨æœ€ç»ˆæ‘˜è¦çš„å­—æ®µã€‚

```python
# å®šä¹‰åŒ…å«æ‘˜è¦å­—æ®µçš„æ‰©å±•çŠ¶æ€
class State(MessagesState):
    """Extended state that includes a summary field for context compression."""
    summary: str
```

æ¥ä¸‹æ¥å®šä¹‰ä¸“ç”¨çš„æ‘˜è¦ç”Ÿæˆæç¤ºè¯ï¼ŒåŒæ—¶ä¿ç•™ä¹‹å‰çš„RAGæç¤ºè¯ã€‚

```python
# å®šä¹‰æ‘˜è¦ç”Ÿæˆæç¤ºè¯
summarization_prompt = """Summarize the full chat history and all tool feedback to 
give an overview of what the user asked about and what the agent did."""
```

ç°åœ¨åˆ›å»º`æ‘˜è¦èŠ‚ç‚¹`ã€‚

* è¯¥èŠ‚ç‚¹å°†åœ¨æ™ºèƒ½ä½“å·¥ä½œç»“æŸæ—¶è§¦å‘ï¼Œç”Ÿæˆæ•´ä¸ªäº¤äº’è¿‡ç¨‹çš„ç®€æ˜æ‘˜è¦ã€‚
* `llm_call` ä¸ `tool_node` ä¿æŒä¸å˜ã€‚

```python
def summary_node(state: MessagesState) -> dict:
    """
    Generate a summary of the conversation and tool interactions.

    Args:
        state: The current state of the graph, containing the message history.

    Returns:
        A dictionary with the key "summary" and the generated summary string
        as the value, which updates the state.
    """
    # å°†æ‘˜è¦ç³»ç»Ÿæç¤ºæ·»åŠ åˆ°æ¶ˆæ¯å†å²è®°å½•å¼€å¤´
    messages = [SystemMessage(content=summarization_prompt)] + state["messages"]
    
    # è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆæ‘˜è¦
    result = llm.invoke(messages)
    
    # è¿”å›æ‘˜è¦å†…å®¹å­˜å‚¨è‡³çŠ¶æ€çš„'summary'å­—æ®µ
    return {"summary": result.content}
```

æ¡ä»¶è¾¹ should_continue ç°åœ¨éœ€è¦å†³å®šè°ƒç”¨å·¥å…·è¿˜æ˜¯è·³è½¬è‡³æ–°çš„ summary_nodeã€‚

```python
def should_continue(state: MessagesState) -> Literal["Action", "summary_node"]:
    """Determine next step based on whether LLM made tool calls."""
    last_message = state["messages"][-1]
    
    # è‹¥å¤§è¯­è¨€æ¨¡å‹å‘èµ·å·¥å…·è°ƒç”¨ï¼Œåˆ™æ‰§è¡Œè°ƒç”¨
    if last_message.tool_calls:
        return "Action"
    # å¦åˆ™è¿›è¡Œæ‘˜è¦ç”Ÿæˆ
    return "summary_node"
```

ç°åœ¨æ„å»ºåŒ…å«æœ€ç»ˆæ‘˜è¦æ­¥éª¤çš„æ–°å·¥ä½œæµå›¾ã€‚

```python
# æ„å»º RAG æ™ºèƒ½ä½“å·¥ä½œæµ
agent_builder = StateGraph(State)

# å‘å·¥ä½œæµæ·»åŠ èŠ‚ç‚¹
agent_builder.add_node("llm_call", llm_call)
agent_builder.add_node("Action", tool_node)
agent_builder.add_node("summary_node", summary_node)

# å®šä¹‰å·¥ä½œæµè¾¹
agent_builder.add_edge(START, "llm_call")
agent_builder.add_conditional_edges(
    "llm_call",
    should_continue,
    {
        "Action": "Action",
        "summary_node": "summary_node",
    },
)
agent_builder.add_edge("Action", "llm_call")
agent_builder.add_edge("summary_node", END)

# ç¼–è¯‘æ™ºèƒ½ä½“
agent = agent_builder.compile()

# å±•ç¤ºæ™ºèƒ½ä½“å·¥ä½œæµ
display(Image(agent.get_graph(xray=True).draw_mermaid_png()))
```

![æˆ‘ä»¬åˆ›å»ºçš„æ™ºèƒ½ä½“](https://cdn-images-1.medium.com/max/1000/1*UTtZj95DQ9_0hXb-h2UetQ.png)

ç°åœ¨æ‰§è¡Œéœ€è¦è·å–å¤§é‡ä¸Šä¸‹æ–‡çš„æŸ¥è¯¢æµ‹è¯•ã€‚

```python
from rich.markdown import Markdown

query = "Why does RL improve LLM reasoning according to the blogs?"
result = agent.invoke({"messages": [("user", query)]})

# å‘ç”¨æˆ·è¾“å‡ºæœ€ç»ˆæ¶ˆæ¯
format_message(result['messages'][-1])

# è¾“å‡ºç”Ÿæˆçš„æ‘˜è¦
Markdown(result["summary"])


#### è¾“å‡ºç»“æœ ####
The user asked about why reinforcement learning (RL) improves LLM re...
```

æ•ˆæœä¸é”™ï¼Œä½†æ¶ˆè€—äº†**11.5ä¸‡ä»¤ç‰Œ**ï¼å®Œæ•´æ‰§è¡Œè½¨è¿¹å¯[åœ¨æ­¤æŸ¥çœ‹](https://smith.langchain.com/public/50d70503-1a8e-46c1-bbba-a1efb8626b05/r) ã€‚è¿™æ˜¯å·¥å…·è°ƒç”¨ä»¤ç‰Œæ¶ˆè€—é‡å¤§çš„æ™ºèƒ½ä½“ç¾¤ç»„æ™®éé¢ä¸´çš„æŒ‘æˆ˜ã€‚

æ›´é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆæ˜¯åœ¨ä¸Šä¸‹æ–‡è¿›å…¥æ™ºèƒ½ä½“ä¸»æš‚å­˜åŒº*ä¹‹å‰*è¿›è¡Œå‹ç¼©å¤„ç†ã€‚è®©æˆ‘ä»¬å‡çº§RAGæ™ºèƒ½ä½“ï¼Œå®ç°å·¥å…·è°ƒç”¨è¾“å‡ºçš„å®æ—¶æ‘˜è¦ç”Ÿæˆã€‚

é¦–å…ˆï¼Œé’ˆå¯¹æ­¤ä»»åŠ¡è®¾è®¡æ–°æç¤ºæ¨¡æ¿ï¼š

```python
tool_summarization_prompt = """You will be provided a doc from a RAG system.
Summarize the docs, ensuring to retain all relevant / essential information.
Your goal is simply to reduce the size of the doc (tokens) to a more manageable size."""
```

æ¥ä¸‹æ¥ä¿®æ”¹**å·¥å…·èŠ‚ç‚¹**ï¼Œå°†æ‘˜è¦ç”Ÿæˆæ­¥éª¤æ•´åˆå…¶ä¸­

```python
def tool_node_with_summarization(state: dict):
    """Performs the tool call and then summarizes the output."""
    result = []
    for tool_call in state["messages"][-1].tool_calls:
        tool = tools_by_name[tool_call["name"]]
        observation = tool.invoke(tool_call["args"])
        
        # æ–‡æ¡£æ‘˜è¦ç”Ÿæˆ
        summary_msg = llm.invoke([
            SystemMessage(content=tool_summarization_prompt),
            ("user", str(observation))
        ])
        
        result.append(ToolMessage(content=summary_msg.content, tool_call_id=tool_call["id"]))
    return {"messages": result}
```

ç”±äºä¸å†éœ€è¦æœ€ç»ˆçš„æ‘˜è¦èŠ‚ç‚¹ï¼Œç°åœ¨å¯ç®€åŒ–`åº”ç»§ç»­`åˆ¤å®šé€»è¾‘

```python
def should_continue(state: MessagesState) -> Literal["Action", END]:
    """Decide if we should continue the loop or stop."""
    if state["messages"][-1].tool_calls:
        return "Action"
    return END
```

ç°åœ¨æ„å»ºå¹¶ç¼–è¯‘è¿™ä¸ªé«˜æ•ˆç‰ˆæ™ºèƒ½ä½“ç¨‹åº

```python
# æ„å»ºå·¥ä½œæµ
agent_builder = StateGraph(MessagesState)

# æ·»åŠ èŠ‚ç‚¹
agent_builder.add_node("llm_call", llm_call)
agent_builder.add_node("Action", tool_node_with_summarization)

# æ·»åŠ è¿æ¥èŠ‚ç‚¹çš„è¾¹
agent_builder.add_edge(START, "llm_call")
agent_builder.add_conditional_edges(
    "llm_call",
    should_continue,
    {
        "Action": "Action",
        END: END,
    },
)
agent_builder.add_edge("Action", "llm_call")

# ç¼–è¯‘æ™ºèƒ½ä½“
agent = agent_builder.compile()

# æ˜¾ç¤ºæ™ºèƒ½ä½“
display(Image(agent.get_graph(xray=True).draw_mermaid_png()))
```

![ä¼˜åŒ–åçš„æ™ºèƒ½ä½“æ¶æ„å›¾ç¤º](https://cdn-images-1.medium.com/max/1000/1*FCRrXQxZveaQxyLHf6AROQ.png)

è®©æˆ‘ä»¬æ‰§è¡Œç›¸åŒæŸ¥è¯¢å¹¶è§‚å¯Ÿå·®å¼‚ã€‚

```python
query = "Why does RL improve LLM reasoning according to the blogs?"
result = agent.invoke({"messages": [("user", query)]})
format_messages(result['messages'])
```

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ user â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Why does RL improve LLM reasoning?â”‚
â”‚ According to the blogs?            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“ AI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Searching Lilian Wengâ€™s blog for  â”‚
â”‚ how RL improves LLM reasoning...  â”‚
â”‚                                   â”‚
â”‚ ğŸ”§ Tool Call: retrieve_blog_posts â”‚
â”‚ Args: {                           â”‚
â”‚ "query": "Reinforcement Learning  â”‚
â”‚ for LLM reasoning"                â”‚
â”‚ }                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”§ Tool Output â”€â”€â”€â”€â”€â”
â”‚ Lilian Weng explains RL helps LLM â”‚
â”‚ reasoning by training on rewards  â”‚
â”‚ for each reasoning step (Process- â”‚
â”‚ based Reward Models). This guides â”‚
â”‚ the model to think step-by-step,  â”‚
â”‚ improving coherence and logic.    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“ AI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RL improves LLM reasoning by       â”‚
â”‚ rewarding stepwise thinking via    â”‚
â”‚ PRMs, encouraging coherent,        â”‚
â”‚ logical argumentation over final   â”‚
â”‚ answers. It helps the model self-  â”‚
â”‚ correct and explore better paths.  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> æœ¬æ¬¡æ™ºèƒ½ä½“ä»…æ¶ˆè€—**6ä¸‡ä»¤ç‰Œ**ï¼ŒæŸ¥çœ‹æ­¤å¤„çš„[è¿½è¸ªè®°å½•](https://smith.langchain.com/public/994cdf93-e837-4708-9628-c83b397dd4b5/r) ã€‚

æ­¤ç®€å•æ”¹åŠ¨ä½¿ä»¤ç‰Œæ¶ˆè€—å‡å°‘è¿‘åŠï¼Œæ˜¾è‘—æå‡æ™ºèƒ½ä½“æ•ˆç‡ä¸æˆæœ¬æ•ˆç›Šã€‚

æ‰©å±•é˜…è¯»èµ„æºï¼š

* [**å¯å‘å¼å‹ç¼©ä¸æ¶ˆæ¯è£å‰ª**](https://langchain-ai.github.io/langgraph/how-tos/memory/add-memory/#trim-messages) ï¼šé€šè¿‡è£å‰ªæ¶ˆæ¯é˜²æ­¢ä¸Šä¸‹æ–‡æº¢å‡ºï¼Œå®ç°ä»¤ç‰Œé™é¢ç®¡ç†ã€‚
* [**æ‘˜è¦ç”ŸæˆèŠ‚ç‚¹ä½œä¸ºæ¨¡å‹å‰é’©**](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-manage-message-history/) ï¼šåœ¨ReActæ™ºèƒ½ä½“ä¸­é€šè¿‡æ±‡æ€»å¯¹è¯å†å²æ§åˆ¶ä»¤ç‰Œæ¶ˆè€—ã€‚
* [**LangMemæ‘˜è¦ç”Ÿæˆ**](https://langchain-ai.github.io/langmem/guides/summarization/) ï¼šé‡‡ç”¨æ¶ˆæ¯æ‘˜è¦ä¸åŠ¨æ€æ‘˜è¦ç­–ç•¥å®ç°é•¿ä¸Šä¸‹æ–‡ç®¡ç†ã€‚

## 10. é€šè¿‡å­æ™ºèƒ½ä½“æ¶æ„éš”ç¦»ä¸Šä¸‹æ–‡

éš”ç¦»ä¸Šä¸‹æ–‡çš„å¸¸è§æ–¹æ³•æ˜¯é€šè¿‡å­æ™ºèƒ½ä½“ç¾¤ç»„åˆ†æ‹…ä¸Šä¸‹æ–‡å¤„ç†ã€‚OpenAIçš„[Swarm](https://github.com/openai/swarm) åº“æ­£æ˜¯ä¸ºå®ç°è¿™ç§ã€Œ[å…³æ³¨ç‚¹åˆ†ç¦»](https://openai.github.io/openai-agents-python/ref/agent/) ã€è€Œè®¾è®¡ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“é€šè¿‡ä¸“å±å·¥å…·ã€æŒ‡ä»¤å’Œä¸Šä¸‹æ–‡çª—å£ç®¡ç†ç‰¹å®šå­ä»»åŠ¡ã€‚

![ä¸Šä¸‹æ–‡å·¥ç¨‹ç¬¬å››ç»„ä»¶](https://cdn-images-1.medium.com/max/1000/1*-b9BLPkLHkYsy2iLQIdxUg.png)
*ä¸Šä¸‹æ–‡å·¥ç¨‹ç¬¬å››ç»„ä»¶ï¼ˆæºè‡ª[LangChainæ–‡æ¡£](https://blog.langchain.com/context-engineering-for-agents/) ï¼‰*

Anthropicçš„[å¤šæ™ºèƒ½ä½“ç ”ç©¶ç³»ç»Ÿ](https://www.anthropic.com/engineering/built-multi-agent-research-system) è¡¨æ˜ï¼Œé‡‡ç”¨ç‹¬ç«‹ä¸Šä¸‹æ–‡çš„å¤šæ™ºèƒ½ä½“ç¾¤ç»„ç›¸è¾ƒå•æ™ºèƒ½ä½“æ€§èƒ½æå‡90.2%ï¼Œå› ä¸ºæ¯ä¸ªå­æ™ºèƒ½ä½“èƒ½èšç„¦äºæ›´çª„çš„å­ä»»åŠ¡ã€‚

> *å­æ™ºèƒ½ä½“é€šè¿‡å„è‡ªçš„ä¸Šä¸‹æ–‡çª—å£å¹¶è¡Œè¿ä½œï¼ŒåŒæ—¶æ¢ç´¢é—®é¢˜çš„ä¸åŒç»´åº¦ã€‚*

ç„¶è€Œï¼Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿé¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š

* ä»¤ç‰Œä½¿ç”¨é‡å¤§å¹…å¢åŠ ï¼ˆæœ‰æ—¶è¾¾åˆ°å•æ™ºèƒ½ä½“èŠå¤©çš„15å€ä»¥ä¸Šï¼‰ã€‚
* éœ€è¦ç²¾å¿ƒè®¾è®¡[æç¤ºè¯å·¥ç¨‹](https://www.anthropic.com/engineering/built-multi-agent-research-system) æ¥è§„åˆ’å­æ™ºèƒ½ä½“ä»»åŠ¡ã€‚
* åè°ƒå­æ™ºèƒ½ä½“çš„è¿‡ç¨‹å¯èƒ½éå¸¸å¤æ‚ã€‚

![å¤šæ™ºèƒ½ä½“å¹¶è¡Œå¤„ç†](https://cdn-images-1.medium.com/max/1000/1*N_BT9M5OyYB7UJfDkpcL-g.png)
*å¤šæ™ºèƒ½ä½“å¹¶è¡Œå¤„ç†ï¼ˆæºè‡ª[LangChainæ–‡æ¡£](https://blog.langchain.com/context-engineering-for-agents/) ï¼‰*

LangGraphæ”¯æŒå¤šæ™ºèƒ½ä½“æ¶æ„éƒ¨ç½²ã€‚å¸¸ç”¨æ–¹æ¡ˆæ˜¯é‡‡ç”¨[ç›‘ç£å™¨](https://github.com/langchain-ai/langgraph-supervisor-py) æ¶æ„ï¼Œè¯¥æ–¹æ¡ˆåŒæ ·åº”ç”¨äºAnthropicå¤šæ™ºèƒ½ä½“ç ”ç©¶ç³»ç»Ÿã€‚ç›‘ç£å™¨å°†ä»»åŠ¡å§”æ´¾ç»™å­æ™ºèƒ½ä½“ï¼Œæ¯ä¸ªå­æ™ºèƒ½ä½“åœ¨ç‹¬ç«‹çš„ä¸Šä¸‹æ–‡çª—å£ä¸­è¿è¡Œã€‚

ä¸‹é¢æˆ‘ä»¬æ„å»ºä¸€ä¸ªç®¡ç†ä¸¤ä¸ªæ™ºèƒ½ä½“çš„ç®€æ˜“ç›‘ç£å™¨ï¼š

* `math_expert` å¤„ç†æ•°å­¦è®¡ç®—ä»»åŠ¡ã€‚
* `research_expert` æœç´¢å¹¶æä¾›ç ”ç©¶ä¿¡æ¯ã€‚

ç›‘ç£å™¨å°†æ ¹æ®æŸ¥è¯¢å†…å®¹å†³å®šè°ƒç”¨å“ªä½ä¸“å®¶ï¼Œå¹¶åœ¨LangGraphå·¥ä½œæµä¸­åè°ƒå…¶å“åº”ã€‚

```python
from langgraph.prebuilt import create_react_agent
from langgraph_supervisor import create_supervisor

# --- å®šä¹‰å„æ™ºèƒ½ä½“å·¥å…·é›† ---
def add(a: float, b: float) -> float:
    """Add two numbers."""
    return a + b

def multiply(a: float, b: float) -> float:
    """Multiply two numbers."""
    return a * b

def web_search(query: str) -> str:
    """Mock web search function that returns FAANG company headcounts."""
    return (
        "Here are the headcounts for each of the FAANG companies in 2024:\n"
        "1. **Facebook (Meta)**: 67,317 employees.\n"
        "2. **Apple**: 164,000 employees.\n"
        "3. **Amazon**: 1,551,000 employees.\n"
        "4. **Netflix**: 14,000 employees.\n"
        "5. **Google (Alphabet)**: 181,269 employees."
    )
```

ç°åœ¨æˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸“ä¸šæ™ºèƒ½ä½“åŠå…¶ç®¡ç†ç›‘ç£å™¨ã€‚

```python
# --- åˆ›å»ºå…·æœ‰éš”ç¦»ä¸Šä¸‹æ–‡çš„ä¸“ä¸šæ™ºèƒ½ä½“ ---
math_agent = create_react_agent(
    model=llm,
    tools=[add, multiply],
    name="math_expert",
    prompt="You are a math expert. Always use one tool at a time."
)

research_agent = create_react_agent(
    model=llm,
    tools=[web_search],
    name="research_expert",
    prompt="You are a world class researcher with access to web search. Do not do any math."
)

# --- åˆ›å»ºåè°ƒæ™ºèƒ½ä½“çš„ç›‘ç£å™¨å·¥ä½œæµ ---
workflow = create_supervisor(
    [research_agent, math_agent],
    model=llm,
    prompt=(
        "You are a team supervisor managing a research expert and a math expert. "
        "Delegate tasks to the appropriate agent to answer the user's query. "
        "For current events or facts, use research_agent. "
        "For math problems, use math_agent."
    )
)

# ç¼–è¯‘å¤šæ™ºèƒ½ä½“åº”ç”¨
app = workflow.compile()
```

æ‰§è¡Œå·¥ä½œæµï¼Œè§‚å¯Ÿç›‘ç£å™¨å¦‚ä½•åˆ†é…ä»»åŠ¡ã€‚

```python
# --- æ‰§è¡Œå¤šæ™ºèƒ½ä½“å·¥ä½œæµ ---
result = app.invoke({
    "messages": [
        {
            "role": "user",
            "content": "what's the combined headcount of the FAANG companies in 2024?"
        }
    ]
})

# æ ¼å¼åŒ–å¹¶æ˜¾ç¤ºç»“æœ
format_messages(result['messages'])
```

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ user â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Learn more about LangGraph Swarm  â”‚
â”‚ and multi-agent systems.          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“ AI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Fetching details on LangGraph     â”‚
â”‚ Swarm and related resources...    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”§ Tool Output â”€â”€â”€â”€â”€â”
â”‚ **LangGraph Swarm**               â”‚
â”‚ Repo:                             â”‚
â”‚ https://github.com/langchain-ai/  â”‚
â”‚ langgraph-swarm-py                â”‚
â”‚                                   â”‚
â”‚ â€¢ Python library for multi-agent  â”‚
â”‚   AI with dynamic collaboration.  â”‚
â”‚ â€¢ Agents hand off control based   â”‚
â”‚   on specialization, keeping      â”‚
â”‚   conversation context.           â”‚
â”‚ â€¢ Supports custom handoffs,       â”‚
â”‚   streaming, memory, and human-   â”‚
â”‚   in-the-loop.                    â”‚
â”‚ â€¢ Install:                        â”‚
â”‚   `pip install langgraph-swarm`   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”§ Tool Output â”€â”€â”€â”€â”€â”
â”‚ **Videos on multi-agent systems** â”‚
â”‚ 1. https://youtu.be/4nZl32FwU-o   â”‚
â”‚ 2. https://youtu.be/JeyDrn1dSUQ   â”‚
â”‚ 3. https://youtu.be/B_0TNuYi56w   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“ AI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LangGraph Swarm makes it easy to  â”‚
â”‚ build context-aware multi-agent    â”‚
â”‚ systems. Check videos for deeper   â”‚
â”‚ insights on multi-agent behavior.  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

æ­¤å¤„ç›‘ç£å™¨æ­£ç¡®éš”ç¦»äº†æ¯é¡¹ä»»åŠ¡çš„ä¸Šä¸‹æ–‡â€”â€”å°†ç ”ç©¶æŸ¥è¯¢å‘é€è‡³ç ”ç©¶å‘˜ï¼Œæ•°å­¦é—®é¢˜å‘é€è‡³æ•°å­¦å®¶ï¼Œå±•ç°äº†é«˜æ•ˆçš„ä¸Šä¸‹æ–‡éš”ç¦»æœºåˆ¶ã€‚

æ‰©å±•é˜…è¯»èµ„æºï¼š

* [**LangGraphç¾¤æ™ºç³»ç»Ÿ**](https://github.com/langchain-ai/langgraph-swarm-py) ï¼šæ”¯æŒåŠ¨æ€ä»»åŠ¡äº¤æ¥ã€è®°å¿†å­˜å‚¨ä¸äººæœºååŒçš„Pythonå¤šæ™ºèƒ½ä½“ç³»ç»Ÿå¼€å‘åº“ã€‚
* [**å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸“é¢˜è§†é¢‘**](https://www.youtube.com/watch?v=4nZl32FwU-o) è·å–æ„å»ºååŒå¼äººå·¥æ™ºèƒ½æ™ºèƒ½ä½“çš„æ·±åº¦è§£æï¼ˆ[è§†é¢‘2](https://www.youtube.com/watch?v=JeyDrn1dSUQ) , [è§†é¢‘3](https://www.youtube.com/watch?v=B_0TNuYi56w) ï¼‰ã€‚

## 11. æ²™ç›’ç¯å¢ƒéš”ç¦»æŠ€æœ¯

HuggingFaceçš„[æ·±åº¦ç ”ç©¶](https://huggingface.co/blog/open-deep-research#:~:text=From%20building%20,it%20can%20still%20use%20it) å±•ç¤ºäº†ä¸€ç§éš”ç¦»ä¸Šä¸‹æ–‡çš„åˆ›æ–°æ–¹æ³•ã€‚å¤§å¤šæ•°æ™ºèƒ½ä½“ä½¿ç”¨[å·¥å…·è°ƒç”¨API](https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/overview) ï¼Œè¿™äº›æ¥å£è¿”å›JSONå‚æ•°æ¥è¿è¡Œæœç´¢APIç­‰å·¥å…·å¹¶è·å–ç»“æœã€‚

HuggingFaceé‡‡ç”¨[ä»£ç æ™ºèƒ½ä½“](https://huggingface.co/papers/2402.01030) ï¼Œé€šè¿‡ç¼–å†™ä»£ç æ¥è°ƒç”¨å·¥å…·ã€‚è¯¥ä»£ç åœ¨å®‰å…¨çš„[æ²™ç›’ç¯å¢ƒ](https://e2b.dev/) ä¸­è¿è¡Œï¼Œæ‰§è¡Œç»“æœå°†è¿”å›ç»™å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚

è¿™ç§æ–¹æ³•ä½¿æµ·é‡æ•°æ®ï¼ˆå¦‚å›¾åƒæˆ–éŸ³é¢‘ï¼‰å¯çªç ´LLMçš„tokené™åˆ¶ã€‚HuggingFaceé˜é‡Šé“ï¼š

> *[ä»£ç æ™ºèƒ½ä½“èƒ½å¤Ÿ]æ›´ä¼˜åœ°å¤„ç†çŠ¶æ€â€¦â€¦éœ€è¦æš‚å­˜æ­¤å›¾åƒ/éŸ³é¢‘/å…¶ä»–æ•°æ®ä¾›åç»­ä½¿ç”¨ï¼Ÿåªéœ€å°†å…¶ä¿å­˜ä¸ºçŠ¶æ€ä¸­çš„å˜é‡ï¼Œåç»­è°ƒç”¨å³å¯ã€‚*

åœ¨LangGraphä¸­ä½¿ç”¨æ²™ç®±ç¯å¢ƒååˆ†ç®€ä¾¿ã€‚[LangChainæ²™ç®±](https://github.com/langchain-ai/langchain-sandbox) é€šè¿‡Pyodideï¼ˆç¼–è¯‘ä¸ºWebAssemblyçš„Pythonï¼‰å®‰å…¨æ‰§è¡Œéå—ä¿¡Pythonä»£ç ã€‚æ‚¨å¯å°†å…¶ä½œä¸ºå·¥å…·é›†æˆè‡³ä»»æ„LangGraphæ™ºèƒ½ä½“ã€‚

**æ³¨æ„ï¼š** éœ€é¢„å…ˆå®‰è£…Denoã€‚ å®‰è£…æŒ‡å—ï¼š<https://docs.deno.com/runtime/getting_started/installation/>

```python
from langchain_sandbox import PyodideSandboxTool
from langgraph.prebuilt import create_react_agent

# åˆ›å»ºæ”¯æŒç½‘ç»œè®¿é—®çš„æ²™ç®±å·¥å…·ï¼ˆç”¨äºè½¯ä»¶åŒ…å®‰è£…ï¼‰
tool = PyodideSandboxTool(allow_net=True)

# åˆ›å»ºåŒ…å«æ²™ç®±å·¥å…·çš„ReActæ™ºèƒ½ä½“
agent = create_react_agent(llm, tools=[tool])

# ä½¿ç”¨æ²™ç®±æ‰§è¡Œæ•°å­¦æŸ¥è¯¢
result = await agent.ainvoke(
    {"messages": [{"role": "user", "content": "what's 5 + 7?"}]},
)

# æ ¼å¼åŒ–å¹¶æ˜¾ç¤ºç»“æœ
format_messages(result['messages'])
```

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ user â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ what's 5 + 7?                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“ AI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ I can solve this by executing     â”‚
â”‚ Python code in the sandbox.       â”‚
â”‚                                  â”‚
â”‚ ğŸ”§ Tool Call: pyodide_sandbox     â”‚
â”‚ Args: {                          â”‚
â”‚   "code": "print(5 + 7)"          â”‚
â”‚ }                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”§ Tool Output â”€â”€â”€â”€â”€â”
â”‚ 12                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“ AI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ The answer is 12.                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 12. LangGraphä¸­çš„çŠ¶æ€éš”ç¦»

æ™ºèƒ½ä½“çš„**è¿è¡Œæ—¶çŠ¶æ€å¯¹è±¡**æ˜¯éš”ç¦»ä¸Šä¸‹æ–‡çš„ç»ä½³æ–¹å¼ï¼Œå…¶ä½œç”¨ç±»ä¼¼äºæ²™ç®±æœºåˆ¶ã€‚å¯é€šè¿‡æ¨¡å¼è®¾è®¡æ­¤çŠ¶æ€ï¼ˆå¦‚é‡‡ç”¨Pydanticæ¨¡å‹ï¼‰ï¼Œå…¶ä¸­ä¸åŒå­—æ®µä¸“ç”¨äºå­˜å‚¨ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

ä¾‹å¦‚ï¼šæŸå­—æ®µï¼ˆå¦‚`messages`ï¼‰æ¯è½®æ¬¡å‡å‘å¤§è¯­è¨€æ¨¡å‹(LLM)å±•ç¤ºï¼Œè€Œå…¶ä»–å­—æ®µå­˜å‚¨çš„ä¿¡æ¯åˆ™ä¿æŒéš”ç¦»ç›´è‡³éœ€è¦æ—¶è°ƒç”¨ã€‚

LangGraph å›´ç»•[**çŠ¶æ€**](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) å¯¹è±¡æ„å»ºï¼Œå…è®¸æ‚¨åˆ›å»ºè‡ªå®šä¹‰çŠ¶æ€æ¨¡å¼å¹¶åœ¨æ™ºèƒ½ä½“å·¥ä½œæµä¸­è®¿é—®å…¶å­—æ®µã€‚

ä¾‹å¦‚ï¼Œæ‚¨å¯å°†å·¥å…·è°ƒç”¨ç»“æœå­˜å‚¨äºç‰¹å®šå­—æ®µï¼Œä½¿å…¶åœ¨å¿…è¦æ—¶æ‰å¯¹å¤§è¯­è¨€æ¨¡å‹å¯è§ã€‚æ‚¨å·²åœ¨ä¸Šè¿°ç¬”è®°ä¸­çœ‹åˆ°è¯¸å¤šç›¸å…³ç¤ºä¾‹ã€‚

## 13. å…¨é¢æ€»ç»“

è®©æˆ‘ä»¬æ€»ç»“å½“å‰å®Œæˆçš„å·¥ä½œï¼š

* æˆ‘ä»¬ä½¿ç”¨ LangGraph çš„ `StateGraph` åˆ›å»ºçŸ­æœŸè®°å¿†**ã€Œæš‚å­˜åŒºã€**ï¼Œå¹¶é‡‡ç”¨ `InMemoryStore` å®ç°é•¿æœŸè®°å¿†å­˜å‚¨ï¼Œä½¿æ™ºèƒ½ä½“å…·å¤‡ä¿¡æ¯å­˜å–èƒ½åŠ›ã€‚
* æˆ‘ä»¬æ¼”ç¤ºäº†å¦‚ä½•ä»æ™ºèƒ½ä½“çŠ¶æ€å’Œé•¿æœŸè®°å¿†ä¸­ç²¾å‡†æå–ç›¸å…³ä¿¡æ¯ã€‚è¿™åŒ…æ‹¬è¿ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆ`RAG`ï¼‰è·å–ç‰¹å®šçŸ¥è¯†ï¼Œä»¥åŠé€šè¿‡ `langgraph-bigtool` ä»å¤šå·¥å…·ä¸­ç²¾å‡†é€‰æ‹©ã€‚
* ä¸ºç®¡ç†é•¿å¯¹è¯åŠå ç”¨å¤§é‡ä»¤ç‰Œçš„å·¥å…·è¾“å‡ºï¼Œæˆ‘ä»¬å®ç°äº†æ‘˜è¦ç”Ÿæˆæœºåˆ¶ã€‚
* æˆ‘ä»¬æ¼”ç¤ºäº†å¦‚ä½•åŠ¨æ€å‹ç¼©`RAG`ç»“æœï¼Œä»¥æå‡æ™ºèƒ½ä½“æ•ˆç‡å¹¶å‡å°‘ä»¤ç‰Œä½¿ç”¨é‡ã€‚
* é€šè¿‡æ„å»ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆç”±ç›‘ç£å‘˜å°†ä»»åŠ¡åˆ†æ´¾ç»™ä¸“ä¸šå­æ™ºèƒ½ä½“ï¼‰ä»¥åŠä½¿ç”¨æ²™ç›’ç¯å¢ƒè¿è¡Œä»£ç ï¼Œæˆ‘ä»¬å®ç°äº†ä¸Šä¸‹æ–‡éš”ç¦»æœºåˆ¶ä»¥é¿å…æ··æ·†ã€‚

è¿™äº›æŠ€æœ¯å‡å±äº**â€œä¸Šä¸‹æ–‡å·¥ç¨‹â€**ç­–ç•¥èŒƒç•´ï¼Œè¯¥ç­–ç•¥é€šè¿‡ç²¾ç»†ç®¡ç†å·¥ä½œå†…å­˜ï¼ˆ`context`ï¼‰æ¥ä¼˜åŒ–äººå·¥æ™ºèƒ½æ™ºèƒ½ä½“ï¼Œä½¿å…¶æ›´é«˜æ•ˆã€æ›´ç²¾å‡†ï¼Œå¹¶èƒ½å¤„ç†å¤æ‚ä¸”é•¿æœŸè¿è¡Œçš„ä»»åŠ¡ã€‚
