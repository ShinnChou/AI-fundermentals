# AI Fundermentals
## ç›¸å…³ç¡¬ä»¶çŸ¥è¯†
- [PCIe çŸ¥è¯†å¤§å…¨](https://mp.weixin.qq.com/s/dHvKYcZoa4rcF90LLyo_0A)
- [NVLink å…¥é—¨](https://mp.weixin.qq.com/s/fP69UEgusOa_X4ZKLo30ig)
- [NVIDIA DGX SuperPODï¼šä¸‹ä¸€ä»£å¯æ‰©å±•çš„AIé¢†å¯¼åŸºç¡€è®¾æ–½](https://mp.weixin.qq.com/s/a64Qb6DuAAZnCTBy8g1p2Q)

## æ·±å…¥ç†è§£ GPU æ¶æ„
åœ¨å‡†å¤‡åœ¨ GPU ä¸Šè¿è¡Œçš„åº”ç”¨ç¨‹åºæ—¶ï¼Œäº†è§£ GPU ç¡¬ä»¶è®¾è®¡çš„ä¸»è¦ç‰¹æ€§å¹¶äº†è§£ä¸ CPU çš„ç›¸ä¼¼ä¹‹å¤„å’Œä¸åŒä¹‹å¤„ä¼šå¾ˆæœ‰å¸®åŠ©ã€‚æœ¬è·¯çº¿å›¾é€‚ç”¨äºé‚£äº›å¯¹ GPU æ¯”è¾ƒé™Œç”Ÿæˆ–åªæ˜¯æƒ³äº†è§£æ›´å¤šæœ‰å…³ GPU ä¸­è®¡ç®—æœºæŠ€æœ¯çš„äººã€‚ä¸éœ€è¦ç‰¹å®šçš„å¹¶è¡Œç¼–ç¨‹ç»éªŒï¼Œç»ƒä¹ åŸºäº CUDA å·¥å…·åŒ…ä¸­åŒ…å«çš„æ ‡å‡† NVIDIA ç¤ºä¾‹ç¨‹åºã€‚

- [GPU ç‰¹æ€§](gpu_architecture/gpu_characteristics.md)
- [GPU å†…å­˜](gpu_architecture/gpu_memory.md)
- [GPU Example: Tesla V100](gpu_architecture/tesla_v100.md)
- [GPUs on Frontera: RTX 5000](gpu_architecture/rtx_5000.md)
- ç»ƒä¹ ï¼š
	- [Exercise: Device Query](gpu_architecture/exer_device_query.md)
	- [Exercise: Device Bandwidth](gpu_architecture/exer_device_bandwidth.md)

### GPU æ¶æ„å’Œç¼–ç¨‹æ¨¡å‹ä»‹ç»
- [GPU Architecture and Programming â€” An Introduction](gpu_programming/gpu_programming_introduction.md)

### å…¶ä»–ç›¸å…³çŸ¥è¯†ç‚¹
- [æ·±å…¥ç†è§£ Nvidia CUDA æ ¸å¿ƒï¼ˆvs. Tensor Cores vs. RT Cores)](cuda/cuda_cores_cn.md)

## CUDA å­¦ä¹ ææ–™
### å¿«é€Ÿå…¥é—¨
- [å¹¶è¡Œè®¡ç®—ã€è´¹æ—åˆ†ç±»æ³•å’Œ CUDA åŸºæœ¬æ¦‚å¿µ](https://mp.weixin.qq.com/s/NL_Bz8JB-LdAtrQake7EdA)
- [CUDA ç¼–ç¨‹æ¨¡å‹å…¥é—¨](https://mp.weixin.qq.com/s/IUYzzgt6DUYhfaDnbxoZuQ)
- [CUDA å¹¶å‘ç¼–ç¨‹ä¹‹ Stream ä»‹ç»](cuda/cuda_streams.md)

### å‚è€ƒèµ„æ–™
- [CUDA Reading Group ç›¸å…³è®²åº§](https://mp.weixin.qq.com/s/6sOrNzG0UeVBes8stWSoWA): [GPU Mode Reading Group](https://github.com/gpu-mode)
- [ã€ŠCUDA C++ Programming Guideã€‹](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html)
- [ã€ŠCUDA C ç¼–ç¨‹æƒå¨æŒ‡å—ã€‹](https://mp.weixin.qq.com/s/xJY5Znv3cuQi_UCd_XjJ4A)ï¼š[ä¹¦ä¸­ç¤ºä¾‹ä»£ç ](https://github.com/Eddie-Wang1120/Professional-CUDA-C-Programming-Code-and-Notes)
- [Nvidia å®˜æ–¹ CUDA æ˜¯ç¤ºä¾‹](https://github.com/NVIDIA/cuda-samples)
- [ã€ŠCUDA ç¼–ç¨‹ï¼šåŸºç¡€ä¸å®è·µ by æ¨Šå“²å‹‡ã€‹](https://book.douban.com/subject/35252459/)
	- [å­¦ä¹ ç¬”è®°](https://github.com/QINZHAOYU/CudaSteps)
	- [ç¤ºä¾‹ä»£ç ](https://github.com/MAhaitao999/CUDA_Programming)
- [ã€ŠCUDA ç¼–ç¨‹ç®€ä»‹: åŸºç¡€ä¸å®è·µ by æç‘œã€‹](http://www.frankyongtju.cn/ToSeminars/hpc.pdf)
- [ã€ŠCUDA ç¼–ç¨‹å…¥é—¨ã€‹ - æœ¬æ–‡æ”¹ç¼–è‡ªåŒ—äº¬å¤§å­¦è¶…ç®—é˜Ÿ CUDA æ•™ç¨‹è®²ä¹‰](https://hpcwiki.io/gpu/cuda/)
- [Multi GPU Programming Models](https://github.com/NVIDIA/multi-gpu-programming-models)
- [CUDA Processing Streams](https://turing.une.edu.au/~cosc330/lectures/display_lecture.php?lecture=22#1)

### ä¸“ä¸šé€‰æ‰‹
[**CUDA-Learn-Notes**](https://github.com/xlite-dev/CUDA-Learn-Notes)ï¼šğŸ“šModern CUDA Learn Notes: 200+ Tensor/CUDA Cores KernelsğŸ‰, HGEMM, FA2 via MMA and CuTe, 98~100% TFLOPS of cuBLAS/FA2.

## ç›‘æ§ä¸è¿ç»´
- [nvidia-smi å…¥é—¨](ops/nvidia-smi.md)
- [nvtop å…¥é—¨](ops/nvtop.md)
- [Nvidia GPU XID æ•…éšœç è§£æ](https://mp.weixin.qq.com/s/ekCnhr3qrhjuX_-CEyx65g)
- [Nvidia GPU å¡ ä¹‹ ECC åŠŸèƒ½](https://mp.weixin.qq.com/s/nmZVOQAyfFyesm79HzjUlQ)
- [æŸ¥è¯¢ GPU å¡è¯¦ç»†å‚æ•°](ops/DeviceQuery.md)
- [Understanding NVIDIA GPU Performance: Utilization vs. Saturation (2023)](https://arthurchiao.art/blog/understanding-gpu-performance/)
- [GPU Utilization is a Misleading Metric](ops/gpu_utils.md)

## æ€§èƒ½åˆ†æä¸è°ƒä¼˜
- [ä½¿ç”¨ Nsight Compute Tool åˆ†æ CUDA çŸ©é˜µä¹˜æ³•ç¨‹åº](https://www.yuque.com/u41800946/nquqpa/eo7gykiyhg8xi2gg)
- [CUDA Kernel Profiling using Nvidia Nsight Compute](profiling/s9345-cuda-kernel-profiling-using-nvidia-nsight-compute.pdf)

# LLM åŸºç¡€
## Article & Video
- [Andrej Karpathyï¼šDeep Dive into LLMs like ChatGPTï¼ˆBç«™è§†é¢‘ï¼‰](https://www.bilibili.com/video/BV16cNEeXEer)
- [å¤§æ¨¡å‹åŸºç¡€ç»„ä»¶ - Tokenizer](https://zhuanlan.zhihu.com/p/651430181)
- [æ·±å…¥æµ…å‡ºæ–‡æœ¬åµŒå…¥æŠ€æœ¯](llm/text_embeddings_guide.md)
- [æ·±å…¥æ¢ç´¢ï¼šAI é©±åŠ¨çš„ PDF å¸ƒå±€æ£€æµ‹å¼•æ“æºä»£ç è§£æ](llm/marker.zh-CN.md)
- [ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤å¼€æºå·¥å…· MinerU åŠ©åŠ›å¤æ‚ PDF é«˜æ•ˆè§£ææå–](llm/minerU_intro.md)
- [**å¤§æ¨¡å‹å¯è§†åŒ–æŒ‡å—**](https://www.maartengrootendorst.com/)

## eBook
- [å¤§æ¨¡å‹åŸºç¡€](https://github.com/ZJU-LLMs/Foundations-of-LLMs) <br>
	<img src="https://raw.githubusercontent.com/ZJU-LLMs/Foundations-of-LLMs/main/figure/cover.png" height="300"/>
- [Hands-On Large Language Models](https://github.com/HandsOnLLM/Hands-On-Large-Language-Models) <br>
	<img src="https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/book_cover.png" height="300"/>
	
## AI Infra
- [é«˜æ€§èƒ½ GPU æœåŠ¡å™¨ç¡¬ä»¶æ‹“æ‰‘ä¸é›†ç¾¤ç»„ç½‘](https://arthurchiao.art/blog/gpu-advanced-notes-1-zh/)
- [NVIDIA GH200 èŠ¯ç‰‡ã€æœåŠ¡å™¨åŠé›†ç¾¤ç»„ç½‘](https://arthurchiao.art/blog/gpu-advanced-notes-4-zh/)
- [æ·±åº¦å­¦ä¹ ï¼ˆå¤§æ¨¡å‹ï¼‰ä¸­çš„ç²¾åº¦](https://mp.weixin.qq.com/s/b08gFicrKNCfrwSlpsecmQ)

## æ·±åº¦å­¦ä¹ /æœºå™¨å­¦ä¹ 
- [ã€Šæœºå™¨å­¦ä¹ ç³»ç»Ÿï¼šè®¾è®¡å’Œå®ç°ã€‹](https://openmlsys.github.io/index.html)
- [ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹](https://zh.d2l.ai/)

## åŠ¨æ‰‹å®è·µ
- [è¯»è€…æ¥ä¿¡ï¼šè¯·é—®7bé˜…è¯»åˆ†æä¸åŒä¸­åŒ»å¤ç±çš„èƒ½åŠ›æ€ä¹ˆæ ·ï¼Ÿå¯ä»¥è¿›è¡Œä¸“é¡¹è®­ç»ƒå¤§å¹…åº¦æé«˜è¿™æ–¹é¢èƒ½åŠ›ä¹ˆï¼Ÿ](llm/traditional-chinese-medicine.md)
- [ollama benchmark](llm/ollama/README.md)
- [è§£å¯†å¤§è¯­è¨€æ¨¡å‹ä¸­çš„ Tokens](llm/token/llm_token_intro.md)
	- [Tiktokenizer åœ¨çº¿ç‰ˆ](https://tiktokenizer.vercel.app/?model=gpt-4o)
- [Markitdown å…¥é—¨](llm/markitdown/README.md)

## DeepSeek
- [Deepseek 3FSï¼ˆ Fire-Flyer File Systemï¼‰è®¾è®¡ç¬”è®°](deepseek/deepseek_3fs_design_notes.zh-CN.md)
- [DeepSeek r1 è’¸é¦æ¨¡å‹å’Œæ»¡è¡€æ¨¡å‹å¯¹æ¯”](deepseek/deepseek-r1-cmp.md)
- [åœ¨ Mac ä¸Šè¿è¡Œ DeepSeek-R1 æ¨¡å‹](deepseek/mac-deepseek-r1.md)

## Useful Projects

- [unstructured](https://github.com/Unstructured-IO/unstructured):Open source libraries and APIs to build custom preprocessing pipelines for labeling, training, or production machine learning pipelines.
- [MinerU](https://github.com/opendatalab/MinerU):A high-quality tool for convert PDF to Markdown and JSON.
- [markitdown](https://github.com/microsoft/markitdown): Python tool for converting files and office documents to Markdown.
- [unsloth](https://github.com/unslothai/unsloth): About
Finetune Llama 3.3, DeepSeek-R1 & Reasoning LLMs 2x faster with 70% less memory! 
- [ktransformers](https://github.com/kvcache-ai/ktransformers): A Flexible Framework for Experiencing Cutting-edge LLM Inference Optimizations

## RAG
- [**ä»0åˆ°1å¿«é€Ÿæ­å»ºRAGåº”ç”¨**](https://mp.weixin.qq.com/s/89-bwZ4aPor4ySj5U3n5zw)
	- [é…å¥—ä»£ç ](llm/rag/lession2.ipynb)

## Fine-Tuning
- [**Qwen 2 å¤§æ¨¡å‹æŒ‡ä»¤å¾®è°ƒå…¥é—¨å®æˆ˜**](https://mp.weixin.qq.com/s/Atf61jocM3FBoGjZ_DZ1UA)
	- [é…å¥—ä»£ç ](llm/fine-tuning/train_qwen2.ipynb)

## MCP Client & Server 

- [**LangChain + æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ï¼šAI æ™ºèƒ½ä½“ Demo**](llm/agent/README.md)

# LLM è®­ç»ƒ

## ä»é›¶å¼€å§‹è®­ç»ƒ 70B æ¨¡å‹

* [Training a 70B model from scratch: open-source tools, evaluation datasets, and learnings](https://imbue.com/research/70b-intro/)
* [Sanitized open-source datasets for natural language and code understanding: how we evaluated our 70B model](https://imbue.com/research/70b-evals/)
* [From bare metal to a 70B model: infrastructure set-up and scripts](https://imbue.com/research/70b-infrastructure/)
* [Open-sourcing CARBS: how we used our hyperparameter optimizer to scale up to a 70B-parameter language model](https://imbue.com/research/70b-carbs/)