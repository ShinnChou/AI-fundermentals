#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LangGraph ç°ä»£è®°å¿†ç®¡ç†ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨LangGraphå®ç°æŒä¹…åŒ–è®°å¿†å’ŒçŠ¶æ€ç®¡ç†
"""

import os
import json
import sqlite3
from datetime import datetime
from typing import Dict, Any, List, Optional, TypedDict, Annotated
from pathlib import Path

try:
    from langgraph.graph import StateGraph, END
    from langgraph.checkpoint.memory import MemorySaver
    LANGGRAPH_AVAILABLE = True
except ImportError:
    print("âš ï¸ LangGraph æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install langgraph")
    print("æœ¬ç¤ºä¾‹å°†å±•ç¤ºæ¦‚å¿µæ€§ä»£ç ç»“æ„")
    LANGGRAPH_AVAILABLE = False
    
    # æ¨¡æ‹ŸLangGraphç±»å‹
    class StateGraph:
        def __init__(self, state_schema): pass
        def add_node(self, name, func): pass
        def add_edge(self, from_node, to_node): pass
        def set_entry_point(self, node): pass
        def compile(self, checkpointer=None): pass
    
    class MemorySaver:
        def __init__(self): pass
    
    END = "__end__"

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.runnables import RunnableConfig

try:
    from .llm_factory import get_llm
    from .config import config
except ImportError:
    from llm_factory import get_llm
    from config import config

# å®šä¹‰çŠ¶æ€ç±»å‹
class ConversationState(TypedDict):
    """å¯¹è¯çŠ¶æ€å®šä¹‰"""
    messages: List[Dict[str, Any]]  # æ¶ˆæ¯å†å²
    user_id: str  # ç”¨æˆ·ID
    session_id: str  # ä¼šè¯ID
    context: Dict[str, Any]  # ä¸Šä¸‹æ–‡ä¿¡æ¯
    memory_summary: str  # è®°å¿†æ‘˜è¦
    last_activity: str  # æœ€åæ´»åŠ¨æ—¶é—´
    metadata: Dict[str, Any]  # å…ƒæ•°æ®

class LangGraphMemoryManager:
    """LangGraphè®°å¿†ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str = "./memory.db"):
        self.db_path = db_path
        self.llm = get_llm()
        
        # åˆ›å»ºæ£€æŸ¥ç‚¹ä¿å­˜å™¨ï¼ˆä½¿ç”¨å†…å­˜ä¿å­˜å™¨ï¼‰
        self.checkpointer = MemorySaver()
        
        # æ„å»ºçŠ¶æ€å›¾
        self.graph = self._build_graph()
        
        print(f"âœ… LangGraphè®°å¿†ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ ä½¿ç”¨å†…å­˜ä¿å­˜å™¨ï¼ˆæ¼”ç¤ºæ¨¡å¼ï¼‰")
    
    def _build_graph(self) -> StateGraph:
        """
        æ„å»ºLangGraphçŠ¶æ€å›¾
        """
        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(ConversationState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("process_input", self._process_input)
        workflow.add_node("update_memory", self._update_memory)
        workflow.add_node("generate_response", self._generate_response)
        workflow.add_node("save_state", self._save_state)
        
        # æ·»åŠ è¾¹
        workflow.add_edge("process_input", "update_memory")
        workflow.add_edge("update_memory", "generate_response")
        workflow.add_edge("generate_response", "save_state")
        workflow.add_edge("save_state", END)
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("process_input")
        
        # ç¼–è¯‘å›¾
        return workflow.compile(checkpointer=self.checkpointer)
    
    def _process_input(self, state: ConversationState) -> ConversationState:
        """
        å¤„ç†è¾“å…¥æ¶ˆæ¯
        """
        print("ğŸ”„ å¤„ç†è¾“å…¥æ¶ˆæ¯...")
        
        # æ›´æ–°æœ€åæ´»åŠ¨æ—¶é—´
        state["last_activity"] = datetime.now().isoformat()
        
        # å¤„ç†æ¶ˆæ¯æ ¼å¼
        if state["messages"]:
            last_message = state["messages"][-1]
            if isinstance(last_message, dict) and "content" in last_message:
                # æ¶ˆæ¯å·²ç»æ˜¯æ­£ç¡®æ ¼å¼
                pass
            else:
                # è½¬æ¢æ¶ˆæ¯æ ¼å¼
                state["messages"][-1] = {
                    "role": "user",
                    "content": str(last_message),
                    "timestamp": datetime.now().isoformat()
                }
        
        return state
    
    def _update_memory(self, state: ConversationState) -> ConversationState:
        """
        æ›´æ–°è®°å¿†
        """
        print("ğŸ§  æ›´æ–°è®°å¿†...")
        
        messages = state["messages"]
        
        # å¦‚æœæ¶ˆæ¯è¿‡å¤šï¼Œç”Ÿæˆæ‘˜è¦
        if len(messages) > config.summary_threshold:
            # æå–æœ€è¿‘çš„æ¶ˆæ¯ç”¨äºæ‘˜è¦
            recent_messages = messages[-config.summary_threshold:]
            
            # ç”Ÿæˆæ‘˜è¦
            summary_prompt = f"""
è¯·æ€»ç»“ä»¥ä¸‹å¯¹è¯çš„å…³é”®ä¿¡æ¯ï¼š

{self._format_messages_for_summary(recent_messages)}

è¯·æä¾›ç®€æ´çš„æ‘˜è¦ï¼ŒåŒ…å«ï¼š
1. ç”¨æˆ·çš„ä¸»è¦éœ€æ±‚æˆ–é—®é¢˜
2. é‡è¦çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
3. å¯¹è¯çš„è¿›å±•çŠ¶æ€
            """.strip()
            
            try:
                summary_response = self.llm.invoke([HumanMessage(content=summary_prompt)])
                state["memory_summary"] = summary_response.content
                
                # ä¿ç•™æœ€è¿‘çš„å‡ æ¡æ¶ˆæ¯å’Œæ‘˜è¦
                state["messages"] = messages[-5:]  # ä¿ç•™æœ€è¿‘5æ¡æ¶ˆæ¯
                
                print(f"ğŸ“ ç”Ÿæˆè®°å¿†æ‘˜è¦: {state['memory_summary'][:100]}...")
                
            except Exception as e:
                print(f"âš ï¸ æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
                state["memory_summary"] = "æ‘˜è¦ç”Ÿæˆå¤±è´¥"
        
        return state
    
    def _format_messages_for_summary(self, messages: List[Dict[str, Any]]) -> str:
        """
        æ ¼å¼åŒ–æ¶ˆæ¯ç”¨äºæ‘˜è¦
        """
        formatted = []
        for msg in messages:
            role = msg.get("role", "unknown")
            content = msg.get("content", "")
            if role == "user":
                formatted.append(f"ç”¨æˆ·: {content}")
            elif role == "assistant":
                formatted.append(f"åŠ©æ‰‹: {content}")
        return "\n".join(formatted)
    
    def _generate_response(self, state: ConversationState) -> ConversationState:
        """
        ç”Ÿæˆå“åº”
        """
        print("ğŸ’­ ç”Ÿæˆå“åº”...")
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context_parts = []
        
        # æ·»åŠ è®°å¿†æ‘˜è¦
        if state.get("memory_summary"):
            context_parts.append(f"å¯¹è¯æ‘˜è¦: {state['memory_summary']}")
        
        # æ·»åŠ æœ€è¿‘æ¶ˆæ¯
        recent_messages = state["messages"][-5:]  # æœ€è¿‘5æ¡æ¶ˆæ¯
        if recent_messages:
            context_parts.append("æœ€è¿‘å¯¹è¯:")
            for msg in recent_messages[:-1]:  # æ’é™¤å½“å‰ç”¨æˆ·æ¶ˆæ¯
                role = msg.get("role", "unknown")
                content = msg.get("content", "")
                if role == "user":
                    context_parts.append(f"ç”¨æˆ·: {content}")
                elif role == "assistant":
                    context_parts.append(f"åŠ©æ‰‹: {content}")
        
        # è·å–å½“å‰ç”¨æˆ·æ¶ˆæ¯
        current_message = state["messages"][-1]["content"]
        
        # æ„å»ºå®Œæ•´æç¤º
        full_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå…·æœ‰è®°å¿†èƒ½åŠ›ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š

{chr(10).join(context_parts)}

å½“å‰ç”¨æˆ·é—®é¢˜: {current_message}

è¯·æä¾›æœ‰å¸®åŠ©çš„å›ç­”ã€‚
        """.strip()
        
        try:
            # ç”Ÿæˆå“åº”
            response = self.llm.invoke([HumanMessage(content=full_prompt)])
            
            # æ·»åŠ åŠ©æ‰‹å“åº”åˆ°æ¶ˆæ¯å†å²
            state["messages"].append({
                "role": "assistant",
                "content": response.content,
                "timestamp": datetime.now().isoformat()
            })
            
            print(f"ğŸ¤– ç”Ÿæˆå“åº”: {response.content[:100]}...")
            
        except Exception as e:
            print(f"âŒ å“åº”ç”Ÿæˆå¤±è´¥: {e}")
            error_response = "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ï¼Œè¯·ç¨åå†è¯•ã€‚"
            state["messages"].append({
                "role": "assistant",
                "content": error_response,
                "timestamp": datetime.now().isoformat()
            })
        
        return state
    
    def _save_state(self, state: ConversationState) -> ConversationState:
        """
        ä¿å­˜çŠ¶æ€
        """
        print("ğŸ’¾ ä¿å­˜çŠ¶æ€...")
        
        # æ›´æ–°å…ƒæ•°æ®
        state["metadata"]["last_updated"] = datetime.now().isoformat()
        state["metadata"]["message_count"] = len(state["messages"])
        
        return state
    
    def chat(
        self, 
        user_id: str, 
        session_id: str, 
        message: str,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        å¤„ç†èŠå¤©æ¶ˆæ¯
        
        Args:
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            message: ç”¨æˆ·æ¶ˆæ¯
            context: é¢å¤–ä¸Šä¸‹æ–‡
            
        Returns:
            å“åº”ç»“æœ
        """
        try:
            # æ„å»ºé…ç½®
            config_dict = {
                "configurable": {
                    "thread_id": f"{user_id}_{session_id}"
                }
            }
            
            # å‡†å¤‡åˆå§‹çŠ¶æ€
            initial_state = {
                "messages": [{
                    "role": "user",
                    "content": message,
                    "timestamp": datetime.now().isoformat()
                }],
                "user_id": user_id,
                "session_id": session_id,
                "context": context or {},
                "memory_summary": "",
                "last_activity": datetime.now().isoformat(),
                "metadata": {
                    "created_at": datetime.now().isoformat()
                }
            }
            
            # æ‰§è¡Œå›¾
            result = self.graph.invoke(initial_state, config=config_dict)
            
            # æå–å“åº”
            assistant_messages = [
                msg for msg in result["messages"] 
                if msg.get("role") == "assistant"
            ]
            
            if assistant_messages:
                response = assistant_messages[-1]["content"]
            else:
                response = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå“åº”ã€‚"
            
            return {
                "response": response,
                "session_id": session_id,
                "user_id": user_id,
                "message_count": len(result["messages"]),
                "memory_summary": result.get("memory_summary", "")
            }
            
        except Exception as e:
            print(f"âŒ èŠå¤©å¤„ç†å¤±è´¥: {e}")
            return {
                "error": str(e),
                "session_id": session_id,
                "user_id": user_id
            }
    
    def get_conversation_history(
        self, 
        user_id: str, 
        session_id: str
    ) -> Optional[Dict[str, Any]]:
        """
        è·å–å¯¹è¯å†å²
        
        Args:
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            
        Returns:
            å¯¹è¯å†å²
        """
        try:
            config_dict = {
                "configurable": {
                    "thread_id": f"{user_id}_{session_id}"
                }
            }
            
            # è·å–çŠ¶æ€
            state = self.graph.get_state(config_dict)
            
            if state and state.values:
                return {
                    "messages": state.values.get("messages", []),
                    "memory_summary": state.values.get("memory_summary", ""),
                    "last_activity": state.values.get("last_activity", ""),
                    "metadata": state.values.get("metadata", {})
                }
            
            return None
            
        except Exception as e:
            print(f"âŒ è·å–å¯¹è¯å†å²å¤±è´¥: {e}")
            return None
    
    def clear_conversation(
        self, 
        user_id: str, 
        session_id: str
    ) -> bool:
        """
        æ¸…é™¤å¯¹è¯å†å²
        
        Args:
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            config_dict = {
                "configurable": {
                    "thread_id": f"{user_id}_{session_id}"
                }
            }
            
            # é‡ç½®çŠ¶æ€
            initial_state = {
                "messages": [],
                "user_id": user_id,
                "session_id": session_id,
                "context": {},
                "memory_summary": "",
                "last_activity": datetime.now().isoformat(),
                "metadata": {
                    "cleared_at": datetime.now().isoformat()
                }
            }
            
            self.graph.update_state(config_dict, initial_state)
            print(f"ğŸ§¹ å·²æ¸…é™¤ä¼šè¯: {user_id}_{session_id}")
            return True
            
        except Exception as e:
            print(f"âŒ æ¸…é™¤å¯¹è¯å¤±è´¥: {e}")
            return False

def demo_langgraph_memory():
    """æ¼”ç¤ºLangGraphè®°å¿†åŠŸèƒ½"""
    print("ğŸš€ LangGraph ç°ä»£è®°å¿†ç®¡ç†æ¼”ç¤º")
    print("=" * 50)
    
    try:
        # åˆ›å»ºè®°å¿†ç®¡ç†å™¨
        memory_manager = LangGraphMemoryManager()
        
        # æ¨¡æ‹Ÿç”¨æˆ·å¯¹è¯
        user_id = "user_123"
        session_id = "session_456"
        
        conversations = [
            "ä½ å¥½ï¼Œæˆ‘æ˜¯æ–°ç”¨æˆ·ï¼Œæƒ³äº†è§£ä½ ä»¬çš„æœåŠ¡",
            "æˆ‘å¯¹äººå·¥æ™ºèƒ½å¾ˆæ„Ÿå…´è¶£ï¼Œä½ èƒ½ä»‹ç»ä¸€ä¸‹å—ï¼Ÿ",
            "æˆ‘æƒ³å­¦ä¹ æœºå™¨å­¦ä¹ ï¼Œæœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿ",
            "åˆšæ‰ä½ æåˆ°çš„æ·±åº¦å­¦ä¹ ï¼Œèƒ½è¯¦ç»†è¯´è¯´å—ï¼Ÿ",
            "æˆ‘ä¹‹å‰é—®è¿‡å…³äºæœºå™¨å­¦ä¹ çš„é—®é¢˜ï¼Œä½ è¿˜è®°å¾—å—ï¼Ÿ",
            "è°¢è°¢ä½ çš„å»ºè®®ï¼Œæˆ‘ä¼šè®¤çœŸè€ƒè™‘çš„"
        ]
        
        print(f"\nğŸ‘¤ ç”¨æˆ·: {user_id}")
        print(f"ğŸ“± ä¼šè¯: {session_id}")
        
        # è¿›è¡Œå¯¹è¯
        for i, message in enumerate(conversations, 1):
            print(f"\n--- ç¬¬ {i} è½®å¯¹è¯ ---")
            print(f"ğŸ‘¤ ç”¨æˆ·: {message}")
            
            # å‘é€æ¶ˆæ¯
            result = memory_manager.chat(user_id, session_id, message)
            
            if "response" in result:
                print(f"ğŸ¤– åŠ©æ‰‹: {result['response']}")
                print(f"ğŸ“Š æ¶ˆæ¯æ•°é‡: {result['message_count']}")
                
                if result.get("memory_summary"):
                    print(f"ğŸ§  è®°å¿†æ‘˜è¦: {result['memory_summary'][:100]}...")
            else:
                print(f"âŒ é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # è·å–å¯¹è¯å†å²
        print("\n" + "=" * 50)
        print("ğŸ“‹ å¯¹è¯å†å²")
        print("=" * 50)
        
        history = memory_manager.get_conversation_history(user_id, session_id)
        if history:
            print(f"ğŸ“ æ¶ˆæ¯æ•°é‡: {len(history['messages'])}")
            print(f"ğŸ§  è®°å¿†æ‘˜è¦: {history.get('memory_summary', 'æ— ')}")
            print(f"ğŸ• æœ€åæ´»åŠ¨: {history.get('last_activity', 'æœªçŸ¥')}")
            
            # æ˜¾ç¤ºæœ€è¿‘å‡ æ¡æ¶ˆæ¯
            recent_messages = history['messages'][-4:]  # æœ€è¿‘4æ¡æ¶ˆæ¯
            print("\næœ€è¿‘æ¶ˆæ¯:")
            for msg in recent_messages:
                role = "ğŸ‘¤" if msg['role'] == 'user' else "ğŸ¤–"
                content = msg['content'][:100] + "..." if len(msg['content']) > 100 else msg['content']
                print(f"{role} {content}")
        
        # æµ‹è¯•è®°å¿†æŒä¹…åŒ–
        print("\n" + "=" * 50)
        print("ğŸ”„ æµ‹è¯•è®°å¿†æŒä¹…åŒ–")
        print("=" * 50)
        
        # åˆ›å»ºæ–°çš„è®°å¿†ç®¡ç†å™¨å®ä¾‹ï¼ˆæ¨¡æ‹Ÿé‡å¯ï¼‰
        print("ğŸ”„ æ¨¡æ‹Ÿç³»ç»Ÿé‡å¯...")
        new_memory_manager = LangGraphMemoryManager()
        
        # ç»§ç»­å¯¹è¯
        continue_message = "æˆ‘ä»¬ä¹‹å‰èŠåˆ°å“ªé‡Œäº†ï¼Ÿ"
        print(f"\nğŸ‘¤ ç”¨æˆ·: {continue_message}")
        
        result = new_memory_manager.chat(user_id, session_id, continue_message)
        if "response" in result:
            print(f"ğŸ¤– åŠ©æ‰‹: {result['response']}")
            print("âœ… è®°å¿†æŒä¹…åŒ–æµ‹è¯•æˆåŠŸï¼")
        else:
            print(f"âŒ é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    print("LangGraph ç°ä»£è®°å¿†ç®¡ç†ç¤ºä¾‹")
    print("=" * 40)
    
    # æ£€æŸ¥é…ç½®
    if not config.validate_config():
        print("âŒ é…ç½®éªŒè¯å¤±è´¥ï¼è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡")
        return
    
    # è¿è¡Œæ¼”ç¤º
    demo_langgraph_memory()

if __name__ == "__main__":
    main()