# ç¬¬ä¸‰å¤©ï¼šLangSmithç›‘æ§å¹³å°é›†æˆ

## å­¦ä¹ ç›®æ ‡

- æŒæ¡LangSmithå¹³å°çš„æ ¸å¿ƒåŠŸèƒ½å’Œæ¶æ„
- å­¦ä¼šé›†æˆLangSmithåˆ°å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ
- æŒæ¡ç³»ç»Ÿç›‘æ§ã€æ—¥å¿—åˆ†æå’Œæ€§èƒ½ä¼˜åŒ–æŠ€æœ¯
- å­¦ä¼šä½¿ç”¨LangSmithè¿›è¡Œè°ƒè¯•å’Œæ•…éšœæ’é™¤
- äº†è§£ä¼ä¸šçº§ç›‘æ§ç³»ç»Ÿçš„è®¾è®¡å’Œå®ç°
- æŒæ¡æ™ºèƒ½å‘Šè­¦å’Œè‡ªåŠ¨åŒ–è¿ç»´æŠ€æœ¯

## å‚è€ƒé¡¹ç›®

æœ¬è¯¾ç¨‹æ·±å…¥è®²è§£LangSmithç›‘æ§å¹³å°çš„é›†æˆä¸åº”ç”¨ï¼Œå¸®åŠ©å­¦å‘˜æŒæ¡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„ç›‘æ§ã€è°ƒè¯•å’Œæ€§èƒ½ä¼˜åŒ–æŠ€æœ¯ã€‚

**ğŸ’¡ å®é™…ä»£ç å‚è€ƒ**ï¼šå®Œæ•´çš„LangSmithç›‘æ§é›†æˆå®ç°å¯å‚è€ƒé¡¹ç›®ä¸­çš„ä»¥ä¸‹æ–‡ä»¶ï¼š

- `langsmith_integration.py` - ä¼ä¸šçº§å…¨é“¾è·¯è¿½è¸ªç³»ç»Ÿ
- `monitoring/system_monitor.py` - ç³»ç»Ÿæ€§èƒ½ç›‘æ§
- `monitoring/alert_manager.py` - æ™ºèƒ½å‘Šè­¦ç®¡ç†
- `multi_agent_system/src/monitoring/` - ç›‘æ§ç»„ä»¶é›†åˆ
- `customer_service_system.py` - å®¢æœç³»ç»Ÿç›‘æ§æ¡ˆä¾‹

**æ¨¡æ‹Ÿç¯å¢ƒè¯´æ˜**ï¼šæœ¬åŸ¹è®­ä½¿ç”¨æ¨¡æ‹Ÿçš„LangSmithç¯å¢ƒè¿›è¡Œæ•™å­¦ï¼Œæ‰€æœ‰åŠŸèƒ½å’ŒAPIæ¥å£ä¸çœŸå®LangSmithä¿æŒä¸€è‡´ã€‚åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œåªéœ€è¦æ›¿æ¢ä¸ºçœŸå®çš„LangSmith APIå¯†é’¥å³å¯æ— ç¼åˆ‡æ¢åˆ°ç”Ÿäº§ç¯å¢ƒã€‚

**ä»£ç å¼•ç”¨**: å®Œæ•´çš„ä¼ä¸šçº§ç›‘æ§ç³»ç»Ÿå®ç°è¯·å‚è€ƒ `multi_agent_system/src/monitoring/langsmith_integration.py`

ä¼ä¸šçº§ç›‘æ§ç³»ç»Ÿçš„æ ¸å¿ƒç‰¹æ€§ï¼š

**æ ¸å¿ƒç»„ä»¶**ï¼š

- `AlertLevel`: å‘Šè­¦çº§åˆ«ç®¡ç†ï¼ˆä¿¡æ¯ã€è­¦å‘Šã€é”™è¯¯ã€ä¸¥é‡ï¼‰
- `MetricType`: æŒ‡æ ‡ç±»å‹åˆ†ç±»ï¼ˆæ€§èƒ½ã€ä¸šåŠ¡ã€ç³»ç»Ÿã€å®‰å…¨ï¼‰
- `MonitoringConfig`: ç›‘æ§é…ç½®ç®¡ç†ï¼ˆé‡‡æ ·ç‡ã€æ‰¹å¤„ç†ã€ä¿ç•™ç­–ç•¥ï¼‰
- `EnterpriseMonitoringSystem`: ä¸»ç›‘æ§ç³»ç»Ÿï¼Œæ”¯æŒå…¨é“¾è·¯è¿½è¸ª

**ä¼ä¸šçº§ç‰¹æ€§**ï¼š

- æ™ºèƒ½ä½“æ‰§è¡Œå…¨é“¾è·¯è¿½è¸ª
- å®æ—¶å‘Šè­¦è§„åˆ™æ£€æŸ¥
- æ€§èƒ½æŒ‡æ ‡è‡ªåŠ¨æ”¶é›†
- å¯é…ç½®çš„æ•°æ®ä¿ç•™ç­–ç•¥

---

## 1. LangSmithå¹³å°æ¦‚è¿°

### 1.1 ä»€ä¹ˆæ˜¯LangSmith

LangSmithæ˜¯LangChainç”Ÿæ€ç³»ç»Ÿä¸­çš„ä¼ä¸šçº§ç›‘æ§å’Œè°ƒè¯•å¹³å°ï¼Œä¸“ä¸ºLLMåº”ç”¨å’Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿè®¾è®¡ã€‚å®ƒæä¾›äº†å®Œæ•´çš„å¯è§‚æµ‹æ€§è§£å†³æ–¹æ¡ˆï¼Œå¸®åŠ©å¼€å‘è€…æ›´å¥½åœ°ç†è§£å’Œä¼˜åŒ–ä»–ä»¬çš„AIåº”ç”¨ã€‚

### 1.2 æ ¸å¿ƒä»·å€¼

- **å…¨é“¾è·¯è¿½è¸ª**ï¼šå®Œæ•´è®°å½•æ™ºèƒ½ä½“äº¤äº’è¿‡ç¨‹ï¼ŒåŒ…æ‹¬è¾“å…¥è¾“å‡ºå’Œä¸­é—´æ­¥éª¤
- **æ€§èƒ½ç›‘æ§**ï¼šå®æ—¶ç›‘æ§ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡ï¼Œå¦‚å“åº”æ—¶é—´ã€æˆåŠŸç‡ç­‰
- **è°ƒè¯•æ”¯æŒ**ï¼šæä¾›å¼ºå¤§çš„è°ƒè¯•å’Œæ•…éšœæ’é™¤å·¥å…·ï¼Œå¿«é€Ÿå®šä½é—®é¢˜
- **æ•°æ®åˆ†æ**ï¼šæ·±å…¥åˆ†ææ™ºèƒ½ä½“è¡Œä¸ºå’Œç³»ç»Ÿæ•ˆç‡ï¼Œæ”¯æŒæ•°æ®é©±åŠ¨çš„ä¼˜åŒ–
- **æˆæœ¬æ§åˆ¶**ï¼šç›‘æ§Tokenä½¿ç”¨é‡å’ŒAPIè°ƒç”¨æˆæœ¬
- **ä¼ä¸šçº§ç‰¹æ€§**ï¼šæ”¯æŒå¤šç§Ÿæˆ·ã€æƒé™ç®¡ç†ã€æ•°æ®å®‰å…¨ç­‰ä¼ä¸šéœ€æ±‚

### 1.3 ä¼ä¸šçº§æ¶æ„ç»„ä»¶

```python
# åŸºäºé¡¹ç›® multi_agent_system/src/monitoring/langsmith_integration.py çš„æ¶æ„è®¾è®¡
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from datetime import datetime
import uuid

@dataclass
class TracingContext:
    """è¿½è¸ªä¸Šä¸‹æ–‡"""
    trace_id: str
    span_id: str
    parent_span_id: Optional[str]
    operation_name: str
    start_time: datetime
    tags: Dict[str, Any]
    metadata: Dict[str, Any]

@dataclass
class RunMetrics:
    """è¿è¡ŒæŒ‡æ ‡"""
    run_id: str
    duration_ms: float
    token_usage: int
    cost_usd: float
    memory_usage_mb: float
    cpu_usage_percent: float
    success_rate: float
    error_count: int

class EnterpriseTracing:
    """ä¼ä¸šçº§å…¨é“¾è·¯è¿½è¸ªç³»ç»Ÿ"""
    
    def __init__(self, project_name: str, environment: str = "production"):
        self.project_name = project_name
        self.environment = environment
        self.active_traces: Dict[str, TracingContext] = {}
        self.metrics_buffer: List[RunMetrics] = []
        self.alert_thresholds = {
            "error_rate": 0.05,  # 5% é”™è¯¯ç‡é˜ˆå€¼
            "response_time": 5000,  # 5ç§’å“åº”æ—¶é—´é˜ˆå€¼
            "memory_usage": 80,  # 80% å†…å­˜ä½¿ç”¨ç‡é˜ˆå€¼
        }
    
    def start_trace(self, operation_name: str, 
                   parent_span_id: Optional[str] = None,
                   tags: Dict[str, Any] = None) -> str:
        """å¼€å§‹è¿½è¸ª"""
        trace_id = str(uuid.uuid4())
        span_id = str(uuid.uuid4())
        
        context = TracingContext(
            trace_id=trace_id,
            span_id=span_id,
            parent_span_id=parent_span_id,
            operation_name=operation_name,
            start_time=datetime.now(),
            tags=tags or {},
            metadata={}
        )
        
        self.active_traces[trace_id] = context
        return trace_id
    
    def end_trace(self, trace_id: str, 
                 outputs: Dict[str, Any] = None,
                 error: Optional[str] = None) -> RunMetrics:
        """ç»“æŸè¿½è¸ªå¹¶ç”ŸæˆæŒ‡æ ‡"""
        if trace_id not in self.active_traces:
            raise ValueError(f"Trace {trace_id} not found")
        
        context = self.active_traces[trace_id]
        end_time = datetime.now()
        duration_ms = (end_time - context.start_time).total_seconds() * 1000
        
        # ç”Ÿæˆè¿è¡ŒæŒ‡æ ‡
        metrics = RunMetrics(
            run_id=trace_id,
            duration_ms=duration_ms,
            token_usage=self._calculate_token_usage(outputs),
            cost_usd=self._calculate_cost(outputs),
            memory_usage_mb=self._get_memory_usage(),
            cpu_usage_percent=self._get_cpu_usage(),
            success_rate=1.0 if error is None else 0.0,
            error_count=1 if error else 0
        )
        
        self.metrics_buffer.append(metrics)
        
        # æ£€æŸ¥å‘Šè­¦é˜ˆå€¼
        self._check_alerts(metrics)
        
        # æ¸…ç†è¿½è¸ªä¸Šä¸‹æ–‡
        del self.active_traces[trace_id]
        
        return metrics
```

### 1.4 æ¨¡æ‹Ÿç¯å¢ƒä¸ç”Ÿäº§ç¯å¢ƒå¯¹æ¯”

| ç‰¹æ€§ | æ¨¡æ‹Ÿç¯å¢ƒ | ç”Ÿäº§ç¯å¢ƒ | è¯´æ˜ |
|------|---------|---------|------|
| **APIæ¥å£** | å®Œå…¨å…¼å®¹ | çœŸå®API | æ¥å£è®¾è®¡å®Œå…¨ä¸€è‡´ |
| **æ•°æ®å­˜å‚¨** | å†…å­˜å­˜å‚¨ | äº‘ç«¯å­˜å‚¨ | æ¨¡æ‹Ÿç¯å¢ƒæ•°æ®é‡å¯åæ¸…ç©º |
| **æ€§èƒ½æŒ‡æ ‡** | æ¨¡æ‹Ÿæ•°æ® | çœŸå®æ•°æ® | ç®—æ³•å’Œé€»è¾‘å®Œå…¨ç›¸åŒ |
| **å‘Šè­¦ç³»ç»Ÿ** | æœ¬åœ°æ—¥å¿— | å¤šæ¸ é“å‘Šè­¦ | æ”¯æŒé‚®ä»¶ã€çŸ­ä¿¡ã€é’‰é’‰ç­‰ |
| **æ•°æ®å¯è§†åŒ–** | ç®€åŒ–ç‰ˆæœ¬ | å®Œæ•´ä»ªè¡¨æ¿ | æ ¸å¿ƒå›¾è¡¨å’ŒæŒ‡æ ‡ä¸€è‡´ |
| **æƒé™ç®¡ç†** | ç®€åŒ–ç‰ˆæœ¬ | ä¼ä¸šçº§RBAC | æ”¯æŒå¤šç§Ÿæˆ·å’Œç»†ç²’åº¦æƒé™ |

> **ğŸš€ å¿«é€Ÿåˆ‡æ¢åˆ°ç”Ÿäº§ç¯å¢ƒ**ï¼š
>
> ```python
> # å¼€å‘/æµ‹è¯•ç¯å¢ƒ
> tracer = EnterpriseTracing(
>     project_name="my-project",
>     environment="development",
>     api_key="mock-key"  # ä½¿ç”¨æ¨¡æ‹Ÿå¯†é’¥
> )
> 
> # ç”Ÿäº§ç¯å¢ƒ
> tracer = EnterpriseTracing(
>     project_name="my-project", 
>     environment="production",
>     api_key=os.getenv("LANGSMITH_API_KEY")  # ä½¿ç”¨çœŸå®å¯†é’¥
> )
> ```

---

## 2. æ ¸å¿ƒåŠŸèƒ½è¯¦è§£

### 2.1 é“¾è·¯è¿½è¸ª(Tracing)

#### 2.1.1 åŸºæœ¬æ¦‚å¿µ

```python
from langsmith import Client
from langchain.callbacks import LangChainTracer

# åˆå§‹åŒ–LangSmithå®¢æˆ·ç«¯
client = Client(
    api_url="https://api.smith.langchain.com",
    api_key="your-api-key"
)

# é…ç½®è¿½è¸ªå™¨
tracer = LangChainTracer(
    project_name="multi-agent-system",
    client=client
)
```

#### 2.1.2 æ™ºèƒ½ä½“è¿½è¸ªå®ç°

```python
from langchain.schema import BaseMessage
from typing import List, Dict, Any

class TracedAgent:
    def __init__(self, name: str, tracer: LangChainTracer):
        self.name = name
        self.tracer = tracer
    
    def process_message(self, message: str, context: Dict[str, Any] = None):
        """å¸¦è¿½è¸ªçš„æ¶ˆæ¯å¤„ç†"""
        with self.tracer.trace(
            name=f"{self.name}_process",
            inputs={"message": message, "context": context}
        ) as trace:
            try:
                # æ¨¡æ‹Ÿæ™ºèƒ½ä½“å¤„ç†é€»è¾‘
                result = self._internal_process(message, context)
                trace.outputs = {"result": result}
                return result
            except Exception as e:
                trace.error = str(e)
                raise
    
    def _internal_process(self, message: str, context: Dict[str, Any]):
        # å®é™…å¤„ç†é€»è¾‘
        return f"Processed: {message}"
```

### 2.2 æ—¥å¿—ç®¡ç†

#### 2.2.1 ç»“æ„åŒ–æ—¥å¿—

```python
import logging
from langsmith import Client
from datetime import datetime

class LangSmithLogger:
    def __init__(self, project_name: str):
        self.client = Client()
        self.project_name = project_name
        
    def log_agent_action(self, agent_name: str, action: str, 
                        inputs: Dict, outputs: Dict, metadata: Dict = None):
        """è®°å½•æ™ºèƒ½ä½“è¡Œä¸º"""
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "agent_name": agent_name,
            "action": action,
            "inputs": inputs,
            "outputs": outputs,
            "metadata": metadata or {}
        }
        
        self.client.create_run(
            name=f"{agent_name}_{action}",
            project_name=self.project_name,
            inputs=inputs,
            outputs=outputs,
            extra=metadata
        )
```

### 2.3 æ€§èƒ½æŒ‡æ ‡æ”¶é›†

#### 2.3.1 å…³é”®æŒ‡æ ‡å®šä¹‰

```python
from dataclasses import dataclass
from typing import Optional
import time

@dataclass
class PerformanceMetrics:
    agent_name: str
    operation: str
    start_time: float
    end_time: Optional[float] = None
    duration: Optional[float] = None
    memory_usage: Optional[float] = None
    token_count: Optional[int] = None
    success: bool = True
    error_message: Optional[str] = None

class MetricsCollector:
    def __init__(self, langsmith_client: Client):
        self.client = langsmith_client
        self.metrics = []
    
    def start_operation(self, agent_name: str, operation: str) -> str:
        """å¼€å§‹æ“ä½œè®¡æ—¶"""
        run_id = f"{agent_name}_{operation}_{int(time.time())}"
        metric = PerformanceMetrics(
            agent_name=agent_name,
            operation=operation,
            start_time=time.time()
        )
        self.metrics.append(metric)
        return run_id
    
    def end_operation(self, run_id: str, success: bool = True, 
                     error_message: str = None):
        """ç»“æŸæ“ä½œè®¡æ—¶"""
        # æŸ¥æ‰¾å¯¹åº”çš„æŒ‡æ ‡è®°å½•å¹¶æ›´æ–°
        for metric in self.metrics:
            if f"{metric.agent_name}_{metric.operation}" in run_id:
                metric.end_time = time.time()
                metric.duration = metric.end_time - metric.start_time
                metric.success = success
                metric.error_message = error_message
                
                # å‘é€åˆ°LangSmith
                self._send_metrics(metric)
                break
    
    def _send_metrics(self, metric: PerformanceMetrics):
        """å‘é€æŒ‡æ ‡åˆ°LangSmith"""
        self.client.create_run(
            name=f"metrics_{metric.agent_name}_{metric.operation}",
            inputs={"operation": metric.operation},
            outputs={
                "duration": metric.duration,
                "success": metric.success,
                "memory_usage": metric.memory_usage,
                "token_count": metric.token_count
            },
            extra={
                "agent_name": metric.agent_name,
                "error_message": metric.error_message
            }
        )
```

---

## 3. é›†æˆå®ç°

### 3.1 LangGraph + LangSmithé›†æˆ

#### 3.1.1 åŸºç¡€é›†æˆé…ç½®

```python
from langgraph import StateGraph
from langsmith import Client
from langchain.callbacks import LangChainTracer
import os

# ç¯å¢ƒé…ç½®
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"
os.environ["LANGCHAIN_API_KEY"] = "your-api-key"
os.environ["LANGCHAIN_PROJECT"] = "multi-agent-system"

class MonitoredMultiAgentSystem:
    def __init__(self):
        self.client = Client()
        self.tracer = LangChainTracer(project_name="multi-agent-system")
        self.graph = self._build_graph()
    
    def _build_graph(self):
        """æ„å»ºå¸¦ç›‘æ§çš„æ™ºèƒ½ä½“å›¾"""
        graph = StateGraph(dict)
        
        # æ·»åŠ èŠ‚ç‚¹ï¼ˆæ™ºèƒ½ä½“ï¼‰
        graph.add_node("coordinator", self._coordinator_with_monitoring)
        graph.add_node("analyzer", self._analyzer_with_monitoring)
        graph.add_node("executor", self._executor_with_monitoring)
        
        # å®šä¹‰è¾¹
        graph.add_edge("coordinator", "analyzer")
        graph.add_edge("analyzer", "executor")
        graph.add_edge("executor", "coordinator")
        
        # è®¾ç½®å…¥å£ç‚¹
        graph.set_entry_point("coordinator")
        
        return graph.compile()
    
    def _coordinator_with_monitoring(self, state: dict):
        """å¸¦ç›‘æ§çš„åè°ƒå™¨æ™ºèƒ½ä½“"""
        with self.tracer.trace(
            name="coordinator_process",
            inputs=state
        ) as trace:
            try:
                # åè°ƒå™¨é€»è¾‘
                result = self._coordinate_tasks(state)
                trace.outputs = result
                return result
            except Exception as e:
                trace.error = str(e)
                raise
    
    def _analyzer_with_monitoring(self, state: dict):
        """å¸¦ç›‘æ§çš„åˆ†æå™¨æ™ºèƒ½ä½“"""
        with self.tracer.trace(
            name="analyzer_process",
            inputs=state
        ) as trace:
            try:
                # åˆ†æå™¨é€»è¾‘
                result = self._analyze_data(state)
                trace.outputs = result
                return result
            except Exception as e:
                trace.error = str(e)
                raise
    
    def _executor_with_monitoring(self, state: dict):
        """å¸¦ç›‘æ§çš„æ‰§è¡Œå™¨æ™ºèƒ½ä½“"""
        with self.tracer.trace(
            name="executor_process",
            inputs=state
        ) as trace:
            try:
                # æ‰§è¡Œå™¨é€»è¾‘
                result = self._execute_tasks(state)
                trace.outputs = result
                return result
            except Exception as e:
                trace.error = str(e)
                raise
```

### 3.2 è‡ªå®šä¹‰ç›‘æ§è£…é¥°å™¨

#### 3.2.1 æ™ºèƒ½ä½“ç›‘æ§è£…é¥°å™¨

```python
from functools import wraps
from typing import Callable, Any
import inspect

def monitor_agent(agent_name: str, operation: str = None):
    """æ™ºèƒ½ä½“ç›‘æ§è£…é¥°å™¨"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            # è·å–æ“ä½œåç§°
            op_name = operation or func.__name__
            
            # å¼€å§‹è¿½è¸ª
            with LangChainTracer().trace(
                name=f"{agent_name}_{op_name}",
                inputs={"args": args, "kwargs": kwargs}
            ) as trace:
                try:
                    # æ‰§è¡ŒåŸå‡½æ•°
                    result = func(*args, **kwargs)
                    trace.outputs = {"result": result}
                    return result
                except Exception as e:
                    trace.error = str(e)
                    raise
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
class SmartAgent:
    @monitor_agent("smart_agent", "process_request")
    def process_request(self, request: str) -> str:
        """å¤„ç†è¯·æ±‚"""
        # å®é™…å¤„ç†é€»è¾‘
        return f"Processed: {request}"
    
    @monitor_agent("smart_agent", "analyze_data")
    def analyze_data(self, data: dict) -> dict:
        """åˆ†ææ•°æ®"""
        # åˆ†æé€»è¾‘
        return {"analysis": "completed", "insights": ["insight1", "insight2"]}
```

---

## 4. ç›‘æ§ä¸åˆ†æ

### 4.1 å®æ—¶ç›‘æ§é¢æ¿

#### 4.1.1 å…³é”®æŒ‡æ ‡ç›‘æ§

```python
from langsmith import Client
from typing import List, Dict
import asyncio

class RealTimeMonitor:
    def __init__(self, project_name: str):
        self.client = Client()
        self.project_name = project_name
        self.is_monitoring = False
    
    async def start_monitoring(self, interval: int = 30):
        """å¼€å§‹å®æ—¶ç›‘æ§"""
        self.is_monitoring = True
        while self.is_monitoring:
            try:
                metrics = await self._collect_metrics()
                await self._analyze_metrics(metrics)
                await asyncio.sleep(interval)
            except Exception as e:
                print(f"ç›‘æ§é”™è¯¯: {e}")
    
    async def _collect_metrics(self) -> Dict:
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        runs = self.client.list_runs(
            project_name=self.project_name,
            limit=100
        )
        
        metrics = {
            "total_runs": len(runs),
            "success_rate": 0,
            "avg_duration": 0,
            "error_count": 0,
            "agent_performance": {}
        }
        
        if runs:
            successful_runs = [r for r in runs if not r.error]
            metrics["success_rate"] = len(successful_runs) / len(runs)
            
            durations = [r.total_time for r in runs if r.total_time]
            if durations:
                metrics["avg_duration"] = sum(durations) / len(durations)
            
            metrics["error_count"] = len(runs) - len(successful_runs)
        
        return metrics
    
    async def _analyze_metrics(self, metrics: Dict):
        """åˆ†ææŒ‡æ ‡å¹¶ç”Ÿæˆå‘Šè­¦"""
        # æ€§èƒ½å‘Šè­¦
        if metrics["avg_duration"] > 5.0:  # 5ç§’é˜ˆå€¼
            await self._send_alert("æ€§èƒ½å‘Šè­¦", f"å¹³å‡å“åº”æ—¶é—´è¿‡é•¿: {metrics['avg_duration']:.2f}s")
        
        # é”™è¯¯ç‡å‘Šè­¦
        if metrics["success_rate"] < 0.95:  # 95%æˆåŠŸç‡é˜ˆå€¼
            await self._send_alert("é”™è¯¯ç‡å‘Šè­¦", f"æˆåŠŸç‡è¿‡ä½: {metrics['success_rate']:.2%}")
    
    async def _send_alert(self, alert_type: str, message: str):
        """å‘é€å‘Šè­¦"""
        print(f"[{alert_type}] {message}")
        # è¿™é‡Œå¯ä»¥é›†æˆé‚®ä»¶ã€Slackç­‰å‘Šè­¦æ¸ é“
```

### 4.2 æ•°æ®åˆ†æä¸æ´å¯Ÿ

#### 4.2.1 æ™ºèƒ½ä½“è¡Œä¸ºåˆ†æ

```python
import pandas as pd
import matplotlib.pyplot as plt
from typing import List, Dict

class AgentAnalytics:
    def __init__(self, langsmith_client: Client):
        self.client = langsmith_client
    
    def analyze_agent_performance(self, agent_name: str, 
                                 time_range: int = 24) -> Dict:
        """åˆ†ææ™ºèƒ½ä½“æ€§èƒ½"""
        # è·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„è¿è¡Œæ•°æ®
        runs = self.client.list_runs(
            project_name="multi-agent-system",
            filter=f"name LIKE '%{agent_name}%'",
            limit=1000
        )
        
        if not runs:
            return {"error": "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ•°æ®"}
        
        # è½¬æ¢ä¸ºDataFrameè¿›è¡Œåˆ†æ
        data = []
        for run in runs:
            data.append({
                "timestamp": run.start_time,
                "duration": run.total_time or 0,
                "success": not bool(run.error),
                "tokens": run.prompt_tokens + run.completion_tokens if hasattr(run, 'prompt_tokens') else 0,
                "operation": run.name
            })
        
        df = pd.DataFrame(data)
        
        # è®¡ç®—å…³é”®æŒ‡æ ‡
        analysis = {
            "total_operations": len(df),
            "success_rate": df["success"].mean(),
            "avg_duration": df["duration"].mean(),
            "max_duration": df["duration"].max(),
            "min_duration": df["duration"].min(),
            "total_tokens": df["tokens"].sum(),
            "operations_per_hour": self._calculate_ops_per_hour(df),
            "performance_trend": self._calculate_trend(df)
        }
        
        return analysis
    
    def _calculate_ops_per_hour(self, df: pd.DataFrame) -> float:
        """è®¡ç®—æ¯å°æ—¶æ“ä½œæ•°"""
        if df.empty:
            return 0
        
        time_span = (df["timestamp"].max() - df["timestamp"].min()).total_seconds() / 3600
        return len(df) / max(time_span, 1)
    
    def _calculate_trend(self, df: pd.DataFrame) -> str:
        """è®¡ç®—æ€§èƒ½è¶‹åŠ¿"""
        if len(df) < 10:
            return "æ•°æ®ä¸è¶³"
        
        # æŒ‰æ—¶é—´æ’åºå¹¶è®¡ç®—ç§»åŠ¨å¹³å‡
        df_sorted = df.sort_values("timestamp")
        df_sorted["duration_ma"] = df_sorted["duration"].rolling(window=10).mean()
        
        # æ¯”è¾ƒæœ€è¿‘å’Œæ—©æœŸçš„å¹³å‡å€¼
        recent_avg = df_sorted["duration_ma"].tail(10).mean()
        early_avg = df_sorted["duration_ma"].head(10).mean()
        
        if recent_avg > early_avg * 1.1:
            return "æ€§èƒ½ä¸‹é™"
        elif recent_avg < early_avg * 0.9:
            return "æ€§èƒ½æå‡"
        else:
            return "æ€§èƒ½ç¨³å®š"
```

---

## 5. æ€§èƒ½ä¼˜åŒ–

### 5.1 åŸºäºç›‘æ§æ•°æ®çš„ä¼˜åŒ–

#### 5.1.1 è‡ªåŠ¨ä¼˜åŒ–å»ºè®®

```python
class PerformanceOptimizer:
    def __init__(self, analytics: AgentAnalytics):
        self.analytics = analytics
    
    def generate_optimization_suggestions(self, agent_name: str) -> List[Dict]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        analysis = self.analytics.analyze_agent_performance(agent_name)
        suggestions = []
        
        # å“åº”æ—¶é—´ä¼˜åŒ–
        if analysis["avg_duration"] > 3.0:
            suggestions.append({
                "type": "performance",
                "priority": "high",
                "issue": "å“åº”æ—¶é—´è¿‡é•¿",
                "suggestion": "è€ƒè™‘ä¼˜åŒ–æ¨¡å‹è°ƒç”¨ã€å¢åŠ ç¼“å­˜æˆ–å¹¶è¡Œå¤„ç†",
                "expected_improvement": "30-50%å“åº”æ—¶é—´å‡å°‘"
            })
        
        # æˆåŠŸç‡ä¼˜åŒ–
        if analysis["success_rate"] < 0.95:
            suggestions.append({
                "type": "reliability",
                "priority": "critical",
                "issue": "æˆåŠŸç‡è¿‡ä½",
                "suggestion": "å¢åŠ é”™è¯¯å¤„ç†ã€é‡è¯•æœºåˆ¶å’Œè¾“å…¥éªŒè¯",
                "expected_improvement": "æˆåŠŸç‡æå‡è‡³98%+"
            })
        
        # èµ„æºä½¿ç”¨ä¼˜åŒ–
        if analysis["total_tokens"] > 100000:
            suggestions.append({
                "type": "cost",
                "priority": "medium",
                "issue": "Tokenä½¿ç”¨é‡è¿‡é«˜",
                "suggestion": "ä¼˜åŒ–æç¤ºè¯ã€ä½¿ç”¨æ›´å°çš„æ¨¡å‹æˆ–å®ç°æ™ºèƒ½ç¼“å­˜",
                "expected_improvement": "20-40%æˆæœ¬é™ä½"
            })
        
        return suggestions
    
    def implement_caching_optimization(self, agent_class):
        """å®ç°ç¼“å­˜ä¼˜åŒ–"""
        from functools import lru_cache
        import hashlib
        
        class CachedAgent(agent_class):
            def __init__(self, *args, **kwargs):
                super().__init__(*args, **kwargs)
                self._cache = {}
            
            def _get_cache_key(self, inputs: Dict) -> str:
                """ç”Ÿæˆç¼“å­˜é”®"""
                content = str(sorted(inputs.items()))
                return hashlib.md5(content.encode()).hexdigest()
            
            def process_with_cache(self, inputs: Dict, ttl: int = 3600):
                """å¸¦ç¼“å­˜çš„å¤„ç†"""
                cache_key = self._get_cache_key(inputs)
                
                # æ£€æŸ¥ç¼“å­˜
                if cache_key in self._cache:
                    cached_result, timestamp = self._cache[cache_key]
                    if time.time() - timestamp < ttl:
                        return cached_result
                
                # æ‰§è¡Œå¤„ç†
                result = self.process(inputs)
                
                # å­˜å‚¨åˆ°ç¼“å­˜
                self._cache[cache_key] = (result, time.time())
                
                return result
        
        return CachedAgent
```

### 5.2 æ™ºèƒ½è´Ÿè½½å‡è¡¡

#### 5.2.1 åŸºäºæ€§èƒ½çš„è´Ÿè½½åˆ†é…

```python
import heapq
from typing import List, Dict, Any

class IntelligentLoadBalancer:
    def __init__(self, agents: List[Any]):
        self.agents = agents
        self.agent_metrics = {id(agent): {"load": 0, "avg_response_time": 0} 
                             for agent in agents}
    
    def select_optimal_agent(self, task_complexity: float = 1.0) -> Any:
        """é€‰æ‹©æœ€ä¼˜æ™ºèƒ½ä½“"""
        # è®¡ç®—æ¯ä¸ªæ™ºèƒ½ä½“çš„è´Ÿè½½åˆ†æ•°
        scores = []
        for agent in self.agents:
            agent_id = id(agent)
            metrics = self.agent_metrics[agent_id]
            
            # ç»¼åˆè€ƒè™‘è´Ÿè½½å’Œå“åº”æ—¶é—´
            score = (metrics["load"] * 0.6 + 
                    metrics["avg_response_time"] * 0.4) * task_complexity
            
            heapq.heappush(scores, (score, agent))
        
        # è¿”å›è´Ÿè½½æœ€ä½çš„æ™ºèƒ½ä½“
        _, optimal_agent = heapq.heappop(scores)
        return optimal_agent
    
    def update_agent_metrics(self, agent: Any, response_time: float):
        """æ›´æ–°æ™ºèƒ½ä½“æŒ‡æ ‡"""
        agent_id = id(agent)
        metrics = self.agent_metrics[agent_id]
        
        # æ›´æ–°å¹³å‡å“åº”æ—¶é—´ï¼ˆæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰
        alpha = 0.3
        metrics["avg_response_time"] = (
            alpha * response_time + 
            (1 - alpha) * metrics["avg_response_time"]
        )
        
        # æ›´æ–°è´Ÿè½½ï¼ˆç®€å•é€’å‡ï¼‰
        metrics["load"] = max(0, metrics["load"] - 0.1)
    
    def assign_task(self, task: Dict[str, Any]) -> Any:
        """åˆ†é…ä»»åŠ¡"""
        # è¯„ä¼°ä»»åŠ¡å¤æ‚åº¦
        complexity = self._evaluate_task_complexity(task)
        
        # é€‰æ‹©æœ€ä¼˜æ™ºèƒ½ä½“
        agent = self.select_optimal_agent(complexity)
        
        # å¢åŠ è´Ÿè½½
        agent_id = id(agent)
        self.agent_metrics[agent_id]["load"] += complexity
        
        return agent
    
    def _evaluate_task_complexity(self, task: Dict[str, Any]) -> float:
        """è¯„ä¼°ä»»åŠ¡å¤æ‚åº¦"""
        # ç®€å•çš„å¤æ‚åº¦è¯„ä¼°é€»è¾‘
        base_complexity = 1.0
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹è°ƒæ•´
        if task.get("type") == "analysis":
            base_complexity *= 1.5
        elif task.get("type") == "generation":
            base_complexity *= 2.0
        
        # æ ¹æ®æ•°æ®é‡è°ƒæ•´
        data_size = len(str(task.get("data", "")))
        if data_size > 1000:
            base_complexity *= 1.2
        
        return base_complexity
```

---

## 6. å®è·µç»ƒä¹ 

### ç»ƒä¹ 1ï¼šåŸºç¡€ç›‘æ§é›†æˆ

**ç›®æ ‡**ï¼šä¸ºç°æœ‰çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿé›†æˆLangSmithç›‘æ§

**ä»»åŠ¡**ï¼š

1. é…ç½®LangSmithç¯å¢ƒ
2. ä¸ºæ™ºèƒ½ä½“æ·»åŠ åŸºç¡€è¿½è¸ª
3. å®ç°æ—¥å¿—æ”¶é›†
4. åˆ›å»ºç®€å•çš„ç›‘æ§é¢æ¿

**ä»£ç æ¡†æ¶**ï¼š

```python
# å­¦å‘˜éœ€è¦å®Œæˆçš„ä»£ç 
class MonitoredAgent:
    def __init__(self, name: str):
        self.name = name
        # TODO: åˆå§‹åŒ–LangSmithå®¢æˆ·ç«¯å’Œè¿½è¸ªå™¨
    
    def process_task(self, task: str):
        # TODO: æ·»åŠ ç›‘æ§å’Œè¿½è¸ªé€»è¾‘
        pass
    
    def get_performance_metrics(self):
        # TODO: è·å–æ€§èƒ½æŒ‡æ ‡
        pass
```

### ç»ƒä¹ 2ï¼šæ€§èƒ½åˆ†æä¸ä¼˜åŒ–

**ç›®æ ‡**ï¼šåˆ†ææ™ºèƒ½ä½“æ€§èƒ½å¹¶å®ç°ä¼˜åŒ–

**ä»»åŠ¡**ï¼š

1. æ”¶é›†æ€§èƒ½æ•°æ®
2. åˆ†æç“¶é¢ˆ
3. å®ç°ç¼“å­˜æœºåˆ¶
4. éªŒè¯ä¼˜åŒ–æ•ˆæœ

### ç»ƒä¹ 3ï¼šå‘Šè­¦ç³»ç»Ÿå®ç°

**ç›®æ ‡**ï¼šæ„å»ºæ™ºèƒ½å‘Šè­¦ç³»ç»Ÿ

**ä»»åŠ¡**ï¼š

1. å®šä¹‰å‘Šè­¦è§„åˆ™
2. å®ç°å‘Šè­¦è§¦å‘é€»è¾‘
3. é›†æˆé€šçŸ¥æ¸ é“
4. æµ‹è¯•å‘Šè­¦åŠŸèƒ½

## æ€»ç»“

æœ¬è¯¾ç¨‹æ¶µç›–äº†LangSmithç›‘æ§å¹³å°çš„æ ¸å¿ƒåŠŸèƒ½å’Œé›†æˆæ–¹æ³•ï¼Œé€šè¿‡å®è·µç»ƒä¹ å¸®åŠ©å­¦å‘˜æŒæ¡ï¼š

1. **ç›‘æ§é›†æˆ**ï¼šå®Œæ•´çš„LangSmithé›†æˆæµç¨‹
2. **æ€§èƒ½åˆ†æ**ï¼šæ·±å…¥çš„æ€§èƒ½åˆ†æå’Œä¼˜åŒ–æŠ€æœ¯
3. **å®æ—¶ç›‘æ§**ï¼šæ„å»ºå®æ—¶ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ
4. **æœ€ä½³å®è·µ**ï¼šä¼ä¸šçº§ç›‘æ§çš„æœ€ä½³å®è·µ

ä¸‹ä¸€è¯¾ç¨‹å°†å­¦ä¹ ä¼ä¸šçº§ç³»ç»Ÿæ¶æ„è®¾è®¡ä¸å®ç°ã€‚
