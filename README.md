# AI Fundamentals

åŸåŠ›æ³¨å…¥ AI åŸºç¡€çŸ¥è¯†

## ç¬¬ä¸€éƒ¨åˆ†ï¼šç¡¬ä»¶åŸºç¡€

### 1. ç›¸å…³ç¡¬ä»¶çŸ¥è¯†

- [PCIe çŸ¥è¯†å¤§å…¨](https://mp.weixin.qq.com/s/dHvKYcZoa4rcF90LLyo_0A)
- [NVLink å…¥é—¨](https://mp.weixin.qq.com/s/fP69UEgusOa_X4ZKLo30ig)
- [NVIDIA DGX SuperPODï¼šä¸‹ä¸€ä»£å¯æ‰©å±•çš„AIé¢†å¯¼åŸºç¡€è®¾æ–½](https://mp.weixin.qq.com/s/a64Qb6DuAAZnCTBy8g1p2Q)

### 2. æ·±å…¥ç†è§£ GPU æ¶æ„

åœ¨å‡†å¤‡åœ¨ GPU ä¸Šè¿è¡Œçš„åº”ç”¨ç¨‹åºæ—¶ï¼Œäº†è§£ GPU ç¡¬ä»¶è®¾è®¡çš„ä¸»è¦ç‰¹æ€§å¹¶äº†è§£ä¸ CPU çš„ç›¸ä¼¼ä¹‹å¤„å’Œä¸åŒä¹‹å¤„ä¼šå¾ˆæœ‰å¸®åŠ©ã€‚æœ¬è·¯çº¿å›¾é€‚ç”¨äºé‚£äº›å¯¹ GPU æ¯”è¾ƒé™Œç”Ÿæˆ–åªæ˜¯æƒ³äº†è§£æ›´å¤šæœ‰å…³ GPU ä¸­è®¡ç®—æœºæŠ€æœ¯çš„äººã€‚ä¸éœ€è¦ç‰¹å®šçš„å¹¶è¡Œç¼–ç¨‹ç»éªŒï¼Œç»ƒä¹ åŸºäº CUDA å·¥å…·åŒ…ä¸­åŒ…å«çš„æ ‡å‡† NVIDIA ç¤ºä¾‹ç¨‹åºã€‚

- [GPU ç‰¹æ€§](gpu_architecture/gpu_characteristics.md)
- [GPU å†…å­˜](gpu_architecture/gpu_memory.md)
- [GPU Example: Tesla V100](gpu_architecture/tesla_v100.md)
- [GPUs on Frontera: RTX 5000](gpu_architecture/rtx_5000.md)
- ç»ƒä¹ ï¼š
  - [Exercise: Device Query](gpu_architecture/exer_device_query.md)
  - [Exercise: Device Bandwidth](gpu_architecture/exer_device_bandwidth.md)

#### 2.1 GPU æ¶æ„å’Œç¼–ç¨‹æ¨¡å‹ä»‹ç»

- [GPU Architecture and Programming â€” An Introduction](gpu_programming/gpu_programming_introduction.md)

#### 2.2 å…¶ä»–ç›¸å…³çŸ¥è¯†ç‚¹

- [æ·±å…¥ç†è§£ Nvidia CUDA æ ¸å¿ƒï¼ˆvs. Tensor Cores vs. RT Cores)](cuda/cuda_cores_cn.md)

### 3. AI åŸºç¡€è®¾æ–½

- [é«˜æ€§èƒ½ GPU æœåŠ¡å™¨ç¡¬ä»¶æ‹“æ‰‘ä¸é›†ç¾¤ç»„ç½‘](https://arthurchiao.art/blog/gpu-advanced-notes-1-zh/)
- [NVIDIA GH200 èŠ¯ç‰‡ã€æœåŠ¡å™¨åŠé›†ç¾¤ç»„ç½‘](https://arthurchiao.art/blog/gpu-advanced-notes-4-zh/)
- [æ·±åº¦å­¦ä¹ ï¼ˆå¤§æ¨¡å‹ï¼‰ä¸­çš„ç²¾åº¦](https://mp.weixin.qq.com/s/b08gFicrKNCfrwSlpsecmQ)

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šç¼–ç¨‹ä¸å¼€å‘

### 4. CUDA å­¦ä¹ ææ–™

#### 4.1 å¿«é€Ÿå…¥é—¨

- [å¹¶è¡Œè®¡ç®—ã€è´¹æ—åˆ†ç±»æ³•å’Œ CUDA åŸºæœ¬æ¦‚å¿µ](https://mp.weixin.qq.com/s/NL_Bz8JB-LdAtrQake7EdA)
- [CUDA ç¼–ç¨‹æ¨¡å‹å…¥é—¨](https://mp.weixin.qq.com/s/IUYzzgt6DUYhfaDnbxoZuQ)
- [CUDA å¹¶å‘ç¼–ç¨‹ä¹‹ Stream ä»‹ç»](cuda/cuda_streams.md)

#### 4.2 å‚è€ƒèµ„æ–™

- [CUDA Reading Group ç›¸å…³è®²åº§](https://mp.weixin.qq.com/s/6sOrNzG0UeVBes8stWSoWA): [GPU Mode Reading Group](https://github.com/gpu-mode)
- [ã€ŠCUDA C++ Programming Guideã€‹](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html)
- [ã€ŠCUDA C ç¼–ç¨‹æƒå¨æŒ‡å—ã€‹](https://mp.weixin.qq.com/s/xJY5Znv3cuQi_UCd_XjJ4A)ï¼š[ä¹¦ä¸­ç¤ºä¾‹ä»£ç ](https://github.com/Eddie-Wang1120/Professional-CUDA-C-Programming-Code-and-Notes)
- [Nvidia å®˜æ–¹ CUDA æ˜¯ç¤ºä¾‹](https://github.com/NVIDIA/cuda-samples)
- [ã€ŠCUDA ç¼–ç¨‹ï¼šåŸºç¡€ä¸å®è·µ by æ¨Šå“²å‹‡ã€‹](https://book.douban.com/subject/35252459/)
  - [å­¦ä¹ ç¬”è®°](https://github.com/QINZHAOYU/CudaSteps)
  - [ç¤ºä¾‹ä»£ç ](https://github.com/MAhaitao999/CUDA_Programming)
- [ã€ŠCUDA ç¼–ç¨‹ç®€ä»‹: åŸºç¡€ä¸å®è·µ by æç‘œã€‹](http://www.frankyongtju.cn/ToSeminars/hpc.pdf)
- [ã€ŠCUDA ç¼–ç¨‹å…¥é—¨ã€‹ - æœ¬æ–‡æ”¹ç¼–è‡ªåŒ—äº¬å¤§å­¦è¶…ç®—é˜Ÿ CUDA æ•™ç¨‹è®²ä¹‰](https://hpcwiki.io/gpu/cuda/)
- [Multi GPU Programming Models](https://github.com/NVIDIA/multi-gpu-programming-models)
- [CUDA Processing Streams](https://turing.une.edu.au/~cosc330/lectures/display_lecture.php?lecture=22#1)

#### 4.3 ä¸“ä¸šé€‰æ‰‹

[**CUDA-Learn-Notes**](https://github.com/xlite-dev/CUDA-Learn-Notes)ï¼šğŸ“šModern CUDA Learn Notes: 200+ Tensor/CUDA Cores KernelsğŸ‰, HGEMM, FA2 via MMA and CuTe, 98~100% TFLOPS of cuBLAS/FA2.

### 5. ç›‘æ§ä¸è¿ç»´

- [nvidia-smi å…¥é—¨](ops/nvidia-smi.md)
- [nvtop å…¥é—¨](ops/nvtop.md)
- [Nvidia GPU XID æ•…éšœç è§£æ](https://mp.weixin.qq.com/s/ekCnhr3qrhjuX_-CEyx65g)
- [Nvidia GPU å¡ ä¹‹ ECC åŠŸèƒ½](https://mp.weixin.qq.com/s/nmZVOQAyfFyesm79HzjUlQ)
- [æŸ¥è¯¢ GPU å¡è¯¦ç»†å‚æ•°](ops/DeviceQuery.md)
- [Understanding NVIDIA GPU Performance: Utilization vs. Saturation (2023)](https://arthurchiao.art/blog/understanding-gpu-performance/)
- [GPU Utilization is a Misleading Metric](ops/gpu_utils.md)ï¼š[GPU åˆ©ç”¨ç‡æ˜¯ä¸€ä¸ªè¯¯å¯¼æ€§æŒ‡æ ‡](ops/GPU%20åˆ©ç”¨ç‡æ˜¯ä¸€ä¸ªè¯¯å¯¼æ€§æŒ‡æ ‡.md)

### 6. æ€§èƒ½åˆ†æä¸è°ƒä¼˜

- [ä½¿ç”¨ Nsight Compute Tool åˆ†æ CUDA çŸ©é˜µä¹˜æ³•ç¨‹åº](https://www.yuque.com/u41800946/nquqpa/eo7gykiyhg8xi2gg)
- [CUDA Kernel Profiling using Nvidia Nsight Compute](profiling/s9345-cuda-kernel-profiling-using-nvidia-nsight-compute.pdf)

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šæœºå™¨å­¦ä¹ åŸºç¡€

### 7. æ·±åº¦å­¦ä¹ /æœºå™¨å­¦ä¹ 

- [ã€Šæœºå™¨å­¦ä¹ ç³»ç»Ÿï¼šè®¾è®¡å’Œå®ç°ã€‹](https://openmlsys.github.io/index.html)
- [ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹](https://zh.d2l.ai/)

---

## ç¬¬å››éƒ¨åˆ†ï¼šå¤§è¯­è¨€æ¨¡å‹

### 8. LLM åŸºç¡€ç†è®º

#### 8.1 æ ¸å¿ƒæ¦‚å¿µ

- [Andrej Karpathyï¼šDeep Dive into LLMs like ChatGPTï¼ˆBç«™è§†é¢‘ï¼‰](https://www.bilibili.com/video/BV16cNEeXEer)
- [å¤§æ¨¡å‹åŸºç¡€ç»„ä»¶ - Tokenizer](https://zhuanlan.zhihu.com/p/651430181)
- [è§£å¯†å¤§è¯­è¨€æ¨¡å‹ä¸­çš„ Tokens](llm/token/llm_token_intro.md)
  - [Tiktokenizer åœ¨çº¿ç‰ˆ](https://tiktokenizer.vercel.app/?model=gpt-4o)
- [æ–‡æœ¬åµŒå…¥ï¼ˆText-Embeddingï¼‰ æŠ€æœ¯å¿«é€Ÿå…¥é—¨](llm/embedding/text_embeddings_guide.md)
- [LLM åµŒå…¥æŠ€æœ¯è¯¦è§£ï¼šå›¾æ–‡æŒ‡å—](llm/embedding/LLM%20Embeddings%20Explained%20-%20A%20Visual%20and%20Intuitive%20Guide.zh-CN.md)
- [å¤§æ¨¡å‹ Embedding å±‚ä¸ç‹¬ç«‹ Embedding æ¨¡å‹ï¼šåŒºåˆ«ä¸è”ç³»](llm/embedding/embedding.md)
- [å¤§æ¨¡å‹å¯è§†åŒ–æŒ‡å—](https://www.maartengrootendorst.com/)
- [ä¸€æ–‡è¯»æ‡‚æ€ç»´é“¾ï¼ˆChain-of-Thought, CoTï¼‰](llm/ä¸€æ–‡è¯»æ‡‚æ€ç»´é“¾ï¼ˆChain-of-Thought,%20CoTï¼‰.md)
- [å¤§æ¨¡å‹çš„å¹»è§‰åŠå…¶åº”å¯¹æªæ–½](llm/å¤§æ¨¡å‹çš„å¹»è§‰åŠå…¶åº”å¯¹æªæ–½.md)
- [å¤§æ¨¡å‹æ–‡ä»¶æ ¼å¼å®Œæ•´æŒ‡å—](llm/å¤§æ¨¡å‹æ–‡ä»¶æ ¼å¼å®Œæ•´æŒ‡å—.md)
- [æ··åˆä¸“å®¶ç³»ç»Ÿï¼ˆMoEï¼‰å›¾è§£æŒ‡å—](llm/A%20Visual%20Guide%20to%20Mixture%20of%20Experts%20(MoE).zh-CN.md)
- [é‡åŒ–æŠ€æœ¯å¯è§†åŒ–æŒ‡å—](llm/A%20Visual%20Guide%20to%20Quantization.zh-CN.md)
- [åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ„å›¾æ£€æµ‹](llm/Intent%20Detection%20using%20LLM.zh-CN.md)
- [Mooncake æ¶æ„è¯¦è§£ï¼šä»¥ KV ç¼“å­˜ä¸ºä¸­å¿ƒçš„é«˜æ•ˆ LLM æ¨ç†ç³»ç»Ÿè®¾è®¡](llm/Mooncake%20æ¶æ„è¯¦è§£ï¼šä»¥%20KV%20ç¼“å­˜ä¸ºä¸­å¿ƒçš„é«˜æ•ˆ%20LLM%20æ¨ç†ç³»ç»Ÿè®¾è®¡.md)
- [vLLM + LWSï¼šKubernetes ä¸Šçš„å¤šæœºå¤šå¡æ¨ç†æ–¹æ¡ˆ](llm/lws_intro.md)

#### 8.2 å‚è€ƒä¹¦ç±

- [å¤§æ¨¡å‹åŸºç¡€](https://github.com/ZJU-LLMs/Foundations-of-LLMs) <br>
 <img src="https://raw.githubusercontent.com/ZJU-LLMs/Foundations-of-LLMs/main/figure/cover.png" height="300"/>
- [Hands-On Large Language Models](https://github.com/HandsOnLLM/Hands-On-Large-Language-Models) <br>
 <img src="https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/book_cover.png" height="300"/>

### 9. LLM è®­ç»ƒ

#### 9.1 å¾®è°ƒæŠ€æœ¯

- [**Qwen 2 å¤§æ¨¡å‹æŒ‡ä»¤å¾®è°ƒå…¥é—¨å®æˆ˜**](https://mp.weixin.qq.com/s/Atf61jocM3FBoGjZ_DZ1UA)
  - [é…å¥—ä»£ç ](llm/fine-tuning/train_qwen2.ipynb)
- [ä¸€æ–‡å…¥é—¨å‚åŸŸæ¨¡å‹SFTå¾®è°ƒ](llm/ä¸€æ–‡å…¥é—¨å‚åŸŸæ¨¡å‹SFTå¾®è°ƒ.md)

#### 9.2 ä»é›¶å¼€å§‹è®­ç»ƒå¤§æ¨¡å‹

- [Training a 70B model from scratch: open-source tools, evaluation datasets, and learnings](https://imbue.com/research/70b-intro/)
- [Sanitized open-source datasets for natural language and code understanding: how we evaluated our 70B model](https://imbue.com/research/70b-evals/)
- [From bare metal to a 70B model: infrastructure set-up and scripts](https://imbue.com/research/70b-infrastructure/)
- [Open-sourcing CARBS: how we used our hyperparameter optimizer to scale up to a 70B-parameter language model](https://imbue.com/research/70b-carbs/)

### 10. LLM åº”ç”¨å¼€å‘

#### 10.1 RAG æŠ€æœ¯

- [**ä»0åˆ°1å¿«é€Ÿæ­å»ºRAGåº”ç”¨**](https://mp.weixin.qq.com/s/89-bwZ4aPor4ySj5U3n5zw)
  - [é…å¥—ä»£ç ](llm/rag/lession2.ipynb)
- [Evaluating Chunking Strategies for Retrieval æ€»ç»“](llm/rag/Evaluating Chunking Strategies for Retrieval æ€»ç»“.md)
- [ä¸­æ–‡RAGç³»ç»ŸEmbeddingæ¨¡å‹é€‰å‹æŠ€æœ¯æ–‡æ¡£](llm/rag/ä¸­æ–‡RAGç³»ç»ŸEmbeddingæ¨¡å‹é€‰å‹æŠ€æœ¯æ–‡æ¡£.md)

#### 10.2 AI Agent å¼€å‘

- [**LangChain + æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ï¼šAI æ™ºèƒ½ä½“ Demo**](llm/agent/README.md)
- [AI Agents for Beginners è¯¾ç¨‹ä¹‹ AI AgentåŠä½¿ç”¨åœºæ™¯ç®€ä»‹](llm/AI%20Agents%20for%20Beginners%20è¯¾ç¨‹ä¹‹%20AI%20AgentåŠä½¿ç”¨åœºæ™¯ç®€ä»‹.md)
- [A Deep Dive Into MCP and the Future of AI Tooling](llm/mcp/A_Deep_Dive_Into_MCP_and_the_Future_of_AI_Tooling_zh_CN.md)
- [LangGraph å®æˆ˜ï¼šç”¨ Python æ‰“é€ æœ‰çŠ¶æ€æ™ºèƒ½ä½“](llm/langgraph/langgraph_intro.md)
- [n8n_multi_agent_guide](llm/n8n_multi_agent_guide.md)
- [å¼€æºå¤§æ¨¡å‹åº”ç”¨ç¼–æ’å¹³å°ï¼šDifyã€AnythingLLMã€Ragflow ä¸ n8n çš„åŠŸèƒ½ä¸å•†ç”¨è®¸å¯å¯¹æ¯”åˆ†æ](llm/å¼€æºå¤§æ¨¡å‹åº”ç”¨ç¼–æ’å¹³å°ï¼šDifyã€AnythingLLMã€Ragflow%20ä¸%20n8n%20çš„åŠŸèƒ½ä¸å•†ç”¨è®¸å¯å¯¹æ¯”åˆ†æ.md)

---

## ç¬¬äº”éƒ¨åˆ†ï¼šå®è·µæ¡ˆä¾‹

### 11. æ¨¡å‹éƒ¨ç½²ä¸æ¨ç†

- [ollama benchmark](llm/ollama/README.md)
- [åœ¨ Mac ä¸Šè¿è¡Œ DeepSeek-R1 æ¨¡å‹](deepseek/mac-deepseek-r1.md)
- [DeepSeek r1 è’¸é¦æ¨¡å‹å’Œæ»¡è¡€æ¨¡å‹å¯¹æ¯”](deepseek/deepseek-r1-cmp.md)
- [Deepseek 3FSï¼ˆ Fire-Flyer File Systemï¼‰è®¾è®¡ç¬”è®°](deepseek/deepseek_3fs_design_notes.zh-CN.md)

### 12. æ–‡æ¡£å¤„ç†å·¥å…·

- [æ·±å…¥æ¢ç´¢ï¼šAI é©±åŠ¨çš„ PDF å¸ƒå±€æ£€æµ‹å¼•æ“æºä»£ç è§£æ](llm/marker.zh-CN.md)
- [ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤å¼€æºå·¥å…· MinerU åŠ©åŠ›å¤æ‚ PDF é«˜æ•ˆè§£ææå–](llm/minerU_intro.md)
- [Markitdown å…¥é—¨](llm/markitdown/README.md)
- [DeepWiki ä½¿ç”¨æ–¹æ³•ä¸æŠ€æœ¯åŸç†æ·±åº¦åˆ†æ](llm/DeepWiki ä½¿ç”¨æ–¹æ³•ä¸æŠ€æœ¯åŸç†æ·±åº¦åˆ†æ.md)

### 13. ç‰¹å®šé¢†åŸŸåº”ç”¨

- [è¯»è€…æ¥ä¿¡ï¼šè¯·é—®7bé˜…è¯»åˆ†æä¸åŒä¸­åŒ»å¤ç±çš„èƒ½åŠ›æ€ä¹ˆæ ·ï¼Ÿå¯ä»¥è¿›è¡Œä¸“é¡¹è®­ç»ƒå¤§å¹…åº¦æé«˜è¿™æ–¹é¢èƒ½åŠ›ä¹ˆï¼Ÿ](llm/scenario/traditional-chinese-medicine.md)
- [ä¸­å›½å¤§é™†åˆåŒå®¡æ ¸è¦ç‚¹æ¸…å•](llm/scenario/ä¸­å›½å¤§é™†åˆåŒå®¡æ ¸è¦ç‚¹æ¸…å•.md)
- [è®©ç”¨æˆ·"è¯´åŠå¥"è¯ä¹Ÿèƒ½æ‡‚ï¼šChatBox çš„æ„å›¾è¯†åˆ«ä¸è¯­ä¹‰ç†è§£æœºåˆ¶è§£æ](llm/è®©ç”¨æˆ·"è¯´åŠå¥"è¯ä¹Ÿèƒ½æ‡‚ï¼šChatBox%20çš„æ„å›¾è¯†åˆ«ä¸è¯­ä¹‰ç†è§£æœºåˆ¶è§£æ.md)

---

## ç¬¬å…­éƒ¨åˆ†ï¼šå·¥å…·ä¸èµ„æº

### 14. å¼€æºé¡¹ç›®æ¨è

- [unstructured](https://github.com/Unstructured-IO/unstructured):Open source libraries and APIs to build custom preprocessing pipelines for labeling, training, or production machine learning pipelines.
- [MinerU](https://github.com/opendatalab/MinerU):A high-quality tool for convert PDF to Markdown and JSON.
- [markitdown](https://github.com/microsoft/markitdown): Python tool for converting files and office documents to Markdown.
- [unsloth](https://github.com/unslothai/unsloth): About
Finetune Llama 3.3, DeepSeek-R1 & Reasoning LLMs 2x faster with 70% less memory!
- [ktransformers](https://github.com/kvcache-ai/ktransformers): A Flexible Framework for Experiencing Cutting-edge LLM Inference Optimizations

---
